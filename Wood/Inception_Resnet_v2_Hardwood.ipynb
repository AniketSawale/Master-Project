{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Inception_Resnet_v2_Hardwood.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rol3LfN3uqPl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "4a15913e-6f46-4be9-d11c-b8b99d18e302"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50u3cEInvIVG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Importing the Libraries.\n",
        "import keras\n",
        "import os\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Dropout\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np\n",
        "#import keras.backend as K\n",
        "import tensorflow.keras.backend as K\n",
        "import tensorflow.compat.v1 as tf\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "import numpy as np\n",
        "import sys\n",
        "import os\n",
        "import shutil\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import keras\n",
        "import glob\n",
        "from PIL import Image\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from keras import models, regularizers, layers, optimizers, losses, metrics\n",
        "from keras.applications.resnet50 import ResNet50\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, MaxPool2D\n",
        "from keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
        "from keras.layers import AveragePooling2D\n",
        "from keras.models import load_model\n",
        "from keras.layers.pooling import GlobalAveragePooling2D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from PIL import ImageFile"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xbxl1Zn_vN5A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.enable_eager_execution()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BkKt62czvRnk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ImageFile.LOAD_TRUNCATED_IMAGES = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8HAO1Ue3vUOc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Data Augmentation.\n",
        "DataGenerator = ImageDataGenerator(horizontal_flip=True, vertical_flip=True, rescale=1./255, brightness_range=[0.2,0.7])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRbErZmBvYTK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TestGenerator = ImageDataGenerator(rescale=1./255)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ByuD91mKvbDt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6c965b33-402b-4ea7-9fd8-314c2c722d1b"
      },
      "source": [
        "Grey_TrainingData = DataGenerator.flow_from_directory('/content/drive/My Drive/1-piece/Train/', target_size=(224,224), batch_size=8, color_mode='grayscale')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2015 images belonging to 112 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hPvS2jDhvg29",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0064555a-a253-49a0-e01f-09d6fc37c9e3"
      },
      "source": [
        "Grey_ValidData = TestGenerator.flow_from_directory('/content/drive/My Drive/1-piece/Valid/', target_size=(224,224),batch_size=8, color_mode='grayscale')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 112 images belonging to 112 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cIY40F0vkZ_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gpu_options = tf.GPUOptions(allow_growth=True)\n",
        "session = tf.InteractiveSession(config=tf.ConfigProto(gpu_options=gpu_options))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qotSK1tyvnln",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.applications.inception_resnet_v2 import InceptionResNetV2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A3yrfGQVwxTC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "38a5a0be-ada5-4a01-db66-c525efca0839"
      },
      "source": [
        "conv_base = InceptionResNetV2(weights = 'imagenet', include_top = False, pooling = 'avg')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_resnet_v2/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "219062272/219055592 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGlTaIpwyQ9u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for layer in conv_base.layers[:765]:\n",
        "  layer.trainable = False\n",
        "for layer in conv_base.layers[765:]:\n",
        "  layer.trainable = True\n",
        "for layer in conv_base.layers:\n",
        "  if isinstance(layer, BatchNormalization):\n",
        "    layer.trainable = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TwI81Maa5eZI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f76714b7-805a-4a9c-be00-776e059d4281"
      },
      "source": [
        "for i, layer in enumerate(conv_base.layers):\n",
        "  print(i, layer.name, layer.trainable)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 input_1 False\n",
            "1 conv2d False\n",
            "2 batch_normalization True\n",
            "3 activation False\n",
            "4 conv2d_1 False\n",
            "5 batch_normalization_1 True\n",
            "6 activation_1 False\n",
            "7 conv2d_2 False\n",
            "8 batch_normalization_2 True\n",
            "9 activation_2 False\n",
            "10 max_pooling2d False\n",
            "11 conv2d_3 False\n",
            "12 batch_normalization_3 True\n",
            "13 activation_3 False\n",
            "14 conv2d_4 False\n",
            "15 batch_normalization_4 True\n",
            "16 activation_4 False\n",
            "17 max_pooling2d_1 False\n",
            "18 conv2d_8 False\n",
            "19 batch_normalization_8 True\n",
            "20 activation_8 False\n",
            "21 conv2d_6 False\n",
            "22 conv2d_9 False\n",
            "23 batch_normalization_6 True\n",
            "24 batch_normalization_9 True\n",
            "25 activation_6 False\n",
            "26 activation_9 False\n",
            "27 average_pooling2d False\n",
            "28 conv2d_5 False\n",
            "29 conv2d_7 False\n",
            "30 conv2d_10 False\n",
            "31 conv2d_11 False\n",
            "32 batch_normalization_5 True\n",
            "33 batch_normalization_7 True\n",
            "34 batch_normalization_10 True\n",
            "35 batch_normalization_11 True\n",
            "36 activation_5 False\n",
            "37 activation_7 False\n",
            "38 activation_10 False\n",
            "39 activation_11 False\n",
            "40 mixed_5b False\n",
            "41 conv2d_15 False\n",
            "42 batch_normalization_15 True\n",
            "43 activation_15 False\n",
            "44 conv2d_13 False\n",
            "45 conv2d_16 False\n",
            "46 batch_normalization_13 True\n",
            "47 batch_normalization_16 True\n",
            "48 activation_13 False\n",
            "49 activation_16 False\n",
            "50 conv2d_12 False\n",
            "51 conv2d_14 False\n",
            "52 conv2d_17 False\n",
            "53 batch_normalization_12 True\n",
            "54 batch_normalization_14 True\n",
            "55 batch_normalization_17 True\n",
            "56 activation_12 False\n",
            "57 activation_14 False\n",
            "58 activation_17 False\n",
            "59 block35_1_mixed False\n",
            "60 block35_1_conv False\n",
            "61 block35_1 False\n",
            "62 block35_1_ac False\n",
            "63 conv2d_21 False\n",
            "64 batch_normalization_21 True\n",
            "65 activation_21 False\n",
            "66 conv2d_19 False\n",
            "67 conv2d_22 False\n",
            "68 batch_normalization_19 True\n",
            "69 batch_normalization_22 True\n",
            "70 activation_19 False\n",
            "71 activation_22 False\n",
            "72 conv2d_18 False\n",
            "73 conv2d_20 False\n",
            "74 conv2d_23 False\n",
            "75 batch_normalization_18 True\n",
            "76 batch_normalization_20 True\n",
            "77 batch_normalization_23 True\n",
            "78 activation_18 False\n",
            "79 activation_20 False\n",
            "80 activation_23 False\n",
            "81 block35_2_mixed False\n",
            "82 block35_2_conv False\n",
            "83 block35_2 False\n",
            "84 block35_2_ac False\n",
            "85 conv2d_27 False\n",
            "86 batch_normalization_27 True\n",
            "87 activation_27 False\n",
            "88 conv2d_25 False\n",
            "89 conv2d_28 False\n",
            "90 batch_normalization_25 True\n",
            "91 batch_normalization_28 True\n",
            "92 activation_25 False\n",
            "93 activation_28 False\n",
            "94 conv2d_24 False\n",
            "95 conv2d_26 False\n",
            "96 conv2d_29 False\n",
            "97 batch_normalization_24 True\n",
            "98 batch_normalization_26 True\n",
            "99 batch_normalization_29 True\n",
            "100 activation_24 False\n",
            "101 activation_26 False\n",
            "102 activation_29 False\n",
            "103 block35_3_mixed False\n",
            "104 block35_3_conv False\n",
            "105 block35_3 False\n",
            "106 block35_3_ac False\n",
            "107 conv2d_33 False\n",
            "108 batch_normalization_33 True\n",
            "109 activation_33 False\n",
            "110 conv2d_31 False\n",
            "111 conv2d_34 False\n",
            "112 batch_normalization_31 True\n",
            "113 batch_normalization_34 True\n",
            "114 activation_31 False\n",
            "115 activation_34 False\n",
            "116 conv2d_30 False\n",
            "117 conv2d_32 False\n",
            "118 conv2d_35 False\n",
            "119 batch_normalization_30 True\n",
            "120 batch_normalization_32 True\n",
            "121 batch_normalization_35 True\n",
            "122 activation_30 False\n",
            "123 activation_32 False\n",
            "124 activation_35 False\n",
            "125 block35_4_mixed False\n",
            "126 block35_4_conv False\n",
            "127 block35_4 False\n",
            "128 block35_4_ac False\n",
            "129 conv2d_39 False\n",
            "130 batch_normalization_39 True\n",
            "131 activation_39 False\n",
            "132 conv2d_37 False\n",
            "133 conv2d_40 False\n",
            "134 batch_normalization_37 True\n",
            "135 batch_normalization_40 True\n",
            "136 activation_37 False\n",
            "137 activation_40 False\n",
            "138 conv2d_36 False\n",
            "139 conv2d_38 False\n",
            "140 conv2d_41 False\n",
            "141 batch_normalization_36 True\n",
            "142 batch_normalization_38 True\n",
            "143 batch_normalization_41 True\n",
            "144 activation_36 False\n",
            "145 activation_38 False\n",
            "146 activation_41 False\n",
            "147 block35_5_mixed False\n",
            "148 block35_5_conv False\n",
            "149 block35_5 False\n",
            "150 block35_5_ac False\n",
            "151 conv2d_45 False\n",
            "152 batch_normalization_45 True\n",
            "153 activation_45 False\n",
            "154 conv2d_43 False\n",
            "155 conv2d_46 False\n",
            "156 batch_normalization_43 True\n",
            "157 batch_normalization_46 True\n",
            "158 activation_43 False\n",
            "159 activation_46 False\n",
            "160 conv2d_42 False\n",
            "161 conv2d_44 False\n",
            "162 conv2d_47 False\n",
            "163 batch_normalization_42 True\n",
            "164 batch_normalization_44 True\n",
            "165 batch_normalization_47 True\n",
            "166 activation_42 False\n",
            "167 activation_44 False\n",
            "168 activation_47 False\n",
            "169 block35_6_mixed False\n",
            "170 block35_6_conv False\n",
            "171 block35_6 False\n",
            "172 block35_6_ac False\n",
            "173 conv2d_51 False\n",
            "174 batch_normalization_51 True\n",
            "175 activation_51 False\n",
            "176 conv2d_49 False\n",
            "177 conv2d_52 False\n",
            "178 batch_normalization_49 True\n",
            "179 batch_normalization_52 True\n",
            "180 activation_49 False\n",
            "181 activation_52 False\n",
            "182 conv2d_48 False\n",
            "183 conv2d_50 False\n",
            "184 conv2d_53 False\n",
            "185 batch_normalization_48 True\n",
            "186 batch_normalization_50 True\n",
            "187 batch_normalization_53 True\n",
            "188 activation_48 False\n",
            "189 activation_50 False\n",
            "190 activation_53 False\n",
            "191 block35_7_mixed False\n",
            "192 block35_7_conv False\n",
            "193 block35_7 False\n",
            "194 block35_7_ac False\n",
            "195 conv2d_57 False\n",
            "196 batch_normalization_57 True\n",
            "197 activation_57 False\n",
            "198 conv2d_55 False\n",
            "199 conv2d_58 False\n",
            "200 batch_normalization_55 True\n",
            "201 batch_normalization_58 True\n",
            "202 activation_55 False\n",
            "203 activation_58 False\n",
            "204 conv2d_54 False\n",
            "205 conv2d_56 False\n",
            "206 conv2d_59 False\n",
            "207 batch_normalization_54 True\n",
            "208 batch_normalization_56 True\n",
            "209 batch_normalization_59 True\n",
            "210 activation_54 False\n",
            "211 activation_56 False\n",
            "212 activation_59 False\n",
            "213 block35_8_mixed False\n",
            "214 block35_8_conv False\n",
            "215 block35_8 False\n",
            "216 block35_8_ac False\n",
            "217 conv2d_63 False\n",
            "218 batch_normalization_63 True\n",
            "219 activation_63 False\n",
            "220 conv2d_61 False\n",
            "221 conv2d_64 False\n",
            "222 batch_normalization_61 True\n",
            "223 batch_normalization_64 True\n",
            "224 activation_61 False\n",
            "225 activation_64 False\n",
            "226 conv2d_60 False\n",
            "227 conv2d_62 False\n",
            "228 conv2d_65 False\n",
            "229 batch_normalization_60 True\n",
            "230 batch_normalization_62 True\n",
            "231 batch_normalization_65 True\n",
            "232 activation_60 False\n",
            "233 activation_62 False\n",
            "234 activation_65 False\n",
            "235 block35_9_mixed False\n",
            "236 block35_9_conv False\n",
            "237 block35_9 False\n",
            "238 block35_9_ac False\n",
            "239 conv2d_69 False\n",
            "240 batch_normalization_69 True\n",
            "241 activation_69 False\n",
            "242 conv2d_67 False\n",
            "243 conv2d_70 False\n",
            "244 batch_normalization_67 True\n",
            "245 batch_normalization_70 True\n",
            "246 activation_67 False\n",
            "247 activation_70 False\n",
            "248 conv2d_66 False\n",
            "249 conv2d_68 False\n",
            "250 conv2d_71 False\n",
            "251 batch_normalization_66 True\n",
            "252 batch_normalization_68 True\n",
            "253 batch_normalization_71 True\n",
            "254 activation_66 False\n",
            "255 activation_68 False\n",
            "256 activation_71 False\n",
            "257 block35_10_mixed False\n",
            "258 block35_10_conv False\n",
            "259 block35_10 False\n",
            "260 block35_10_ac False\n",
            "261 conv2d_73 False\n",
            "262 batch_normalization_73 True\n",
            "263 activation_73 False\n",
            "264 conv2d_74 False\n",
            "265 batch_normalization_74 True\n",
            "266 activation_74 False\n",
            "267 conv2d_72 False\n",
            "268 conv2d_75 False\n",
            "269 batch_normalization_72 True\n",
            "270 batch_normalization_75 True\n",
            "271 activation_72 False\n",
            "272 activation_75 False\n",
            "273 max_pooling2d_2 False\n",
            "274 mixed_6a False\n",
            "275 conv2d_77 False\n",
            "276 batch_normalization_77 True\n",
            "277 activation_77 False\n",
            "278 conv2d_78 False\n",
            "279 batch_normalization_78 True\n",
            "280 activation_78 False\n",
            "281 conv2d_76 False\n",
            "282 conv2d_79 False\n",
            "283 batch_normalization_76 True\n",
            "284 batch_normalization_79 True\n",
            "285 activation_76 False\n",
            "286 activation_79 False\n",
            "287 block17_1_mixed False\n",
            "288 block17_1_conv False\n",
            "289 block17_1 False\n",
            "290 block17_1_ac False\n",
            "291 conv2d_81 False\n",
            "292 batch_normalization_81 True\n",
            "293 activation_81 False\n",
            "294 conv2d_82 False\n",
            "295 batch_normalization_82 True\n",
            "296 activation_82 False\n",
            "297 conv2d_80 False\n",
            "298 conv2d_83 False\n",
            "299 batch_normalization_80 True\n",
            "300 batch_normalization_83 True\n",
            "301 activation_80 False\n",
            "302 activation_83 False\n",
            "303 block17_2_mixed False\n",
            "304 block17_2_conv False\n",
            "305 block17_2 False\n",
            "306 block17_2_ac False\n",
            "307 conv2d_85 False\n",
            "308 batch_normalization_85 True\n",
            "309 activation_85 False\n",
            "310 conv2d_86 False\n",
            "311 batch_normalization_86 True\n",
            "312 activation_86 False\n",
            "313 conv2d_84 False\n",
            "314 conv2d_87 False\n",
            "315 batch_normalization_84 True\n",
            "316 batch_normalization_87 True\n",
            "317 activation_84 False\n",
            "318 activation_87 False\n",
            "319 block17_3_mixed False\n",
            "320 block17_3_conv False\n",
            "321 block17_3 False\n",
            "322 block17_3_ac False\n",
            "323 conv2d_89 False\n",
            "324 batch_normalization_89 True\n",
            "325 activation_89 False\n",
            "326 conv2d_90 False\n",
            "327 batch_normalization_90 True\n",
            "328 activation_90 False\n",
            "329 conv2d_88 False\n",
            "330 conv2d_91 False\n",
            "331 batch_normalization_88 True\n",
            "332 batch_normalization_91 True\n",
            "333 activation_88 False\n",
            "334 activation_91 False\n",
            "335 block17_4_mixed False\n",
            "336 block17_4_conv False\n",
            "337 block17_4 False\n",
            "338 block17_4_ac False\n",
            "339 conv2d_93 False\n",
            "340 batch_normalization_93 True\n",
            "341 activation_93 False\n",
            "342 conv2d_94 False\n",
            "343 batch_normalization_94 True\n",
            "344 activation_94 False\n",
            "345 conv2d_92 False\n",
            "346 conv2d_95 False\n",
            "347 batch_normalization_92 True\n",
            "348 batch_normalization_95 True\n",
            "349 activation_92 False\n",
            "350 activation_95 False\n",
            "351 block17_5_mixed False\n",
            "352 block17_5_conv False\n",
            "353 block17_5 False\n",
            "354 block17_5_ac False\n",
            "355 conv2d_97 False\n",
            "356 batch_normalization_97 True\n",
            "357 activation_97 False\n",
            "358 conv2d_98 False\n",
            "359 batch_normalization_98 True\n",
            "360 activation_98 False\n",
            "361 conv2d_96 False\n",
            "362 conv2d_99 False\n",
            "363 batch_normalization_96 True\n",
            "364 batch_normalization_99 True\n",
            "365 activation_96 False\n",
            "366 activation_99 False\n",
            "367 block17_6_mixed False\n",
            "368 block17_6_conv False\n",
            "369 block17_6 False\n",
            "370 block17_6_ac False\n",
            "371 conv2d_101 False\n",
            "372 batch_normalization_101 True\n",
            "373 activation_101 False\n",
            "374 conv2d_102 False\n",
            "375 batch_normalization_102 True\n",
            "376 activation_102 False\n",
            "377 conv2d_100 False\n",
            "378 conv2d_103 False\n",
            "379 batch_normalization_100 True\n",
            "380 batch_normalization_103 True\n",
            "381 activation_100 False\n",
            "382 activation_103 False\n",
            "383 block17_7_mixed False\n",
            "384 block17_7_conv False\n",
            "385 block17_7 False\n",
            "386 block17_7_ac False\n",
            "387 conv2d_105 False\n",
            "388 batch_normalization_105 True\n",
            "389 activation_105 False\n",
            "390 conv2d_106 False\n",
            "391 batch_normalization_106 True\n",
            "392 activation_106 False\n",
            "393 conv2d_104 False\n",
            "394 conv2d_107 False\n",
            "395 batch_normalization_104 True\n",
            "396 batch_normalization_107 True\n",
            "397 activation_104 False\n",
            "398 activation_107 False\n",
            "399 block17_8_mixed False\n",
            "400 block17_8_conv False\n",
            "401 block17_8 False\n",
            "402 block17_8_ac False\n",
            "403 conv2d_109 False\n",
            "404 batch_normalization_109 True\n",
            "405 activation_109 False\n",
            "406 conv2d_110 False\n",
            "407 batch_normalization_110 True\n",
            "408 activation_110 False\n",
            "409 conv2d_108 False\n",
            "410 conv2d_111 False\n",
            "411 batch_normalization_108 True\n",
            "412 batch_normalization_111 True\n",
            "413 activation_108 False\n",
            "414 activation_111 False\n",
            "415 block17_9_mixed False\n",
            "416 block17_9_conv False\n",
            "417 block17_9 False\n",
            "418 block17_9_ac False\n",
            "419 conv2d_113 False\n",
            "420 batch_normalization_113 True\n",
            "421 activation_113 False\n",
            "422 conv2d_114 False\n",
            "423 batch_normalization_114 True\n",
            "424 activation_114 False\n",
            "425 conv2d_112 False\n",
            "426 conv2d_115 False\n",
            "427 batch_normalization_112 True\n",
            "428 batch_normalization_115 True\n",
            "429 activation_112 False\n",
            "430 activation_115 False\n",
            "431 block17_10_mixed False\n",
            "432 block17_10_conv False\n",
            "433 block17_10 False\n",
            "434 block17_10_ac False\n",
            "435 conv2d_117 False\n",
            "436 batch_normalization_117 True\n",
            "437 activation_117 False\n",
            "438 conv2d_118 False\n",
            "439 batch_normalization_118 True\n",
            "440 activation_118 False\n",
            "441 conv2d_116 False\n",
            "442 conv2d_119 False\n",
            "443 batch_normalization_116 True\n",
            "444 batch_normalization_119 True\n",
            "445 activation_116 False\n",
            "446 activation_119 False\n",
            "447 block17_11_mixed False\n",
            "448 block17_11_conv False\n",
            "449 block17_11 False\n",
            "450 block17_11_ac False\n",
            "451 conv2d_121 False\n",
            "452 batch_normalization_121 True\n",
            "453 activation_121 False\n",
            "454 conv2d_122 False\n",
            "455 batch_normalization_122 True\n",
            "456 activation_122 False\n",
            "457 conv2d_120 False\n",
            "458 conv2d_123 False\n",
            "459 batch_normalization_120 True\n",
            "460 batch_normalization_123 True\n",
            "461 activation_120 False\n",
            "462 activation_123 False\n",
            "463 block17_12_mixed False\n",
            "464 block17_12_conv False\n",
            "465 block17_12 False\n",
            "466 block17_12_ac False\n",
            "467 conv2d_125 False\n",
            "468 batch_normalization_125 True\n",
            "469 activation_125 False\n",
            "470 conv2d_126 False\n",
            "471 batch_normalization_126 True\n",
            "472 activation_126 False\n",
            "473 conv2d_124 False\n",
            "474 conv2d_127 False\n",
            "475 batch_normalization_124 True\n",
            "476 batch_normalization_127 True\n",
            "477 activation_124 False\n",
            "478 activation_127 False\n",
            "479 block17_13_mixed False\n",
            "480 block17_13_conv False\n",
            "481 block17_13 False\n",
            "482 block17_13_ac False\n",
            "483 conv2d_129 False\n",
            "484 batch_normalization_129 True\n",
            "485 activation_129 False\n",
            "486 conv2d_130 False\n",
            "487 batch_normalization_130 True\n",
            "488 activation_130 False\n",
            "489 conv2d_128 False\n",
            "490 conv2d_131 False\n",
            "491 batch_normalization_128 True\n",
            "492 batch_normalization_131 True\n",
            "493 activation_128 False\n",
            "494 activation_131 False\n",
            "495 block17_14_mixed False\n",
            "496 block17_14_conv False\n",
            "497 block17_14 False\n",
            "498 block17_14_ac False\n",
            "499 conv2d_133 False\n",
            "500 batch_normalization_133 True\n",
            "501 activation_133 False\n",
            "502 conv2d_134 False\n",
            "503 batch_normalization_134 True\n",
            "504 activation_134 False\n",
            "505 conv2d_132 False\n",
            "506 conv2d_135 False\n",
            "507 batch_normalization_132 True\n",
            "508 batch_normalization_135 True\n",
            "509 activation_132 False\n",
            "510 activation_135 False\n",
            "511 block17_15_mixed False\n",
            "512 block17_15_conv False\n",
            "513 block17_15 False\n",
            "514 block17_15_ac False\n",
            "515 conv2d_137 False\n",
            "516 batch_normalization_137 True\n",
            "517 activation_137 False\n",
            "518 conv2d_138 False\n",
            "519 batch_normalization_138 True\n",
            "520 activation_138 False\n",
            "521 conv2d_136 False\n",
            "522 conv2d_139 False\n",
            "523 batch_normalization_136 True\n",
            "524 batch_normalization_139 True\n",
            "525 activation_136 False\n",
            "526 activation_139 False\n",
            "527 block17_16_mixed False\n",
            "528 block17_16_conv False\n",
            "529 block17_16 False\n",
            "530 block17_16_ac False\n",
            "531 conv2d_141 False\n",
            "532 batch_normalization_141 True\n",
            "533 activation_141 False\n",
            "534 conv2d_142 False\n",
            "535 batch_normalization_142 True\n",
            "536 activation_142 False\n",
            "537 conv2d_140 False\n",
            "538 conv2d_143 False\n",
            "539 batch_normalization_140 True\n",
            "540 batch_normalization_143 True\n",
            "541 activation_140 False\n",
            "542 activation_143 False\n",
            "543 block17_17_mixed False\n",
            "544 block17_17_conv False\n",
            "545 block17_17 False\n",
            "546 block17_17_ac False\n",
            "547 conv2d_145 False\n",
            "548 batch_normalization_145 True\n",
            "549 activation_145 False\n",
            "550 conv2d_146 False\n",
            "551 batch_normalization_146 True\n",
            "552 activation_146 False\n",
            "553 conv2d_144 False\n",
            "554 conv2d_147 False\n",
            "555 batch_normalization_144 True\n",
            "556 batch_normalization_147 True\n",
            "557 activation_144 False\n",
            "558 activation_147 False\n",
            "559 block17_18_mixed False\n",
            "560 block17_18_conv False\n",
            "561 block17_18 False\n",
            "562 block17_18_ac False\n",
            "563 conv2d_149 False\n",
            "564 batch_normalization_149 True\n",
            "565 activation_149 False\n",
            "566 conv2d_150 False\n",
            "567 batch_normalization_150 True\n",
            "568 activation_150 False\n",
            "569 conv2d_148 False\n",
            "570 conv2d_151 False\n",
            "571 batch_normalization_148 True\n",
            "572 batch_normalization_151 True\n",
            "573 activation_148 False\n",
            "574 activation_151 False\n",
            "575 block17_19_mixed False\n",
            "576 block17_19_conv False\n",
            "577 block17_19 False\n",
            "578 block17_19_ac False\n",
            "579 conv2d_153 False\n",
            "580 batch_normalization_153 True\n",
            "581 activation_153 False\n",
            "582 conv2d_154 False\n",
            "583 batch_normalization_154 True\n",
            "584 activation_154 False\n",
            "585 conv2d_152 False\n",
            "586 conv2d_155 False\n",
            "587 batch_normalization_152 True\n",
            "588 batch_normalization_155 True\n",
            "589 activation_152 False\n",
            "590 activation_155 False\n",
            "591 block17_20_mixed False\n",
            "592 block17_20_conv False\n",
            "593 block17_20 False\n",
            "594 block17_20_ac False\n",
            "595 conv2d_160 False\n",
            "596 batch_normalization_160 True\n",
            "597 activation_160 False\n",
            "598 conv2d_156 False\n",
            "599 conv2d_158 False\n",
            "600 conv2d_161 False\n",
            "601 batch_normalization_156 True\n",
            "602 batch_normalization_158 True\n",
            "603 batch_normalization_161 True\n",
            "604 activation_156 False\n",
            "605 activation_158 False\n",
            "606 activation_161 False\n",
            "607 conv2d_157 False\n",
            "608 conv2d_159 False\n",
            "609 conv2d_162 False\n",
            "610 batch_normalization_157 True\n",
            "611 batch_normalization_159 True\n",
            "612 batch_normalization_162 True\n",
            "613 activation_157 False\n",
            "614 activation_159 False\n",
            "615 activation_162 False\n",
            "616 max_pooling2d_3 False\n",
            "617 mixed_7a False\n",
            "618 conv2d_164 False\n",
            "619 batch_normalization_164 True\n",
            "620 activation_164 False\n",
            "621 conv2d_165 False\n",
            "622 batch_normalization_165 True\n",
            "623 activation_165 False\n",
            "624 conv2d_163 False\n",
            "625 conv2d_166 False\n",
            "626 batch_normalization_163 True\n",
            "627 batch_normalization_166 True\n",
            "628 activation_163 False\n",
            "629 activation_166 False\n",
            "630 block8_1_mixed False\n",
            "631 block8_1_conv False\n",
            "632 block8_1 False\n",
            "633 block8_1_ac False\n",
            "634 conv2d_168 False\n",
            "635 batch_normalization_168 True\n",
            "636 activation_168 False\n",
            "637 conv2d_169 False\n",
            "638 batch_normalization_169 True\n",
            "639 activation_169 False\n",
            "640 conv2d_167 False\n",
            "641 conv2d_170 False\n",
            "642 batch_normalization_167 True\n",
            "643 batch_normalization_170 True\n",
            "644 activation_167 False\n",
            "645 activation_170 False\n",
            "646 block8_2_mixed False\n",
            "647 block8_2_conv False\n",
            "648 block8_2 False\n",
            "649 block8_2_ac False\n",
            "650 conv2d_172 False\n",
            "651 batch_normalization_172 True\n",
            "652 activation_172 False\n",
            "653 conv2d_173 False\n",
            "654 batch_normalization_173 True\n",
            "655 activation_173 False\n",
            "656 conv2d_171 False\n",
            "657 conv2d_174 False\n",
            "658 batch_normalization_171 True\n",
            "659 batch_normalization_174 True\n",
            "660 activation_171 False\n",
            "661 activation_174 False\n",
            "662 block8_3_mixed False\n",
            "663 block8_3_conv False\n",
            "664 block8_3 False\n",
            "665 block8_3_ac False\n",
            "666 conv2d_176 False\n",
            "667 batch_normalization_176 True\n",
            "668 activation_176 False\n",
            "669 conv2d_177 False\n",
            "670 batch_normalization_177 True\n",
            "671 activation_177 False\n",
            "672 conv2d_175 False\n",
            "673 conv2d_178 False\n",
            "674 batch_normalization_175 True\n",
            "675 batch_normalization_178 True\n",
            "676 activation_175 False\n",
            "677 activation_178 False\n",
            "678 block8_4_mixed False\n",
            "679 block8_4_conv False\n",
            "680 block8_4 False\n",
            "681 block8_4_ac False\n",
            "682 conv2d_180 False\n",
            "683 batch_normalization_180 True\n",
            "684 activation_180 False\n",
            "685 conv2d_181 False\n",
            "686 batch_normalization_181 True\n",
            "687 activation_181 False\n",
            "688 conv2d_179 False\n",
            "689 conv2d_182 False\n",
            "690 batch_normalization_179 True\n",
            "691 batch_normalization_182 True\n",
            "692 activation_179 False\n",
            "693 activation_182 False\n",
            "694 block8_5_mixed False\n",
            "695 block8_5_conv False\n",
            "696 block8_5 False\n",
            "697 block8_5_ac False\n",
            "698 conv2d_184 False\n",
            "699 batch_normalization_184 True\n",
            "700 activation_184 False\n",
            "701 conv2d_185 False\n",
            "702 batch_normalization_185 True\n",
            "703 activation_185 False\n",
            "704 conv2d_183 False\n",
            "705 conv2d_186 False\n",
            "706 batch_normalization_183 True\n",
            "707 batch_normalization_186 True\n",
            "708 activation_183 False\n",
            "709 activation_186 False\n",
            "710 block8_6_mixed False\n",
            "711 block8_6_conv False\n",
            "712 block8_6 False\n",
            "713 block8_6_ac False\n",
            "714 conv2d_188 False\n",
            "715 batch_normalization_188 True\n",
            "716 activation_188 False\n",
            "717 conv2d_189 False\n",
            "718 batch_normalization_189 True\n",
            "719 activation_189 False\n",
            "720 conv2d_187 False\n",
            "721 conv2d_190 False\n",
            "722 batch_normalization_187 True\n",
            "723 batch_normalization_190 True\n",
            "724 activation_187 False\n",
            "725 activation_190 False\n",
            "726 block8_7_mixed False\n",
            "727 block8_7_conv False\n",
            "728 block8_7 False\n",
            "729 block8_7_ac False\n",
            "730 conv2d_192 False\n",
            "731 batch_normalization_192 True\n",
            "732 activation_192 False\n",
            "733 conv2d_193 False\n",
            "734 batch_normalization_193 True\n",
            "735 activation_193 False\n",
            "736 conv2d_191 False\n",
            "737 conv2d_194 False\n",
            "738 batch_normalization_191 True\n",
            "739 batch_normalization_194 True\n",
            "740 activation_191 False\n",
            "741 activation_194 False\n",
            "742 block8_8_mixed False\n",
            "743 block8_8_conv False\n",
            "744 block8_8 False\n",
            "745 block8_8_ac False\n",
            "746 conv2d_196 False\n",
            "747 batch_normalization_196 True\n",
            "748 activation_196 False\n",
            "749 conv2d_197 False\n",
            "750 batch_normalization_197 True\n",
            "751 activation_197 False\n",
            "752 conv2d_195 False\n",
            "753 conv2d_198 False\n",
            "754 batch_normalization_195 True\n",
            "755 batch_normalization_198 True\n",
            "756 activation_195 False\n",
            "757 activation_198 False\n",
            "758 block8_9_mixed False\n",
            "759 block8_9_conv False\n",
            "760 block8_9 False\n",
            "761 block8_9_ac False\n",
            "762 conv2d_200 False\n",
            "763 batch_normalization_200 True\n",
            "764 activation_200 False\n",
            "765 conv2d_201 True\n",
            "766 batch_normalization_201 True\n",
            "767 activation_201 True\n",
            "768 conv2d_199 True\n",
            "769 conv2d_202 True\n",
            "770 batch_normalization_199 True\n",
            "771 batch_normalization_202 True\n",
            "772 activation_199 True\n",
            "773 activation_202 True\n",
            "774 block8_10_mixed True\n",
            "775 block8_10_conv True\n",
            "776 block8_10 True\n",
            "777 conv_7b True\n",
            "778 conv_7b_bn True\n",
            "779 conv_7b_ac True\n",
            "780 global_average_pooling2d True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzWqYI8J5hGS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import Input"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dqBP288D5vug",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_tensor = Input(shape=(224,224,1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IMnkL3bw5-s_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = Conv2D(3,(3,3), padding='same')(input_tensor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "De0lHrbi6I5Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = conv_base(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_Rq-OhQ6Nuf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = Dense(2048, activation='relu', kernel_regularizer=regularizers.l2(0.001))(x)\n",
        "x = Dropout(0.5)(x)\n",
        "out = Dense(112, activation='softmax')(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "puwW1wKf6nYQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Model(inputs = input_tensor, outputs = out)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUkDF-Sj7Iia",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "e452f013-5336-4255-df3d-863cbb7f796c"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 224, 224, 1)]     0         \n",
            "_________________________________________________________________\n",
            "conv2d_203 (Conv2D)          (None, 224, 224, 3)       30        \n",
            "_________________________________________________________________\n",
            "inception_resnet_v2 (Functio (None, 1536)              54336736  \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 2048)              3147776   \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 112)               229488    \n",
            "=================================================================\n",
            "Total params: 57,714,030\n",
            "Trainable params: 8,236,782\n",
            "Non-trainable params: 49,477,248\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHdoLuda7LbU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(lr=0.001),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Dc78Rf97QXu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "checkpoint = ModelCheckpoint(\"/content/drive/My Drive/1-piece/Inception_ResnetV2_GrayScale.h5\",\n",
        "                             monitor=\"val_loss\",\n",
        "                             mode=\"min\",\n",
        "                             save_best_only = True,\n",
        "                             verbose=1)\n",
        "\n",
        "earlystop = EarlyStopping(monitor = 'val_loss', \n",
        "                          min_delta = 0, \n",
        "                          patience = 40,\n",
        "                          verbose = 1,\n",
        "                          restore_best_weights = True)\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(monitor = 'val_loss',\n",
        "                              factor = 0.2,\n",
        "                              patience = 40,\n",
        "                              verbose = 1,\n",
        "                              min_delta = 0.00001)\n",
        "\n",
        "callBacks = [earlystop, checkpoint, reduce_lr]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RCbK8gbZ7cpK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ff2002f0-bcc6-424c-f22a-cd4970168f5f"
      },
      "source": [
        "hist = model.fit_generator(steps_per_epoch=252,generator= Grey_TrainingData, validation_data= Grey_ValidData, validation_steps=14,epochs=150,callbacks=callBacks)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-23-2f51164406f7>:1: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.fit, which supports generators.\n",
            "Epoch 1/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 5.5671 - accuracy: 0.0387\n",
            "Epoch 00001: val_loss improved from inf to 4.30550, saving model to /content/drive/My Drive/1-piece/Inception_ResnetV2_GrayScale.h5\n",
            "252/252 [==============================] - 1646s 7s/step - loss: 5.5671 - accuracy: 0.0387 - val_loss: 4.3055 - val_accuracy: 0.1250\n",
            "Epoch 2/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 4.0440 - accuracy: 0.1270\n",
            "Epoch 00002: val_loss improved from 4.30550 to 3.72152, saving model to /content/drive/My Drive/1-piece/Inception_ResnetV2_GrayScale.h5\n",
            "252/252 [==============================] - 98s 388ms/step - loss: 4.0440 - accuracy: 0.1270 - val_loss: 3.7215 - val_accuracy: 0.2143\n",
            "Epoch 3/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 3.2977 - accuracy: 0.2069\n",
            "Epoch 00003: val_loss improved from 3.72152 to 3.58306, saving model to /content/drive/My Drive/1-piece/Inception_ResnetV2_GrayScale.h5\n",
            "252/252 [==============================] - 97s 386ms/step - loss: 3.2977 - accuracy: 0.2069 - val_loss: 3.5831 - val_accuracy: 0.2679\n",
            "Epoch 4/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 2.7627 - accuracy: 0.3266\n",
            "Epoch 00004: val_loss improved from 3.58306 to 3.19886, saving model to /content/drive/My Drive/1-piece/Inception_ResnetV2_GrayScale.h5\n",
            "252/252 [==============================] - 97s 386ms/step - loss: 2.7627 - accuracy: 0.3266 - val_loss: 3.1989 - val_accuracy: 0.3036\n",
            "Epoch 5/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 2.3499 - accuracy: 0.4055\n",
            "Epoch 00005: val_loss improved from 3.19886 to 2.41601, saving model to /content/drive/My Drive/1-piece/Inception_ResnetV2_GrayScale.h5\n",
            "252/252 [==============================] - 97s 385ms/step - loss: 2.3499 - accuracy: 0.4055 - val_loss: 2.4160 - val_accuracy: 0.4911\n",
            "Epoch 6/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 2.1247 - accuracy: 0.4794\n",
            "Epoch 00006: val_loss improved from 2.41601 to 2.31505, saving model to /content/drive/My Drive/1-piece/Inception_ResnetV2_GrayScale.h5\n",
            "252/252 [==============================] - 97s 383ms/step - loss: 2.1247 - accuracy: 0.4794 - val_loss: 2.3150 - val_accuracy: 0.4464\n",
            "Epoch 7/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 1.8507 - accuracy: 0.5320\n",
            "Epoch 00007: val_loss improved from 2.31505 to 2.26800, saving model to /content/drive/My Drive/1-piece/Inception_ResnetV2_GrayScale.h5\n",
            "252/252 [==============================] - 97s 386ms/step - loss: 1.8507 - accuracy: 0.5320 - val_loss: 2.2680 - val_accuracy: 0.4643\n",
            "Epoch 8/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 1.7341 - accuracy: 0.5697\n",
            "Epoch 00008: val_loss did not improve from 2.26800\n",
            "252/252 [==============================] - 92s 365ms/step - loss: 1.7341 - accuracy: 0.5697 - val_loss: 2.3392 - val_accuracy: 0.5000\n",
            "Epoch 9/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 1.5964 - accuracy: 0.6099\n",
            "Epoch 00009: val_loss improved from 2.26800 to 1.88817, saving model to /content/drive/My Drive/1-piece/Inception_ResnetV2_GrayScale.h5\n",
            "252/252 [==============================] - 96s 382ms/step - loss: 1.5964 - accuracy: 0.6099 - val_loss: 1.8882 - val_accuracy: 0.5446\n",
            "Epoch 10/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 1.4463 - accuracy: 0.6700\n",
            "Epoch 00010: val_loss improved from 1.88817 to 1.74523, saving model to /content/drive/My Drive/1-piece/Inception_ResnetV2_GrayScale.h5\n",
            "252/252 [==============================] - 97s 386ms/step - loss: 1.4463 - accuracy: 0.6700 - val_loss: 1.7452 - val_accuracy: 0.6071\n",
            "Epoch 11/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 1.4051 - accuracy: 0.6789\n",
            "Epoch 00011: val_loss improved from 1.74523 to 1.46595, saving model to /content/drive/My Drive/1-piece/Inception_ResnetV2_GrayScale.h5\n",
            "252/252 [==============================] - 98s 390ms/step - loss: 1.4051 - accuracy: 0.6789 - val_loss: 1.4659 - val_accuracy: 0.6518\n",
            "Epoch 12/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 1.3286 - accuracy: 0.7002\n",
            "Epoch 00012: val_loss did not improve from 1.46595\n",
            "252/252 [==============================] - 92s 364ms/step - loss: 1.3286 - accuracy: 0.7002 - val_loss: 1.7473 - val_accuracy: 0.6161\n",
            "Epoch 13/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 1.2465 - accuracy: 0.7266\n",
            "Epoch 00013: val_loss did not improve from 1.46595\n",
            "252/252 [==============================] - 91s 363ms/step - loss: 1.2465 - accuracy: 0.7266 - val_loss: 6.5854 - val_accuracy: 0.2679\n",
            "Epoch 14/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 1.2114 - accuracy: 0.7221\n",
            "Epoch 00014: val_loss improved from 1.46595 to 1.31810, saving model to /content/drive/My Drive/1-piece/Inception_ResnetV2_GrayScale.h5\n",
            "252/252 [==============================] - 96s 382ms/step - loss: 1.2114 - accuracy: 0.7221 - val_loss: 1.3181 - val_accuracy: 0.7768\n",
            "Epoch 15/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 1.1600 - accuracy: 0.7454\n",
            "Epoch 00015: val_loss did not improve from 1.31810\n",
            "252/252 [==============================] - 92s 364ms/step - loss: 1.1600 - accuracy: 0.7454 - val_loss: 1.4062 - val_accuracy: 0.6964\n",
            "Epoch 16/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 1.1630 - accuracy: 0.7439\n",
            "Epoch 00016: val_loss did not improve from 1.31810\n",
            "252/252 [==============================] - 90s 358ms/step - loss: 1.1630 - accuracy: 0.7439 - val_loss: 1.4179 - val_accuracy: 0.6696\n",
            "Epoch 17/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 1.0845 - accuracy: 0.7593\n",
            "Epoch 00017: val_loss did not improve from 1.31810\n",
            "252/252 [==============================] - 92s 364ms/step - loss: 1.0845 - accuracy: 0.7593 - val_loss: 1.4120 - val_accuracy: 0.6607\n",
            "Epoch 18/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 1.0378 - accuracy: 0.7667\n",
            "Epoch 00018: val_loss did not improve from 1.31810\n",
            "252/252 [==============================] - 92s 363ms/step - loss: 1.0378 - accuracy: 0.7667 - val_loss: 1.5011 - val_accuracy: 0.6518\n",
            "Epoch 19/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.9907 - accuracy: 0.7955\n",
            "Epoch 00019: val_loss did not improve from 1.31810\n",
            "252/252 [==============================] - 91s 363ms/step - loss: 0.9907 - accuracy: 0.7955 - val_loss: 1.4777 - val_accuracy: 0.6964\n",
            "Epoch 20/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.9787 - accuracy: 0.7891\n",
            "Epoch 00020: val_loss did not improve from 1.31810\n",
            "252/252 [==============================] - 92s 366ms/step - loss: 0.9787 - accuracy: 0.7891 - val_loss: 1.6016 - val_accuracy: 0.5982\n",
            "Epoch 21/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.9597 - accuracy: 0.8020\n",
            "Epoch 00021: val_loss improved from 1.31810 to 1.26159, saving model to /content/drive/My Drive/1-piece/Inception_ResnetV2_GrayScale.h5\n",
            "252/252 [==============================] - 98s 389ms/step - loss: 0.9597 - accuracy: 0.8020 - val_loss: 1.2616 - val_accuracy: 0.7054\n",
            "Epoch 22/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.9057 - accuracy: 0.8030\n",
            "Epoch 00022: val_loss improved from 1.26159 to 1.20057, saving model to /content/drive/My Drive/1-piece/Inception_ResnetV2_GrayScale.h5\n",
            "252/252 [==============================] - 98s 388ms/step - loss: 0.9057 - accuracy: 0.8030 - val_loss: 1.2006 - val_accuracy: 0.7768\n",
            "Epoch 23/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.8578 - accuracy: 0.8169\n",
            "Epoch 00023: val_loss did not improve from 1.20057\n",
            "252/252 [==============================] - 92s 365ms/step - loss: 0.8578 - accuracy: 0.8169 - val_loss: 1.3409 - val_accuracy: 0.7321\n",
            "Epoch 24/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.8647 - accuracy: 0.8223\n",
            "Epoch 00024: val_loss did not improve from 1.20057\n",
            "252/252 [==============================] - 91s 362ms/step - loss: 0.8647 - accuracy: 0.8223 - val_loss: 1.2509 - val_accuracy: 0.7232\n",
            "Epoch 25/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.8685 - accuracy: 0.8283\n",
            "Epoch 00025: val_loss improved from 1.20057 to 1.07317, saving model to /content/drive/My Drive/1-piece/Inception_ResnetV2_GrayScale.h5\n",
            "252/252 [==============================] - 96s 382ms/step - loss: 0.8685 - accuracy: 0.8283 - val_loss: 1.0732 - val_accuracy: 0.8125\n",
            "Epoch 26/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.8386 - accuracy: 0.8362\n",
            "Epoch 00026: val_loss did not improve from 1.07317\n",
            "252/252 [==============================] - 91s 363ms/step - loss: 0.8386 - accuracy: 0.8362 - val_loss: 1.1309 - val_accuracy: 0.7679\n",
            "Epoch 27/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.8330 - accuracy: 0.8342\n",
            "Epoch 00027: val_loss did not improve from 1.07317\n",
            "252/252 [==============================] - 91s 362ms/step - loss: 0.8330 - accuracy: 0.8342 - val_loss: 1.3025 - val_accuracy: 0.6964\n",
            "Epoch 28/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.8080 - accuracy: 0.8362\n",
            "Epoch 00028: val_loss did not improve from 1.07317\n",
            "252/252 [==============================] - 91s 362ms/step - loss: 0.8080 - accuracy: 0.8362 - val_loss: 1.1262 - val_accuracy: 0.7232\n",
            "Epoch 29/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.7866 - accuracy: 0.8412\n",
            "Epoch 00029: val_loss did not improve from 1.07317\n",
            "252/252 [==============================] - 91s 361ms/step - loss: 0.7866 - accuracy: 0.8412 - val_loss: 1.3273 - val_accuracy: 0.6875\n",
            "Epoch 30/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.7861 - accuracy: 0.8506\n",
            "Epoch 00030: val_loss did not improve from 1.07317\n",
            "252/252 [==============================] - 91s 362ms/step - loss: 0.7861 - accuracy: 0.8506 - val_loss: 1.0979 - val_accuracy: 0.7679\n",
            "Epoch 31/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.7559 - accuracy: 0.8541\n",
            "Epoch 00031: val_loss did not improve from 1.07317\n",
            "252/252 [==============================] - 89s 353ms/step - loss: 0.7559 - accuracy: 0.8541 - val_loss: 1.4040 - val_accuracy: 0.6964\n",
            "Epoch 32/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.7409 - accuracy: 0.8536\n",
            "Epoch 00032: val_loss improved from 1.07317 to 1.01934, saving model to /content/drive/My Drive/1-piece/Inception_ResnetV2_GrayScale.h5\n",
            "252/252 [==============================] - 95s 378ms/step - loss: 0.7409 - accuracy: 0.8536 - val_loss: 1.0193 - val_accuracy: 0.7589\n",
            "Epoch 33/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.7134 - accuracy: 0.8625\n",
            "Epoch 00033: val_loss did not improve from 1.01934\n",
            "252/252 [==============================] - 90s 358ms/step - loss: 0.7134 - accuracy: 0.8625 - val_loss: 1.0306 - val_accuracy: 0.7679\n",
            "Epoch 34/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.7098 - accuracy: 0.8725\n",
            "Epoch 00034: val_loss improved from 1.01934 to 0.98805, saving model to /content/drive/My Drive/1-piece/Inception_ResnetV2_GrayScale.h5\n",
            "252/252 [==============================] - 95s 379ms/step - loss: 0.7098 - accuracy: 0.8725 - val_loss: 0.9880 - val_accuracy: 0.7857\n",
            "Epoch 35/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.7279 - accuracy: 0.8620\n",
            "Epoch 00035: val_loss improved from 0.98805 to 0.81795, saving model to /content/drive/My Drive/1-piece/Inception_ResnetV2_GrayScale.h5\n",
            "252/252 [==============================] - 97s 383ms/step - loss: 0.7279 - accuracy: 0.8620 - val_loss: 0.8180 - val_accuracy: 0.8304\n",
            "Epoch 36/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.6690 - accuracy: 0.8809\n",
            "Epoch 00036: val_loss did not improve from 0.81795\n",
            "252/252 [==============================] - 92s 364ms/step - loss: 0.6690 - accuracy: 0.8809 - val_loss: 2.2236 - val_accuracy: 0.5536\n",
            "Epoch 37/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.6623 - accuracy: 0.8730\n",
            "Epoch 00037: val_loss did not improve from 0.81795\n",
            "252/252 [==============================] - 92s 364ms/step - loss: 0.6623 - accuracy: 0.8730 - val_loss: 1.2933 - val_accuracy: 0.6786\n",
            "Epoch 38/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.6553 - accuracy: 0.8849\n",
            "Epoch 00038: val_loss did not improve from 0.81795\n",
            "252/252 [==============================] - 89s 353ms/step - loss: 0.6553 - accuracy: 0.8849 - val_loss: 1.5367 - val_accuracy: 0.6696\n",
            "Epoch 39/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.6663 - accuracy: 0.8725\n",
            "Epoch 00039: val_loss did not improve from 0.81795\n",
            "252/252 [==============================] - 88s 350ms/step - loss: 0.6663 - accuracy: 0.8725 - val_loss: 1.8586 - val_accuracy: 0.6696\n",
            "Epoch 40/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.6531 - accuracy: 0.8744\n",
            "Epoch 00040: val_loss did not improve from 0.81795\n",
            "252/252 [==============================] - 89s 352ms/step - loss: 0.6531 - accuracy: 0.8744 - val_loss: 1.0513 - val_accuracy: 0.7857\n",
            "Epoch 41/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.5944 - accuracy: 0.9012\n",
            "Epoch 00041: val_loss did not improve from 0.81795\n",
            "252/252 [==============================] - 88s 351ms/step - loss: 0.5944 - accuracy: 0.9012 - val_loss: 1.1782 - val_accuracy: 0.7857\n",
            "Epoch 42/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.6100 - accuracy: 0.8943\n",
            "Epoch 00042: val_loss did not improve from 0.81795\n",
            "252/252 [==============================] - 88s 351ms/step - loss: 0.6100 - accuracy: 0.8943 - val_loss: 0.9304 - val_accuracy: 0.8393\n",
            "Epoch 43/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.6124 - accuracy: 0.8913\n",
            "Epoch 00043: val_loss did not improve from 0.81795\n",
            "252/252 [==============================] - 89s 352ms/step - loss: 0.6124 - accuracy: 0.8913 - val_loss: 1.1105 - val_accuracy: 0.7857\n",
            "Epoch 44/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.6012 - accuracy: 0.8908\n",
            "Epoch 00044: val_loss did not improve from 0.81795\n",
            "252/252 [==============================] - 89s 353ms/step - loss: 0.6012 - accuracy: 0.8908 - val_loss: 1.1954 - val_accuracy: 0.7679\n",
            "Epoch 45/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.6011 - accuracy: 0.8923\n",
            "Epoch 00045: val_loss improved from 0.81795 to 0.77518, saving model to /content/drive/My Drive/1-piece/Inception_ResnetV2_GrayScale.h5\n",
            "252/252 [==============================] - 94s 371ms/step - loss: 0.6011 - accuracy: 0.8923 - val_loss: 0.7752 - val_accuracy: 0.8125\n",
            "Epoch 46/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.6024 - accuracy: 0.8963\n",
            "Epoch 00046: val_loss did not improve from 0.77518\n",
            "252/252 [==============================] - 88s 351ms/step - loss: 0.6024 - accuracy: 0.8963 - val_loss: 2.6708 - val_accuracy: 0.4643\n",
            "Epoch 47/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.5771 - accuracy: 0.9037\n",
            "Epoch 00047: val_loss improved from 0.77518 to 0.72378, saving model to /content/drive/My Drive/1-piece/Inception_ResnetV2_GrayScale.h5\n",
            "252/252 [==============================] - 93s 368ms/step - loss: 0.5771 - accuracy: 0.9037 - val_loss: 0.7238 - val_accuracy: 0.8929\n",
            "Epoch 48/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.5552 - accuracy: 0.9117\n",
            "Epoch 00048: val_loss did not improve from 0.72378\n",
            "252/252 [==============================] - 89s 352ms/step - loss: 0.5552 - accuracy: 0.9117 - val_loss: 0.8320 - val_accuracy: 0.8125\n",
            "Epoch 49/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.5632 - accuracy: 0.9027\n",
            "Epoch 00049: val_loss did not improve from 0.72378\n",
            "252/252 [==============================] - 88s 348ms/step - loss: 0.5632 - accuracy: 0.9027 - val_loss: 0.8077 - val_accuracy: 0.8214\n",
            "Epoch 50/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.5461 - accuracy: 0.9122\n",
            "Epoch 00050: val_loss did not improve from 0.72378\n",
            "252/252 [==============================] - 88s 350ms/step - loss: 0.5461 - accuracy: 0.9122 - val_loss: 1.1517 - val_accuracy: 0.7500\n",
            "Epoch 51/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.5681 - accuracy: 0.9052\n",
            "Epoch 00051: val_loss did not improve from 0.72378\n",
            "252/252 [==============================] - 88s 349ms/step - loss: 0.5681 - accuracy: 0.9052 - val_loss: 0.9184 - val_accuracy: 0.8125\n",
            "Epoch 52/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.5383 - accuracy: 0.9087\n",
            "Epoch 00052: val_loss did not improve from 0.72378\n",
            "252/252 [==============================] - 88s 350ms/step - loss: 0.5383 - accuracy: 0.9087 - val_loss: 1.2409 - val_accuracy: 0.8125\n",
            "Epoch 53/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.5315 - accuracy: 0.9117\n",
            "Epoch 00053: val_loss did not improve from 0.72378\n",
            "252/252 [==============================] - 88s 347ms/step - loss: 0.5315 - accuracy: 0.9117 - val_loss: 1.1161 - val_accuracy: 0.7768\n",
            "Epoch 54/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.5177 - accuracy: 0.9161\n",
            "Epoch 00054: val_loss did not improve from 0.72378\n",
            "252/252 [==============================] - 88s 350ms/step - loss: 0.5177 - accuracy: 0.9161 - val_loss: 1.5748 - val_accuracy: 0.6875\n",
            "Epoch 55/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.5219 - accuracy: 0.9117\n",
            "Epoch 00055: val_loss did not improve from 0.72378\n",
            "252/252 [==============================] - 88s 348ms/step - loss: 0.5219 - accuracy: 0.9117 - val_loss: 0.8550 - val_accuracy: 0.8214\n",
            "Epoch 56/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.5470 - accuracy: 0.9072\n",
            "Epoch 00056: val_loss did not improve from 0.72378\n",
            "252/252 [==============================] - 87s 344ms/step - loss: 0.5470 - accuracy: 0.9072 - val_loss: 0.8950 - val_accuracy: 0.8214\n",
            "Epoch 57/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.4847 - accuracy: 0.9290\n",
            "Epoch 00057: val_loss improved from 0.72378 to 0.70061, saving model to /content/drive/My Drive/1-piece/Inception_ResnetV2_GrayScale.h5\n",
            "252/252 [==============================] - 93s 369ms/step - loss: 0.4847 - accuracy: 0.9290 - val_loss: 0.7006 - val_accuracy: 0.8661\n",
            "Epoch 58/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.4805 - accuracy: 0.9251\n",
            "Epoch 00058: val_loss did not improve from 0.70061\n",
            "252/252 [==============================] - 87s 346ms/step - loss: 0.4805 - accuracy: 0.9251 - val_loss: 4.3145 - val_accuracy: 0.5179\n",
            "Epoch 59/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.5201 - accuracy: 0.9107\n",
            "Epoch 00059: val_loss did not improve from 0.70061\n",
            "252/252 [==============================] - 87s 343ms/step - loss: 0.5201 - accuracy: 0.9107 - val_loss: 0.8366 - val_accuracy: 0.8125\n",
            "Epoch 60/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.5224 - accuracy: 0.9156\n",
            "Epoch 00060: val_loss did not improve from 0.70061\n",
            "252/252 [==============================] - 88s 349ms/step - loss: 0.5224 - accuracy: 0.9156 - val_loss: 0.7307 - val_accuracy: 0.8304\n",
            "Epoch 61/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.4966 - accuracy: 0.9270\n",
            "Epoch 00061: val_loss improved from 0.70061 to 0.60413, saving model to /content/drive/My Drive/1-piece/Inception_ResnetV2_GrayScale.h5\n",
            "252/252 [==============================] - 93s 370ms/step - loss: 0.4966 - accuracy: 0.9270 - val_loss: 0.6041 - val_accuracy: 0.9196\n",
            "Epoch 62/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.4619 - accuracy: 0.9295\n",
            "Epoch 00062: val_loss did not improve from 0.60413\n",
            "252/252 [==============================] - 88s 350ms/step - loss: 0.4619 - accuracy: 0.9295 - val_loss: 0.6559 - val_accuracy: 0.8304\n",
            "Epoch 63/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.4771 - accuracy: 0.9201\n",
            "Epoch 00063: val_loss did not improve from 0.60413\n",
            "252/252 [==============================] - 88s 348ms/step - loss: 0.4771 - accuracy: 0.9201 - val_loss: 0.6170 - val_accuracy: 0.8571\n",
            "Epoch 64/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.4733 - accuracy: 0.9280\n",
            "Epoch 00064: val_loss did not improve from 0.60413\n",
            "252/252 [==============================] - 88s 349ms/step - loss: 0.4733 - accuracy: 0.9280 - val_loss: 0.8761 - val_accuracy: 0.8571\n",
            "Epoch 65/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.4733 - accuracy: 0.9236\n",
            "Epoch 00065: val_loss did not improve from 0.60413\n",
            "252/252 [==============================] - 87s 344ms/step - loss: 0.4733 - accuracy: 0.9236 - val_loss: 0.8844 - val_accuracy: 0.8482\n",
            "Epoch 66/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.4903 - accuracy: 0.9231\n",
            "Epoch 00066: val_loss did not improve from 0.60413\n",
            "252/252 [==============================] - 85s 339ms/step - loss: 0.4903 - accuracy: 0.9231 - val_loss: 0.8222 - val_accuracy: 0.8393\n",
            "Epoch 67/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.5117 - accuracy: 0.9270\n",
            "Epoch 00067: val_loss did not improve from 0.60413\n",
            "252/252 [==============================] - 87s 347ms/step - loss: 0.5117 - accuracy: 0.9270 - val_loss: 0.6821 - val_accuracy: 0.8661\n",
            "Epoch 68/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.4784 - accuracy: 0.9295\n",
            "Epoch 00068: val_loss did not improve from 0.60413\n",
            "252/252 [==============================] - 90s 358ms/step - loss: 0.4784 - accuracy: 0.9295 - val_loss: 0.7408 - val_accuracy: 0.8661\n",
            "Epoch 69/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.4467 - accuracy: 0.9305\n",
            "Epoch 00069: val_loss did not improve from 0.60413\n",
            "252/252 [==============================] - 88s 349ms/step - loss: 0.4467 - accuracy: 0.9305 - val_loss: 0.6660 - val_accuracy: 0.8661\n",
            "Epoch 70/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.4396 - accuracy: 0.9365\n",
            "Epoch 00070: val_loss did not improve from 0.60413\n",
            "252/252 [==============================] - 88s 351ms/step - loss: 0.4396 - accuracy: 0.9365 - val_loss: 0.6906 - val_accuracy: 0.8571\n",
            "Epoch 71/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.4785 - accuracy: 0.9216\n",
            "Epoch 00071: val_loss did not improve from 0.60413\n",
            "252/252 [==============================] - 88s 350ms/step - loss: 0.4785 - accuracy: 0.9216 - val_loss: 0.7399 - val_accuracy: 0.8214\n",
            "Epoch 72/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.4462 - accuracy: 0.9390\n",
            "Epoch 00072: val_loss did not improve from 0.60413\n",
            "252/252 [==============================] - 88s 350ms/step - loss: 0.4462 - accuracy: 0.9390 - val_loss: 0.7103 - val_accuracy: 0.8661\n",
            "Epoch 73/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.4679 - accuracy: 0.9355\n",
            "Epoch 00073: val_loss did not improve from 0.60413\n",
            "252/252 [==============================] - 88s 351ms/step - loss: 0.4679 - accuracy: 0.9355 - val_loss: 0.6337 - val_accuracy: 0.8750\n",
            "Epoch 74/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.4888 - accuracy: 0.9221\n",
            "Epoch 00074: val_loss improved from 0.60413 to 0.59742, saving model to /content/drive/My Drive/1-piece/Inception_ResnetV2_GrayScale.h5\n",
            "252/252 [==============================] - 94s 373ms/step - loss: 0.4888 - accuracy: 0.9221 - val_loss: 0.5974 - val_accuracy: 0.8839\n",
            "Epoch 75/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.4349 - accuracy: 0.9404\n",
            "Epoch 00075: val_loss did not improve from 0.59742\n",
            "252/252 [==============================] - 90s 357ms/step - loss: 0.4349 - accuracy: 0.9404 - val_loss: 0.7414 - val_accuracy: 0.8661\n",
            "Epoch 76/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.4214 - accuracy: 0.9380\n",
            "Epoch 00076: val_loss did not improve from 0.59742\n",
            "252/252 [==============================] - 87s 345ms/step - loss: 0.4214 - accuracy: 0.9380 - val_loss: 0.8533 - val_accuracy: 0.8304\n",
            "Epoch 77/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.4502 - accuracy: 0.9285\n",
            "Epoch 00077: val_loss improved from 0.59742 to 0.59246, saving model to /content/drive/My Drive/1-piece/Inception_ResnetV2_GrayScale.h5\n",
            "252/252 [==============================] - 90s 359ms/step - loss: 0.4502 - accuracy: 0.9285 - val_loss: 0.5925 - val_accuracy: 0.8750\n",
            "Epoch 78/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.4062 - accuracy: 0.9414\n",
            "Epoch 00078: val_loss did not improve from 0.59246\n",
            "252/252 [==============================] - 86s 343ms/step - loss: 0.4062 - accuracy: 0.9414 - val_loss: 0.6651 - val_accuracy: 0.8482\n",
            "Epoch 79/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.4343 - accuracy: 0.9385\n",
            "Epoch 00079: val_loss did not improve from 0.59246\n",
            "252/252 [==============================] - 90s 356ms/step - loss: 0.4343 - accuracy: 0.9385 - val_loss: 1.0993 - val_accuracy: 0.7589\n",
            "Epoch 80/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.3949 - accuracy: 0.9524\n",
            "Epoch 00080: val_loss did not improve from 0.59246\n",
            "252/252 [==============================] - 90s 357ms/step - loss: 0.3949 - accuracy: 0.9524 - val_loss: 0.7641 - val_accuracy: 0.8571\n",
            "Epoch 81/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.4381 - accuracy: 0.9330\n",
            "Epoch 00081: val_loss did not improve from 0.59246\n",
            "252/252 [==============================] - 87s 347ms/step - loss: 0.4381 - accuracy: 0.9330 - val_loss: 0.6959 - val_accuracy: 0.8661\n",
            "Epoch 82/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.4132 - accuracy: 0.9469\n",
            "Epoch 00082: val_loss did not improve from 0.59246\n",
            "252/252 [==============================] - 88s 348ms/step - loss: 0.4132 - accuracy: 0.9469 - val_loss: 0.7338 - val_accuracy: 0.8393\n",
            "Epoch 83/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.4152 - accuracy: 0.9449\n",
            "Epoch 00083: val_loss did not improve from 0.59246\n",
            "252/252 [==============================] - 88s 347ms/step - loss: 0.4152 - accuracy: 0.9449 - val_loss: 0.9719 - val_accuracy: 0.8393\n",
            "Epoch 84/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.4192 - accuracy: 0.9360\n",
            "Epoch 00084: val_loss did not improve from 0.59246\n",
            "252/252 [==============================] - 87s 347ms/step - loss: 0.4192 - accuracy: 0.9360 - val_loss: 0.7028 - val_accuracy: 0.8839\n",
            "Epoch 85/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.4093 - accuracy: 0.9489\n",
            "Epoch 00085: val_loss did not improve from 0.59246\n",
            "252/252 [==============================] - 87s 347ms/step - loss: 0.4093 - accuracy: 0.9489 - val_loss: 0.7049 - val_accuracy: 0.8571\n",
            "Epoch 86/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.4049 - accuracy: 0.9479\n",
            "Epoch 00086: val_loss improved from 0.59246 to 0.55890, saving model to /content/drive/My Drive/1-piece/Inception_ResnetV2_GrayScale.h5\n",
            "252/252 [==============================] - 92s 366ms/step - loss: 0.4049 - accuracy: 0.9479 - val_loss: 0.5589 - val_accuracy: 0.8929\n",
            "Epoch 87/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.4007 - accuracy: 0.9538\n",
            "Epoch 00087: val_loss did not improve from 0.55890\n",
            "252/252 [==============================] - 88s 349ms/step - loss: 0.4007 - accuracy: 0.9538 - val_loss: 0.6391 - val_accuracy: 0.8929\n",
            "Epoch 88/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.4188 - accuracy: 0.9345\n",
            "Epoch 00088: val_loss did not improve from 0.55890\n",
            "252/252 [==============================] - 88s 348ms/step - loss: 0.4188 - accuracy: 0.9345 - val_loss: 0.5638 - val_accuracy: 0.9018\n",
            "Epoch 89/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.3948 - accuracy: 0.9469\n",
            "Epoch 00089: val_loss improved from 0.55890 to 0.55753, saving model to /content/drive/My Drive/1-piece/Inception_ResnetV2_GrayScale.h5\n",
            "252/252 [==============================] - 93s 369ms/step - loss: 0.3948 - accuracy: 0.9469 - val_loss: 0.5575 - val_accuracy: 0.8661\n",
            "Epoch 90/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.3847 - accuracy: 0.9533\n",
            "Epoch 00090: val_loss did not improve from 0.55753\n",
            "252/252 [==============================] - 86s 343ms/step - loss: 0.3847 - accuracy: 0.9533 - val_loss: 0.7485 - val_accuracy: 0.8393\n",
            "Epoch 91/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.3688 - accuracy: 0.9623\n",
            "Epoch 00091: val_loss did not improve from 0.55753\n",
            "252/252 [==============================] - 86s 343ms/step - loss: 0.3688 - accuracy: 0.9623 - val_loss: 0.6004 - val_accuracy: 0.9018\n",
            "Epoch 92/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.4015 - accuracy: 0.9429\n",
            "Epoch 00092: val_loss improved from 0.55753 to 0.54308, saving model to /content/drive/My Drive/1-piece/Inception_ResnetV2_GrayScale.h5\n",
            "252/252 [==============================] - 95s 379ms/step - loss: 0.4015 - accuracy: 0.9429 - val_loss: 0.5431 - val_accuracy: 0.9196\n",
            "Epoch 93/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.4068 - accuracy: 0.9489\n",
            "Epoch 00093: val_loss did not improve from 0.54308\n",
            "252/252 [==============================] - 88s 348ms/step - loss: 0.4068 - accuracy: 0.9489 - val_loss: 0.6439 - val_accuracy: 0.8661\n",
            "Epoch 94/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.3673 - accuracy: 0.9529\n",
            "Epoch 00094: val_loss improved from 0.54308 to 0.41023, saving model to /content/drive/My Drive/1-piece/Inception_ResnetV2_GrayScale.h5\n",
            "252/252 [==============================] - 92s 364ms/step - loss: 0.3673 - accuracy: 0.9529 - val_loss: 0.4102 - val_accuracy: 0.9196\n",
            "Epoch 95/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.4126 - accuracy: 0.9444\n",
            "Epoch 00095: val_loss did not improve from 0.41023\n",
            "252/252 [==============================] - 88s 349ms/step - loss: 0.4126 - accuracy: 0.9444 - val_loss: 0.5690 - val_accuracy: 0.9018\n",
            "Epoch 96/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.3950 - accuracy: 0.9499\n",
            "Epoch 00096: val_loss did not improve from 0.41023\n",
            "252/252 [==============================] - 89s 351ms/step - loss: 0.3950 - accuracy: 0.9499 - val_loss: 0.7164 - val_accuracy: 0.8750\n",
            "Epoch 97/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.4152 - accuracy: 0.9419\n",
            "Epoch 00097: val_loss did not improve from 0.41023\n",
            "252/252 [==============================] - 88s 349ms/step - loss: 0.4152 - accuracy: 0.9419 - val_loss: 0.6870 - val_accuracy: 0.8661\n",
            "Epoch 98/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.3872 - accuracy: 0.9548\n",
            "Epoch 00098: val_loss did not improve from 0.41023\n",
            "252/252 [==============================] - 87s 347ms/step - loss: 0.3872 - accuracy: 0.9548 - val_loss: 0.5218 - val_accuracy: 0.9107\n",
            "Epoch 99/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.3655 - accuracy: 0.9583\n",
            "Epoch 00099: val_loss did not improve from 0.41023\n",
            "252/252 [==============================] - 88s 348ms/step - loss: 0.3655 - accuracy: 0.9583 - val_loss: 0.6295 - val_accuracy: 0.8929\n",
            "Epoch 100/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.3517 - accuracy: 0.9578\n",
            "Epoch 00100: val_loss did not improve from 0.41023\n",
            "252/252 [==============================] - 88s 349ms/step - loss: 0.3517 - accuracy: 0.9578 - val_loss: 0.4779 - val_accuracy: 0.9196\n",
            "Epoch 101/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.3484 - accuracy: 0.9623\n",
            "Epoch 00101: val_loss did not improve from 0.41023\n",
            "252/252 [==============================] - 86s 342ms/step - loss: 0.3484 - accuracy: 0.9623 - val_loss: 0.5037 - val_accuracy: 0.9107\n",
            "Epoch 102/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.3437 - accuracy: 0.9578\n",
            "Epoch 00102: val_loss did not improve from 0.41023\n",
            "252/252 [==============================] - 86s 341ms/step - loss: 0.3437 - accuracy: 0.9578 - val_loss: 0.6893 - val_accuracy: 0.8661\n",
            "Epoch 103/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.3674 - accuracy: 0.9509\n",
            "Epoch 00103: val_loss did not improve from 0.41023\n",
            "252/252 [==============================] - 86s 343ms/step - loss: 0.3674 - accuracy: 0.9509 - val_loss: 0.7580 - val_accuracy: 0.8482\n",
            "Epoch 104/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.3810 - accuracy: 0.9509\n",
            "Epoch 00104: val_loss did not improve from 0.41023\n",
            "252/252 [==============================] - 86s 341ms/step - loss: 0.3810 - accuracy: 0.9509 - val_loss: 0.5943 - val_accuracy: 0.8661\n",
            "Epoch 105/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.3720 - accuracy: 0.9509\n",
            "Epoch 00105: val_loss did not improve from 0.41023\n",
            "252/252 [==============================] - 86s 340ms/step - loss: 0.3720 - accuracy: 0.9509 - val_loss: 0.5696 - val_accuracy: 0.8661\n",
            "Epoch 106/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.3735 - accuracy: 0.9474\n",
            "Epoch 00106: val_loss did not improve from 0.41023\n",
            "252/252 [==============================] - 86s 342ms/step - loss: 0.3735 - accuracy: 0.9474 - val_loss: 0.6663 - val_accuracy: 0.8393\n",
            "Epoch 107/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.3859 - accuracy: 0.9479\n",
            "Epoch 00107: val_loss did not improve from 0.41023\n",
            "252/252 [==============================] - 85s 338ms/step - loss: 0.3859 - accuracy: 0.9479 - val_loss: 0.7261 - val_accuracy: 0.8571\n",
            "Epoch 108/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.3966 - accuracy: 0.9484\n",
            "Epoch 00108: val_loss did not improve from 0.41023\n",
            "252/252 [==============================] - 85s 338ms/step - loss: 0.3966 - accuracy: 0.9484 - val_loss: 0.7037 - val_accuracy: 0.8661\n",
            "Epoch 109/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.3239 - accuracy: 0.9682\n",
            "Epoch 00109: val_loss did not improve from 0.41023\n",
            "252/252 [==============================] - 85s 339ms/step - loss: 0.3239 - accuracy: 0.9682 - val_loss: 0.5268 - val_accuracy: 0.8839\n",
            "Epoch 110/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.3714 - accuracy: 0.9529\n",
            "Epoch 00110: val_loss did not improve from 0.41023\n",
            "252/252 [==============================] - 86s 340ms/step - loss: 0.3714 - accuracy: 0.9529 - val_loss: 0.5715 - val_accuracy: 0.9018\n",
            "Epoch 111/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.3263 - accuracy: 0.9633\n",
            "Epoch 00111: val_loss did not improve from 0.41023\n",
            "252/252 [==============================] - 85s 338ms/step - loss: 0.3263 - accuracy: 0.9633 - val_loss: 0.4489 - val_accuracy: 0.9196\n",
            "Epoch 112/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.3203 - accuracy: 0.9633\n",
            "Epoch 00112: val_loss did not improve from 0.41023\n",
            "252/252 [==============================] - 85s 338ms/step - loss: 0.3203 - accuracy: 0.9633 - val_loss: 0.5329 - val_accuracy: 0.8839\n",
            "Epoch 113/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.3599 - accuracy: 0.9543\n",
            "Epoch 00113: val_loss did not improve from 0.41023\n",
            "252/252 [==============================] - 85s 339ms/step - loss: 0.3599 - accuracy: 0.9543 - val_loss: 0.6758 - val_accuracy: 0.8750\n",
            "Epoch 114/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.3394 - accuracy: 0.9603\n",
            "Epoch 00114: val_loss did not improve from 0.41023\n",
            "252/252 [==============================] - 86s 341ms/step - loss: 0.3394 - accuracy: 0.9603 - val_loss: 0.5627 - val_accuracy: 0.9107\n",
            "Epoch 115/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.3615 - accuracy: 0.9553\n",
            "Epoch 00115: val_loss did not improve from 0.41023\n",
            "252/252 [==============================] - 85s 338ms/step - loss: 0.3615 - accuracy: 0.9553 - val_loss: 0.5219 - val_accuracy: 0.9107\n",
            "Epoch 116/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.3382 - accuracy: 0.9588\n",
            "Epoch 00116: val_loss did not improve from 0.41023\n",
            "252/252 [==============================] - 85s 338ms/step - loss: 0.3382 - accuracy: 0.9588 - val_loss: 0.4509 - val_accuracy: 0.9018\n",
            "Epoch 117/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.3273 - accuracy: 0.9608\n",
            "Epoch 00117: val_loss did not improve from 0.41023\n",
            "252/252 [==============================] - 86s 340ms/step - loss: 0.3273 - accuracy: 0.9608 - val_loss: 2.0516 - val_accuracy: 0.6429\n",
            "Epoch 118/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.3498 - accuracy: 0.9484\n",
            "Epoch 00118: val_loss did not improve from 0.41023\n",
            "252/252 [==============================] - 85s 338ms/step - loss: 0.3498 - accuracy: 0.9484 - val_loss: 0.7143 - val_accuracy: 0.8661\n",
            "Epoch 119/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.3547 - accuracy: 0.9568\n",
            "Epoch 00119: val_loss did not improve from 0.41023\n",
            "252/252 [==============================] - 85s 338ms/step - loss: 0.3547 - accuracy: 0.9568 - val_loss: 0.4585 - val_accuracy: 0.9107\n",
            "Epoch 120/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.3222 - accuracy: 0.9667\n",
            "Epoch 00120: val_loss did not improve from 0.41023\n",
            "252/252 [==============================] - 85s 338ms/step - loss: 0.3222 - accuracy: 0.9667 - val_loss: 0.5557 - val_accuracy: 0.8929\n",
            "Epoch 121/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.3230 - accuracy: 0.9667\n",
            "Epoch 00121: val_loss did not improve from 0.41023\n",
            "252/252 [==============================] - 86s 341ms/step - loss: 0.3230 - accuracy: 0.9667 - val_loss: 0.4823 - val_accuracy: 0.8929\n",
            "Epoch 122/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.3223 - accuracy: 0.9578\n",
            "Epoch 00122: val_loss improved from 0.41023 to 0.40680, saving model to /content/drive/My Drive/1-piece/Inception_ResnetV2_GrayScale.h5\n",
            "252/252 [==============================] - 91s 360ms/step - loss: 0.3223 - accuracy: 0.9578 - val_loss: 0.4068 - val_accuracy: 0.9286\n",
            "Epoch 123/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.3203 - accuracy: 0.9588\n",
            "Epoch 00123: val_loss did not improve from 0.40680\n",
            "252/252 [==============================] - 89s 352ms/step - loss: 0.3203 - accuracy: 0.9588 - val_loss: 0.6666 - val_accuracy: 0.8750\n",
            "Epoch 124/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.3449 - accuracy: 0.9553\n",
            "Epoch 00124: val_loss did not improve from 0.40680\n",
            "252/252 [==============================] - 89s 354ms/step - loss: 0.3449 - accuracy: 0.9553 - val_loss: 0.6200 - val_accuracy: 0.8929\n",
            "Epoch 125/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.3143 - accuracy: 0.9672\n",
            "Epoch 00125: val_loss did not improve from 0.40680\n",
            "252/252 [==============================] - 87s 345ms/step - loss: 0.3143 - accuracy: 0.9672 - val_loss: 0.4908 - val_accuracy: 0.8929\n",
            "Epoch 126/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.3362 - accuracy: 0.9603\n",
            "Epoch 00126: val_loss did not improve from 0.40680\n",
            "252/252 [==============================] - 87s 345ms/step - loss: 0.3362 - accuracy: 0.9603 - val_loss: 0.4357 - val_accuracy: 0.9375\n",
            "Epoch 127/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.3233 - accuracy: 0.9633\n",
            "Epoch 00127: val_loss improved from 0.40680 to 0.38947, saving model to /content/drive/My Drive/1-piece/Inception_ResnetV2_GrayScale.h5\n",
            "252/252 [==============================] - 91s 362ms/step - loss: 0.3233 - accuracy: 0.9633 - val_loss: 0.3895 - val_accuracy: 0.9107\n",
            "Epoch 128/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.3131 - accuracy: 0.9667\n",
            "Epoch 00128: val_loss did not improve from 0.38947\n",
            "252/252 [==============================] - 88s 350ms/step - loss: 0.3131 - accuracy: 0.9667 - val_loss: 0.4277 - val_accuracy: 0.9107\n",
            "Epoch 129/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.3251 - accuracy: 0.9593\n",
            "Epoch 00129: val_loss did not improve from 0.38947\n",
            "252/252 [==============================] - 87s 345ms/step - loss: 0.3251 - accuracy: 0.9593 - val_loss: 0.4385 - val_accuracy: 0.9196\n",
            "Epoch 130/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.3325 - accuracy: 0.9628\n",
            "Epoch 00130: val_loss did not improve from 0.38947\n",
            "252/252 [==============================] - 87s 345ms/step - loss: 0.3325 - accuracy: 0.9628 - val_loss: 0.4584 - val_accuracy: 0.9375\n",
            "Epoch 131/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.3143 - accuracy: 0.9667\n",
            "Epoch 00131: val_loss did not improve from 0.38947\n",
            "252/252 [==============================] - 87s 347ms/step - loss: 0.3143 - accuracy: 0.9667 - val_loss: 0.5286 - val_accuracy: 0.9018\n",
            "Epoch 132/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.3325 - accuracy: 0.9663\n",
            "Epoch 00132: val_loss did not improve from 0.38947\n",
            "252/252 [==============================] - 87s 346ms/step - loss: 0.3325 - accuracy: 0.9663 - val_loss: 0.4981 - val_accuracy: 0.8929\n",
            "Epoch 133/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.3158 - accuracy: 0.9638\n",
            "Epoch 00133: val_loss did not improve from 0.38947\n",
            "252/252 [==============================] - 87s 345ms/step - loss: 0.3158 - accuracy: 0.9638 - val_loss: 0.4955 - val_accuracy: 0.9196\n",
            "Epoch 134/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.3202 - accuracy: 0.9663\n",
            "Epoch 00134: val_loss did not improve from 0.38947\n",
            "252/252 [==============================] - 87s 345ms/step - loss: 0.3202 - accuracy: 0.9663 - val_loss: 0.4411 - val_accuracy: 0.9196\n",
            "Epoch 135/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.3081 - accuracy: 0.9658\n",
            "Epoch 00135: val_loss did not improve from 0.38947\n",
            "252/252 [==============================] - 87s 347ms/step - loss: 0.3081 - accuracy: 0.9658 - val_loss: 0.4046 - val_accuracy: 0.9286\n",
            "Epoch 136/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.3068 - accuracy: 0.9618\n",
            "Epoch 00136: val_loss did not improve from 0.38947\n",
            "252/252 [==============================] - 87s 344ms/step - loss: 0.3068 - accuracy: 0.9618 - val_loss: 0.5243 - val_accuracy: 0.8839\n",
            "Epoch 137/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.3128 - accuracy: 0.9618\n",
            "Epoch 00137: val_loss did not improve from 0.38947\n",
            "252/252 [==============================] - 87s 344ms/step - loss: 0.3128 - accuracy: 0.9618 - val_loss: 0.4458 - val_accuracy: 0.9107\n",
            "Epoch 138/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.3233 - accuracy: 0.9618\n",
            "Epoch 00138: val_loss did not improve from 0.38947\n",
            "252/252 [==============================] - 87s 345ms/step - loss: 0.3233 - accuracy: 0.9618 - val_loss: 0.4213 - val_accuracy: 0.9286\n",
            "Epoch 139/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.3092 - accuracy: 0.9648\n",
            "Epoch 00139: val_loss did not improve from 0.38947\n",
            "252/252 [==============================] - 87s 346ms/step - loss: 0.3092 - accuracy: 0.9648 - val_loss: 0.5015 - val_accuracy: 0.9018\n",
            "Epoch 140/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.3109 - accuracy: 0.9643\n",
            "Epoch 00140: val_loss did not improve from 0.38947\n",
            "252/252 [==============================] - 87s 344ms/step - loss: 0.3109 - accuracy: 0.9643 - val_loss: 0.5248 - val_accuracy: 0.8929\n",
            "Epoch 141/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.3063 - accuracy: 0.9658\n",
            "Epoch 00141: val_loss did not improve from 0.38947\n",
            "252/252 [==============================] - 87s 347ms/step - loss: 0.3063 - accuracy: 0.9658 - val_loss: 0.5385 - val_accuracy: 0.9018\n",
            "Epoch 142/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.3026 - accuracy: 0.9722\n",
            "Epoch 00142: val_loss did not improve from 0.38947\n",
            "252/252 [==============================] - 88s 348ms/step - loss: 0.3026 - accuracy: 0.9722 - val_loss: 0.6927 - val_accuracy: 0.8929\n",
            "Epoch 143/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.3258 - accuracy: 0.9618\n",
            "Epoch 00143: val_loss did not improve from 0.38947\n",
            "252/252 [==============================] - 87s 344ms/step - loss: 0.3258 - accuracy: 0.9618 - val_loss: 0.5864 - val_accuracy: 0.9018\n",
            "Epoch 144/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.3255 - accuracy: 0.9628\n",
            "Epoch 00144: val_loss did not improve from 0.38947\n",
            "252/252 [==============================] - 86s 343ms/step - loss: 0.3255 - accuracy: 0.9628 - val_loss: 0.5877 - val_accuracy: 0.8929\n",
            "Epoch 145/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.2780 - accuracy: 0.9782\n",
            "Epoch 00145: val_loss improved from 0.38947 to 0.37414, saving model to /content/drive/My Drive/1-piece/Inception_ResnetV2_GrayScale.h5\n",
            "252/252 [==============================] - 93s 367ms/step - loss: 0.2780 - accuracy: 0.9782 - val_loss: 0.3741 - val_accuracy: 0.9554\n",
            "Epoch 146/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.3007 - accuracy: 0.9677\n",
            "Epoch 00146: val_loss did not improve from 0.37414\n",
            "252/252 [==============================] - 88s 350ms/step - loss: 0.3007 - accuracy: 0.9677 - val_loss: 0.4530 - val_accuracy: 0.9286\n",
            "Epoch 147/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.3012 - accuracy: 0.9667\n",
            "Epoch 00147: val_loss did not improve from 0.37414\n",
            "252/252 [==============================] - 87s 345ms/step - loss: 0.3012 - accuracy: 0.9667 - val_loss: 0.4893 - val_accuracy: 0.9107\n",
            "Epoch 148/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.2996 - accuracy: 0.9682\n",
            "Epoch 00148: val_loss did not improve from 0.37414\n",
            "252/252 [==============================] - 87s 346ms/step - loss: 0.2996 - accuracy: 0.9682 - val_loss: 0.5218 - val_accuracy: 0.8929\n",
            "Epoch 149/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.3026 - accuracy: 0.9672\n",
            "Epoch 00149: val_loss did not improve from 0.37414\n",
            "252/252 [==============================] - 88s 348ms/step - loss: 0.3026 - accuracy: 0.9672 - val_loss: 0.4113 - val_accuracy: 0.9464\n",
            "Epoch 150/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.2870 - accuracy: 0.9737\n",
            "Epoch 00150: val_loss did not improve from 0.37414\n",
            "252/252 [==============================] - 87s 345ms/step - loss: 0.2870 - accuracy: 0.9737 - val_loss: 0.4216 - val_accuracy: 0.9286\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yOPu_IUM8Pl0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "5ea45408-ef42-4374-98b3-80559053fde3"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(hist.history[\"accuracy\"])\n",
        "plt.plot(hist.history['val_accuracy'])\n",
        "plt.title(\"model accuracy\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.legend([\"Accuracy\",\"Validation Accuracy\"])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tOCNL9oW8TaP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "1651fd3a-5728-4a37-f80a-c105a5e79cfd"
      },
      "source": [
        "plt.plot(hist.history['loss'])\n",
        "plt.plot(hist.history['val_loss'])\n",
        "plt.title(\"model Loss\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.legend([\"Loss\",\"Validation Loss\"])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4KDTBLb8WAw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e3c61efd-2fa7-46a5-a541-50531db62aa6"
      },
      "source": [
        "GreyTestData = TestGenerator.flow_from_directory('/content/drive/My Drive/1-piece/Test/', target_size=(224,224), batch_size = 8, shuffle = False, color_mode='grayscale')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 112 images belonging to 112 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5IHoWvG8ZSE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Grey_predict = model.predict(GreyTestData)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1s-tRf1X8bXg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Grey_predict_classes = np.argmax(Grey_predict, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSkMj7ZF8dSi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "3ea59e5c-dcd1-4c1d-f8dc-39e57a697fc0"
      },
      "source": [
        "Grey_predict_classes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  0,   1,   1,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
              "        14,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
              "        29,  27,  17,  29,  30,  31,  32,  33,  32,  35,  36,  37,  38,\n",
              "        39,  40,  41,  42,  43,  44,  52,  46,  48,  48,  49,  50,  51,\n",
              "        52,  53,  54,  54,  56,  57,  58,  59,  60,  61,  51,  63,  64,\n",
              "        65,  66,  67,  68,  69,  70,  71, 110,  73,  74,  75,  76,  77,\n",
              "        75,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
              "        91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
              "       104, 105, 106, 107, 108, 109, 110, 111])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WR5JjoUf8fO2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "from sklearn.metrics import roc_auc_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QPdBV1ie8h2Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e8c609a7-c122-4c13-bf92-8cdcc729dd28"
      },
      "source": [
        "Grey_accuracy = accuracy_score(GreyTestData.classes, Grey_predict_classes)\n",
        "print(\"Grey Accuracy: \", Grey_accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Grey Accuracy:  0.9017857142857143\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7NiliKD18jqU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "d7b91673-1437-47a2-d617-2eec10e6e66e"
      },
      "source": [
        "Grey_precision = precision_score(GreyTestData.classes, Grey_predict_classes,average=\"weighted\")\n",
        "print(\"Grey Precision: \", Grey_precision)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Grey Precision:  0.8526785714285714\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3jL4TNW8mPr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a84a5061-4185-4a6e-9165-627981859cb7"
      },
      "source": [
        "Grey_recall = recall_score(GreyTestData.classes, Grey_predict_classes, average=\"weighted\")\n",
        "print(\"Grey Recall:\", Grey_recall)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Grey Recall: 0.9017857142857143\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7DmNdV88o7H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "71f6d546-4722-410e-f09c-6945e649a5fa"
      },
      "source": [
        "Grey_f1_score = f1_score(GreyTestData.classes, Grey_predict_classes, average=\"weighted\")\n",
        "print(\"F1 score for Grey: \", Grey_f1_score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 score for Grey:  0.8690476190476192\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1E2CI9V8rK6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f1bddf11-12ff-4b81-9098-3d455d51465b"
      },
      "source": [
        "Colour_TrainingData =  DataGenerator.flow_from_directory('/content/drive/My Drive/1-piece/Train/', target_size=(224,224), batch_size=8)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2015 images belonging to 112 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cm6wcs9_8xNl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a053db37-5a67-4760-d3a2-6f5d126ae51b"
      },
      "source": [
        "Colour_ValidData =  DataGenerator.flow_from_directory('/content/drive/My Drive/1-piece/Valid/', target_size=(224,224), batch_size=8)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 112 images belonging to 112 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRoP3DQE81Bn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "conv_base_colour = InceptionResNetV2(weights = 'imagenet', include_top = False, pooling = 'avg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iw3YDI5w9HoA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for layer in conv_base.layers[:765]:\n",
        "  layer.trainable = False\n",
        "for layer in conv_base.layers[765:]:\n",
        "  layer.trainable = True\n",
        "for layer in conv_base.layers:\n",
        "  if isinstance(layer, BatchNormalization):\n",
        "    layer.trainable = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tTSM8DzJ9xsf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4def3c28-57b3-401d-b7a7-c896202f549c"
      },
      "source": [
        "for i, layer in enumerate(conv_base.layers):\n",
        "  print(i, layer.name, layer.trainable)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 input_1 False\n",
            "1 conv2d False\n",
            "2 batch_normalization True\n",
            "3 activation False\n",
            "4 conv2d_1 False\n",
            "5 batch_normalization_1 True\n",
            "6 activation_1 False\n",
            "7 conv2d_2 False\n",
            "8 batch_normalization_2 True\n",
            "9 activation_2 False\n",
            "10 max_pooling2d False\n",
            "11 conv2d_3 False\n",
            "12 batch_normalization_3 True\n",
            "13 activation_3 False\n",
            "14 conv2d_4 False\n",
            "15 batch_normalization_4 True\n",
            "16 activation_4 False\n",
            "17 max_pooling2d_1 False\n",
            "18 conv2d_8 False\n",
            "19 batch_normalization_8 True\n",
            "20 activation_8 False\n",
            "21 conv2d_6 False\n",
            "22 conv2d_9 False\n",
            "23 batch_normalization_6 True\n",
            "24 batch_normalization_9 True\n",
            "25 activation_6 False\n",
            "26 activation_9 False\n",
            "27 average_pooling2d False\n",
            "28 conv2d_5 False\n",
            "29 conv2d_7 False\n",
            "30 conv2d_10 False\n",
            "31 conv2d_11 False\n",
            "32 batch_normalization_5 True\n",
            "33 batch_normalization_7 True\n",
            "34 batch_normalization_10 True\n",
            "35 batch_normalization_11 True\n",
            "36 activation_5 False\n",
            "37 activation_7 False\n",
            "38 activation_10 False\n",
            "39 activation_11 False\n",
            "40 mixed_5b False\n",
            "41 conv2d_15 False\n",
            "42 batch_normalization_15 True\n",
            "43 activation_15 False\n",
            "44 conv2d_13 False\n",
            "45 conv2d_16 False\n",
            "46 batch_normalization_13 True\n",
            "47 batch_normalization_16 True\n",
            "48 activation_13 False\n",
            "49 activation_16 False\n",
            "50 conv2d_12 False\n",
            "51 conv2d_14 False\n",
            "52 conv2d_17 False\n",
            "53 batch_normalization_12 True\n",
            "54 batch_normalization_14 True\n",
            "55 batch_normalization_17 True\n",
            "56 activation_12 False\n",
            "57 activation_14 False\n",
            "58 activation_17 False\n",
            "59 block35_1_mixed False\n",
            "60 block35_1_conv False\n",
            "61 block35_1 False\n",
            "62 block35_1_ac False\n",
            "63 conv2d_21 False\n",
            "64 batch_normalization_21 True\n",
            "65 activation_21 False\n",
            "66 conv2d_19 False\n",
            "67 conv2d_22 False\n",
            "68 batch_normalization_19 True\n",
            "69 batch_normalization_22 True\n",
            "70 activation_19 False\n",
            "71 activation_22 False\n",
            "72 conv2d_18 False\n",
            "73 conv2d_20 False\n",
            "74 conv2d_23 False\n",
            "75 batch_normalization_18 True\n",
            "76 batch_normalization_20 True\n",
            "77 batch_normalization_23 True\n",
            "78 activation_18 False\n",
            "79 activation_20 False\n",
            "80 activation_23 False\n",
            "81 block35_2_mixed False\n",
            "82 block35_2_conv False\n",
            "83 block35_2 False\n",
            "84 block35_2_ac False\n",
            "85 conv2d_27 False\n",
            "86 batch_normalization_27 True\n",
            "87 activation_27 False\n",
            "88 conv2d_25 False\n",
            "89 conv2d_28 False\n",
            "90 batch_normalization_25 True\n",
            "91 batch_normalization_28 True\n",
            "92 activation_25 False\n",
            "93 activation_28 False\n",
            "94 conv2d_24 False\n",
            "95 conv2d_26 False\n",
            "96 conv2d_29 False\n",
            "97 batch_normalization_24 True\n",
            "98 batch_normalization_26 True\n",
            "99 batch_normalization_29 True\n",
            "100 activation_24 False\n",
            "101 activation_26 False\n",
            "102 activation_29 False\n",
            "103 block35_3_mixed False\n",
            "104 block35_3_conv False\n",
            "105 block35_3 False\n",
            "106 block35_3_ac False\n",
            "107 conv2d_33 False\n",
            "108 batch_normalization_33 True\n",
            "109 activation_33 False\n",
            "110 conv2d_31 False\n",
            "111 conv2d_34 False\n",
            "112 batch_normalization_31 True\n",
            "113 batch_normalization_34 True\n",
            "114 activation_31 False\n",
            "115 activation_34 False\n",
            "116 conv2d_30 False\n",
            "117 conv2d_32 False\n",
            "118 conv2d_35 False\n",
            "119 batch_normalization_30 True\n",
            "120 batch_normalization_32 True\n",
            "121 batch_normalization_35 True\n",
            "122 activation_30 False\n",
            "123 activation_32 False\n",
            "124 activation_35 False\n",
            "125 block35_4_mixed False\n",
            "126 block35_4_conv False\n",
            "127 block35_4 False\n",
            "128 block35_4_ac False\n",
            "129 conv2d_39 False\n",
            "130 batch_normalization_39 True\n",
            "131 activation_39 False\n",
            "132 conv2d_37 False\n",
            "133 conv2d_40 False\n",
            "134 batch_normalization_37 True\n",
            "135 batch_normalization_40 True\n",
            "136 activation_37 False\n",
            "137 activation_40 False\n",
            "138 conv2d_36 False\n",
            "139 conv2d_38 False\n",
            "140 conv2d_41 False\n",
            "141 batch_normalization_36 True\n",
            "142 batch_normalization_38 True\n",
            "143 batch_normalization_41 True\n",
            "144 activation_36 False\n",
            "145 activation_38 False\n",
            "146 activation_41 False\n",
            "147 block35_5_mixed False\n",
            "148 block35_5_conv False\n",
            "149 block35_5 False\n",
            "150 block35_5_ac False\n",
            "151 conv2d_45 False\n",
            "152 batch_normalization_45 True\n",
            "153 activation_45 False\n",
            "154 conv2d_43 False\n",
            "155 conv2d_46 False\n",
            "156 batch_normalization_43 True\n",
            "157 batch_normalization_46 True\n",
            "158 activation_43 False\n",
            "159 activation_46 False\n",
            "160 conv2d_42 False\n",
            "161 conv2d_44 False\n",
            "162 conv2d_47 False\n",
            "163 batch_normalization_42 True\n",
            "164 batch_normalization_44 True\n",
            "165 batch_normalization_47 True\n",
            "166 activation_42 False\n",
            "167 activation_44 False\n",
            "168 activation_47 False\n",
            "169 block35_6_mixed False\n",
            "170 block35_6_conv False\n",
            "171 block35_6 False\n",
            "172 block35_6_ac False\n",
            "173 conv2d_51 False\n",
            "174 batch_normalization_51 True\n",
            "175 activation_51 False\n",
            "176 conv2d_49 False\n",
            "177 conv2d_52 False\n",
            "178 batch_normalization_49 True\n",
            "179 batch_normalization_52 True\n",
            "180 activation_49 False\n",
            "181 activation_52 False\n",
            "182 conv2d_48 False\n",
            "183 conv2d_50 False\n",
            "184 conv2d_53 False\n",
            "185 batch_normalization_48 True\n",
            "186 batch_normalization_50 True\n",
            "187 batch_normalization_53 True\n",
            "188 activation_48 False\n",
            "189 activation_50 False\n",
            "190 activation_53 False\n",
            "191 block35_7_mixed False\n",
            "192 block35_7_conv False\n",
            "193 block35_7 False\n",
            "194 block35_7_ac False\n",
            "195 conv2d_57 False\n",
            "196 batch_normalization_57 True\n",
            "197 activation_57 False\n",
            "198 conv2d_55 False\n",
            "199 conv2d_58 False\n",
            "200 batch_normalization_55 True\n",
            "201 batch_normalization_58 True\n",
            "202 activation_55 False\n",
            "203 activation_58 False\n",
            "204 conv2d_54 False\n",
            "205 conv2d_56 False\n",
            "206 conv2d_59 False\n",
            "207 batch_normalization_54 True\n",
            "208 batch_normalization_56 True\n",
            "209 batch_normalization_59 True\n",
            "210 activation_54 False\n",
            "211 activation_56 False\n",
            "212 activation_59 False\n",
            "213 block35_8_mixed False\n",
            "214 block35_8_conv False\n",
            "215 block35_8 False\n",
            "216 block35_8_ac False\n",
            "217 conv2d_63 False\n",
            "218 batch_normalization_63 True\n",
            "219 activation_63 False\n",
            "220 conv2d_61 False\n",
            "221 conv2d_64 False\n",
            "222 batch_normalization_61 True\n",
            "223 batch_normalization_64 True\n",
            "224 activation_61 False\n",
            "225 activation_64 False\n",
            "226 conv2d_60 False\n",
            "227 conv2d_62 False\n",
            "228 conv2d_65 False\n",
            "229 batch_normalization_60 True\n",
            "230 batch_normalization_62 True\n",
            "231 batch_normalization_65 True\n",
            "232 activation_60 False\n",
            "233 activation_62 False\n",
            "234 activation_65 False\n",
            "235 block35_9_mixed False\n",
            "236 block35_9_conv False\n",
            "237 block35_9 False\n",
            "238 block35_9_ac False\n",
            "239 conv2d_69 False\n",
            "240 batch_normalization_69 True\n",
            "241 activation_69 False\n",
            "242 conv2d_67 False\n",
            "243 conv2d_70 False\n",
            "244 batch_normalization_67 True\n",
            "245 batch_normalization_70 True\n",
            "246 activation_67 False\n",
            "247 activation_70 False\n",
            "248 conv2d_66 False\n",
            "249 conv2d_68 False\n",
            "250 conv2d_71 False\n",
            "251 batch_normalization_66 True\n",
            "252 batch_normalization_68 True\n",
            "253 batch_normalization_71 True\n",
            "254 activation_66 False\n",
            "255 activation_68 False\n",
            "256 activation_71 False\n",
            "257 block35_10_mixed False\n",
            "258 block35_10_conv False\n",
            "259 block35_10 False\n",
            "260 block35_10_ac False\n",
            "261 conv2d_73 False\n",
            "262 batch_normalization_73 True\n",
            "263 activation_73 False\n",
            "264 conv2d_74 False\n",
            "265 batch_normalization_74 True\n",
            "266 activation_74 False\n",
            "267 conv2d_72 False\n",
            "268 conv2d_75 False\n",
            "269 batch_normalization_72 True\n",
            "270 batch_normalization_75 True\n",
            "271 activation_72 False\n",
            "272 activation_75 False\n",
            "273 max_pooling2d_2 False\n",
            "274 mixed_6a False\n",
            "275 conv2d_77 False\n",
            "276 batch_normalization_77 True\n",
            "277 activation_77 False\n",
            "278 conv2d_78 False\n",
            "279 batch_normalization_78 True\n",
            "280 activation_78 False\n",
            "281 conv2d_76 False\n",
            "282 conv2d_79 False\n",
            "283 batch_normalization_76 True\n",
            "284 batch_normalization_79 True\n",
            "285 activation_76 False\n",
            "286 activation_79 False\n",
            "287 block17_1_mixed False\n",
            "288 block17_1_conv False\n",
            "289 block17_1 False\n",
            "290 block17_1_ac False\n",
            "291 conv2d_81 False\n",
            "292 batch_normalization_81 True\n",
            "293 activation_81 False\n",
            "294 conv2d_82 False\n",
            "295 batch_normalization_82 True\n",
            "296 activation_82 False\n",
            "297 conv2d_80 False\n",
            "298 conv2d_83 False\n",
            "299 batch_normalization_80 True\n",
            "300 batch_normalization_83 True\n",
            "301 activation_80 False\n",
            "302 activation_83 False\n",
            "303 block17_2_mixed False\n",
            "304 block17_2_conv False\n",
            "305 block17_2 False\n",
            "306 block17_2_ac False\n",
            "307 conv2d_85 False\n",
            "308 batch_normalization_85 True\n",
            "309 activation_85 False\n",
            "310 conv2d_86 False\n",
            "311 batch_normalization_86 True\n",
            "312 activation_86 False\n",
            "313 conv2d_84 False\n",
            "314 conv2d_87 False\n",
            "315 batch_normalization_84 True\n",
            "316 batch_normalization_87 True\n",
            "317 activation_84 False\n",
            "318 activation_87 False\n",
            "319 block17_3_mixed False\n",
            "320 block17_3_conv False\n",
            "321 block17_3 False\n",
            "322 block17_3_ac False\n",
            "323 conv2d_89 False\n",
            "324 batch_normalization_89 True\n",
            "325 activation_89 False\n",
            "326 conv2d_90 False\n",
            "327 batch_normalization_90 True\n",
            "328 activation_90 False\n",
            "329 conv2d_88 False\n",
            "330 conv2d_91 False\n",
            "331 batch_normalization_88 True\n",
            "332 batch_normalization_91 True\n",
            "333 activation_88 False\n",
            "334 activation_91 False\n",
            "335 block17_4_mixed False\n",
            "336 block17_4_conv False\n",
            "337 block17_4 False\n",
            "338 block17_4_ac False\n",
            "339 conv2d_93 False\n",
            "340 batch_normalization_93 True\n",
            "341 activation_93 False\n",
            "342 conv2d_94 False\n",
            "343 batch_normalization_94 True\n",
            "344 activation_94 False\n",
            "345 conv2d_92 False\n",
            "346 conv2d_95 False\n",
            "347 batch_normalization_92 True\n",
            "348 batch_normalization_95 True\n",
            "349 activation_92 False\n",
            "350 activation_95 False\n",
            "351 block17_5_mixed False\n",
            "352 block17_5_conv False\n",
            "353 block17_5 False\n",
            "354 block17_5_ac False\n",
            "355 conv2d_97 False\n",
            "356 batch_normalization_97 True\n",
            "357 activation_97 False\n",
            "358 conv2d_98 False\n",
            "359 batch_normalization_98 True\n",
            "360 activation_98 False\n",
            "361 conv2d_96 False\n",
            "362 conv2d_99 False\n",
            "363 batch_normalization_96 True\n",
            "364 batch_normalization_99 True\n",
            "365 activation_96 False\n",
            "366 activation_99 False\n",
            "367 block17_6_mixed False\n",
            "368 block17_6_conv False\n",
            "369 block17_6 False\n",
            "370 block17_6_ac False\n",
            "371 conv2d_101 False\n",
            "372 batch_normalization_101 True\n",
            "373 activation_101 False\n",
            "374 conv2d_102 False\n",
            "375 batch_normalization_102 True\n",
            "376 activation_102 False\n",
            "377 conv2d_100 False\n",
            "378 conv2d_103 False\n",
            "379 batch_normalization_100 True\n",
            "380 batch_normalization_103 True\n",
            "381 activation_100 False\n",
            "382 activation_103 False\n",
            "383 block17_7_mixed False\n",
            "384 block17_7_conv False\n",
            "385 block17_7 False\n",
            "386 block17_7_ac False\n",
            "387 conv2d_105 False\n",
            "388 batch_normalization_105 True\n",
            "389 activation_105 False\n",
            "390 conv2d_106 False\n",
            "391 batch_normalization_106 True\n",
            "392 activation_106 False\n",
            "393 conv2d_104 False\n",
            "394 conv2d_107 False\n",
            "395 batch_normalization_104 True\n",
            "396 batch_normalization_107 True\n",
            "397 activation_104 False\n",
            "398 activation_107 False\n",
            "399 block17_8_mixed False\n",
            "400 block17_8_conv False\n",
            "401 block17_8 False\n",
            "402 block17_8_ac False\n",
            "403 conv2d_109 False\n",
            "404 batch_normalization_109 True\n",
            "405 activation_109 False\n",
            "406 conv2d_110 False\n",
            "407 batch_normalization_110 True\n",
            "408 activation_110 False\n",
            "409 conv2d_108 False\n",
            "410 conv2d_111 False\n",
            "411 batch_normalization_108 True\n",
            "412 batch_normalization_111 True\n",
            "413 activation_108 False\n",
            "414 activation_111 False\n",
            "415 block17_9_mixed False\n",
            "416 block17_9_conv False\n",
            "417 block17_9 False\n",
            "418 block17_9_ac False\n",
            "419 conv2d_113 False\n",
            "420 batch_normalization_113 True\n",
            "421 activation_113 False\n",
            "422 conv2d_114 False\n",
            "423 batch_normalization_114 True\n",
            "424 activation_114 False\n",
            "425 conv2d_112 False\n",
            "426 conv2d_115 False\n",
            "427 batch_normalization_112 True\n",
            "428 batch_normalization_115 True\n",
            "429 activation_112 False\n",
            "430 activation_115 False\n",
            "431 block17_10_mixed False\n",
            "432 block17_10_conv False\n",
            "433 block17_10 False\n",
            "434 block17_10_ac False\n",
            "435 conv2d_117 False\n",
            "436 batch_normalization_117 True\n",
            "437 activation_117 False\n",
            "438 conv2d_118 False\n",
            "439 batch_normalization_118 True\n",
            "440 activation_118 False\n",
            "441 conv2d_116 False\n",
            "442 conv2d_119 False\n",
            "443 batch_normalization_116 True\n",
            "444 batch_normalization_119 True\n",
            "445 activation_116 False\n",
            "446 activation_119 False\n",
            "447 block17_11_mixed False\n",
            "448 block17_11_conv False\n",
            "449 block17_11 False\n",
            "450 block17_11_ac False\n",
            "451 conv2d_121 False\n",
            "452 batch_normalization_121 True\n",
            "453 activation_121 False\n",
            "454 conv2d_122 False\n",
            "455 batch_normalization_122 True\n",
            "456 activation_122 False\n",
            "457 conv2d_120 False\n",
            "458 conv2d_123 False\n",
            "459 batch_normalization_120 True\n",
            "460 batch_normalization_123 True\n",
            "461 activation_120 False\n",
            "462 activation_123 False\n",
            "463 block17_12_mixed False\n",
            "464 block17_12_conv False\n",
            "465 block17_12 False\n",
            "466 block17_12_ac False\n",
            "467 conv2d_125 False\n",
            "468 batch_normalization_125 True\n",
            "469 activation_125 False\n",
            "470 conv2d_126 False\n",
            "471 batch_normalization_126 True\n",
            "472 activation_126 False\n",
            "473 conv2d_124 False\n",
            "474 conv2d_127 False\n",
            "475 batch_normalization_124 True\n",
            "476 batch_normalization_127 True\n",
            "477 activation_124 False\n",
            "478 activation_127 False\n",
            "479 block17_13_mixed False\n",
            "480 block17_13_conv False\n",
            "481 block17_13 False\n",
            "482 block17_13_ac False\n",
            "483 conv2d_129 False\n",
            "484 batch_normalization_129 True\n",
            "485 activation_129 False\n",
            "486 conv2d_130 False\n",
            "487 batch_normalization_130 True\n",
            "488 activation_130 False\n",
            "489 conv2d_128 False\n",
            "490 conv2d_131 False\n",
            "491 batch_normalization_128 True\n",
            "492 batch_normalization_131 True\n",
            "493 activation_128 False\n",
            "494 activation_131 False\n",
            "495 block17_14_mixed False\n",
            "496 block17_14_conv False\n",
            "497 block17_14 False\n",
            "498 block17_14_ac False\n",
            "499 conv2d_133 False\n",
            "500 batch_normalization_133 True\n",
            "501 activation_133 False\n",
            "502 conv2d_134 False\n",
            "503 batch_normalization_134 True\n",
            "504 activation_134 False\n",
            "505 conv2d_132 False\n",
            "506 conv2d_135 False\n",
            "507 batch_normalization_132 True\n",
            "508 batch_normalization_135 True\n",
            "509 activation_132 False\n",
            "510 activation_135 False\n",
            "511 block17_15_mixed False\n",
            "512 block17_15_conv False\n",
            "513 block17_15 False\n",
            "514 block17_15_ac False\n",
            "515 conv2d_137 False\n",
            "516 batch_normalization_137 True\n",
            "517 activation_137 False\n",
            "518 conv2d_138 False\n",
            "519 batch_normalization_138 True\n",
            "520 activation_138 False\n",
            "521 conv2d_136 False\n",
            "522 conv2d_139 False\n",
            "523 batch_normalization_136 True\n",
            "524 batch_normalization_139 True\n",
            "525 activation_136 False\n",
            "526 activation_139 False\n",
            "527 block17_16_mixed False\n",
            "528 block17_16_conv False\n",
            "529 block17_16 False\n",
            "530 block17_16_ac False\n",
            "531 conv2d_141 False\n",
            "532 batch_normalization_141 True\n",
            "533 activation_141 False\n",
            "534 conv2d_142 False\n",
            "535 batch_normalization_142 True\n",
            "536 activation_142 False\n",
            "537 conv2d_140 False\n",
            "538 conv2d_143 False\n",
            "539 batch_normalization_140 True\n",
            "540 batch_normalization_143 True\n",
            "541 activation_140 False\n",
            "542 activation_143 False\n",
            "543 block17_17_mixed False\n",
            "544 block17_17_conv False\n",
            "545 block17_17 False\n",
            "546 block17_17_ac False\n",
            "547 conv2d_145 False\n",
            "548 batch_normalization_145 True\n",
            "549 activation_145 False\n",
            "550 conv2d_146 False\n",
            "551 batch_normalization_146 True\n",
            "552 activation_146 False\n",
            "553 conv2d_144 False\n",
            "554 conv2d_147 False\n",
            "555 batch_normalization_144 True\n",
            "556 batch_normalization_147 True\n",
            "557 activation_144 False\n",
            "558 activation_147 False\n",
            "559 block17_18_mixed False\n",
            "560 block17_18_conv False\n",
            "561 block17_18 False\n",
            "562 block17_18_ac False\n",
            "563 conv2d_149 False\n",
            "564 batch_normalization_149 True\n",
            "565 activation_149 False\n",
            "566 conv2d_150 False\n",
            "567 batch_normalization_150 True\n",
            "568 activation_150 False\n",
            "569 conv2d_148 False\n",
            "570 conv2d_151 False\n",
            "571 batch_normalization_148 True\n",
            "572 batch_normalization_151 True\n",
            "573 activation_148 False\n",
            "574 activation_151 False\n",
            "575 block17_19_mixed False\n",
            "576 block17_19_conv False\n",
            "577 block17_19 False\n",
            "578 block17_19_ac False\n",
            "579 conv2d_153 False\n",
            "580 batch_normalization_153 True\n",
            "581 activation_153 False\n",
            "582 conv2d_154 False\n",
            "583 batch_normalization_154 True\n",
            "584 activation_154 False\n",
            "585 conv2d_152 False\n",
            "586 conv2d_155 False\n",
            "587 batch_normalization_152 True\n",
            "588 batch_normalization_155 True\n",
            "589 activation_152 False\n",
            "590 activation_155 False\n",
            "591 block17_20_mixed False\n",
            "592 block17_20_conv False\n",
            "593 block17_20 False\n",
            "594 block17_20_ac False\n",
            "595 conv2d_160 False\n",
            "596 batch_normalization_160 True\n",
            "597 activation_160 False\n",
            "598 conv2d_156 False\n",
            "599 conv2d_158 False\n",
            "600 conv2d_161 False\n",
            "601 batch_normalization_156 True\n",
            "602 batch_normalization_158 True\n",
            "603 batch_normalization_161 True\n",
            "604 activation_156 False\n",
            "605 activation_158 False\n",
            "606 activation_161 False\n",
            "607 conv2d_157 False\n",
            "608 conv2d_159 False\n",
            "609 conv2d_162 False\n",
            "610 batch_normalization_157 True\n",
            "611 batch_normalization_159 True\n",
            "612 batch_normalization_162 True\n",
            "613 activation_157 False\n",
            "614 activation_159 False\n",
            "615 activation_162 False\n",
            "616 max_pooling2d_3 False\n",
            "617 mixed_7a False\n",
            "618 conv2d_164 False\n",
            "619 batch_normalization_164 True\n",
            "620 activation_164 False\n",
            "621 conv2d_165 False\n",
            "622 batch_normalization_165 True\n",
            "623 activation_165 False\n",
            "624 conv2d_163 False\n",
            "625 conv2d_166 False\n",
            "626 batch_normalization_163 True\n",
            "627 batch_normalization_166 True\n",
            "628 activation_163 False\n",
            "629 activation_166 False\n",
            "630 block8_1_mixed False\n",
            "631 block8_1_conv False\n",
            "632 block8_1 False\n",
            "633 block8_1_ac False\n",
            "634 conv2d_168 False\n",
            "635 batch_normalization_168 True\n",
            "636 activation_168 False\n",
            "637 conv2d_169 False\n",
            "638 batch_normalization_169 True\n",
            "639 activation_169 False\n",
            "640 conv2d_167 False\n",
            "641 conv2d_170 False\n",
            "642 batch_normalization_167 True\n",
            "643 batch_normalization_170 True\n",
            "644 activation_167 False\n",
            "645 activation_170 False\n",
            "646 block8_2_mixed False\n",
            "647 block8_2_conv False\n",
            "648 block8_2 False\n",
            "649 block8_2_ac False\n",
            "650 conv2d_172 False\n",
            "651 batch_normalization_172 True\n",
            "652 activation_172 False\n",
            "653 conv2d_173 False\n",
            "654 batch_normalization_173 True\n",
            "655 activation_173 False\n",
            "656 conv2d_171 False\n",
            "657 conv2d_174 False\n",
            "658 batch_normalization_171 True\n",
            "659 batch_normalization_174 True\n",
            "660 activation_171 False\n",
            "661 activation_174 False\n",
            "662 block8_3_mixed False\n",
            "663 block8_3_conv False\n",
            "664 block8_3 False\n",
            "665 block8_3_ac False\n",
            "666 conv2d_176 False\n",
            "667 batch_normalization_176 True\n",
            "668 activation_176 False\n",
            "669 conv2d_177 False\n",
            "670 batch_normalization_177 True\n",
            "671 activation_177 False\n",
            "672 conv2d_175 False\n",
            "673 conv2d_178 False\n",
            "674 batch_normalization_175 True\n",
            "675 batch_normalization_178 True\n",
            "676 activation_175 False\n",
            "677 activation_178 False\n",
            "678 block8_4_mixed False\n",
            "679 block8_4_conv False\n",
            "680 block8_4 False\n",
            "681 block8_4_ac False\n",
            "682 conv2d_180 False\n",
            "683 batch_normalization_180 True\n",
            "684 activation_180 False\n",
            "685 conv2d_181 False\n",
            "686 batch_normalization_181 True\n",
            "687 activation_181 False\n",
            "688 conv2d_179 False\n",
            "689 conv2d_182 False\n",
            "690 batch_normalization_179 True\n",
            "691 batch_normalization_182 True\n",
            "692 activation_179 False\n",
            "693 activation_182 False\n",
            "694 block8_5_mixed False\n",
            "695 block8_5_conv False\n",
            "696 block8_5 False\n",
            "697 block8_5_ac False\n",
            "698 conv2d_184 False\n",
            "699 batch_normalization_184 True\n",
            "700 activation_184 False\n",
            "701 conv2d_185 False\n",
            "702 batch_normalization_185 True\n",
            "703 activation_185 False\n",
            "704 conv2d_183 False\n",
            "705 conv2d_186 False\n",
            "706 batch_normalization_183 True\n",
            "707 batch_normalization_186 True\n",
            "708 activation_183 False\n",
            "709 activation_186 False\n",
            "710 block8_6_mixed False\n",
            "711 block8_6_conv False\n",
            "712 block8_6 False\n",
            "713 block8_6_ac False\n",
            "714 conv2d_188 False\n",
            "715 batch_normalization_188 True\n",
            "716 activation_188 False\n",
            "717 conv2d_189 False\n",
            "718 batch_normalization_189 True\n",
            "719 activation_189 False\n",
            "720 conv2d_187 False\n",
            "721 conv2d_190 False\n",
            "722 batch_normalization_187 True\n",
            "723 batch_normalization_190 True\n",
            "724 activation_187 False\n",
            "725 activation_190 False\n",
            "726 block8_7_mixed False\n",
            "727 block8_7_conv False\n",
            "728 block8_7 False\n",
            "729 block8_7_ac False\n",
            "730 conv2d_192 False\n",
            "731 batch_normalization_192 True\n",
            "732 activation_192 False\n",
            "733 conv2d_193 False\n",
            "734 batch_normalization_193 True\n",
            "735 activation_193 False\n",
            "736 conv2d_191 False\n",
            "737 conv2d_194 False\n",
            "738 batch_normalization_191 True\n",
            "739 batch_normalization_194 True\n",
            "740 activation_191 False\n",
            "741 activation_194 False\n",
            "742 block8_8_mixed False\n",
            "743 block8_8_conv False\n",
            "744 block8_8 False\n",
            "745 block8_8_ac False\n",
            "746 conv2d_196 False\n",
            "747 batch_normalization_196 True\n",
            "748 activation_196 False\n",
            "749 conv2d_197 False\n",
            "750 batch_normalization_197 True\n",
            "751 activation_197 False\n",
            "752 conv2d_195 False\n",
            "753 conv2d_198 False\n",
            "754 batch_normalization_195 True\n",
            "755 batch_normalization_198 True\n",
            "756 activation_195 False\n",
            "757 activation_198 False\n",
            "758 block8_9_mixed False\n",
            "759 block8_9_conv False\n",
            "760 block8_9 False\n",
            "761 block8_9_ac False\n",
            "762 conv2d_200 False\n",
            "763 batch_normalization_200 True\n",
            "764 activation_200 False\n",
            "765 conv2d_201 True\n",
            "766 batch_normalization_201 True\n",
            "767 activation_201 True\n",
            "768 conv2d_199 True\n",
            "769 conv2d_202 True\n",
            "770 batch_normalization_199 True\n",
            "771 batch_normalization_202 True\n",
            "772 activation_199 True\n",
            "773 activation_202 True\n",
            "774 block8_10_mixed True\n",
            "775 block8_10_conv True\n",
            "776 block8_10 True\n",
            "777 conv_7b True\n",
            "778 conv_7b_bn True\n",
            "779 conv_7b_ac True\n",
            "780 global_average_pooling2d True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2waEzcK92d2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import Input"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHch9MVY-FGJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_tensor = Input(shape=(224,224,3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zwcHRHrn-E1S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = conv_base_colour(input_tensor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btoK53RE-S6a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = Dense(2048, activation='relu', kernel_regularizer=regularizers.l2(0.001))(x)\n",
        "x = Dropout(0.5)(x)\n",
        "out = Dense(112, activation='softmax')(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rbc25w-t-ujn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_colour = Model(inputs = input_tensor, outputs = out)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOT3FZcP-5fI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "d896faec-24f3-4ee3-969f-f9585f2a1dd1"
      },
      "source": [
        "model_colour.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_4 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "inception_resnet_v2 (Functio (None, 1536)              54336736  \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 2048)              3147776   \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 112)               229488    \n",
            "=================================================================\n",
            "Total params: 57,714,000\n",
            "Trainable params: 57,653,456\n",
            "Non-trainable params: 60,544\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lqpn5go5-8v5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_colour.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(lr=0.001),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "af4WkeVK_ARA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "checkpoint = ModelCheckpoint(\"/content/drive/My Drive/1-piece/Colour_Inception_ResnetV2.h5\",\n",
        "                             monitor=\"val_loss\",\n",
        "                             mode=\"min\",\n",
        "                             save_best_only = True,\n",
        "                             verbose=1)\n",
        "\n",
        "earlystop = EarlyStopping(monitor = 'val_loss', \n",
        "                          min_delta = 0, \n",
        "                          patience = 40,\n",
        "                          verbose = 1,\n",
        "                          restore_best_weights = True)\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(monitor = 'val_loss',\n",
        "                              factor = 0.2,\n",
        "                              patience = 40,\n",
        "                              verbose = 1,\n",
        "                              min_delta = 0.00001)\n",
        "\n",
        "callBacks = [earlystop, checkpoint, reduce_lr]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X3sUkRZ1_Jcx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ff3e5f79-c33f-49cc-c4f0-55d1b0d648a1"
      },
      "source": [
        "hist = model_colour.fit_generator(steps_per_epoch=252,generator= Colour_TrainingData, validation_data= Colour_ValidData, validation_steps=14,epochs=150,callbacks=callBacks)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 5.6678 - accuracy: 0.0159\n",
            "Epoch 00001: val_loss improved from inf to 9.67970, saving model to /content/drive/My Drive/1-piece/Colour_Inception_ResnetV2.h5\n",
            "252/252 [==============================] - 96s 381ms/step - loss: 5.6678 - accuracy: 0.0159 - val_loss: 9.6797 - val_accuracy: 0.0357\n",
            "Epoch 2/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 4.4888 - accuracy: 0.0387\n",
            "Epoch 00002: val_loss did not improve from 9.67970\n",
            "252/252 [==============================] - 89s 352ms/step - loss: 4.4888 - accuracy: 0.0387 - val_loss: 22.7229 - val_accuracy: 0.0357\n",
            "Epoch 3/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 3.9222 - accuracy: 0.0809\n",
            "Epoch 00003: val_loss improved from 9.67970 to 3.22145, saving model to /content/drive/My Drive/1-piece/Colour_Inception_ResnetV2.h5\n",
            "252/252 [==============================] - 97s 386ms/step - loss: 3.9222 - accuracy: 0.0809 - val_loss: 3.2214 - val_accuracy: 0.2500\n",
            "Epoch 4/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 3.4352 - accuracy: 0.1459\n",
            "Epoch 00004: val_loss improved from 3.22145 to 3.13253, saving model to /content/drive/My Drive/1-piece/Colour_Inception_ResnetV2.h5\n",
            "252/252 [==============================] - 99s 392ms/step - loss: 3.4352 - accuracy: 0.1459 - val_loss: 3.1325 - val_accuracy: 0.2679\n",
            "Epoch 5/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 3.0635 - accuracy: 0.2079\n",
            "Epoch 00005: val_loss did not improve from 3.13253\n",
            "252/252 [==============================] - 90s 356ms/step - loss: 3.0635 - accuracy: 0.2079 - val_loss: 221.2210 - val_accuracy: 0.0625\n",
            "Epoch 6/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 2.7732 - accuracy: 0.2521\n",
            "Epoch 00006: val_loss improved from 3.13253 to 2.14687, saving model to /content/drive/My Drive/1-piece/Colour_Inception_ResnetV2.h5\n",
            "252/252 [==============================] - 99s 392ms/step - loss: 2.7732 - accuracy: 0.2521 - val_loss: 2.1469 - val_accuracy: 0.4821\n",
            "Epoch 7/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 2.4445 - accuracy: 0.3548\n",
            "Epoch 00007: val_loss did not improve from 2.14687\n",
            "252/252 [==============================] - 91s 359ms/step - loss: 2.4445 - accuracy: 0.3548 - val_loss: 85.5920 - val_accuracy: 0.1607\n",
            "Epoch 8/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 2.1739 - accuracy: 0.4213\n",
            "Epoch 00008: val_loss improved from 2.14687 to 1.80650, saving model to /content/drive/My Drive/1-piece/Colour_Inception_ResnetV2.h5\n",
            "252/252 [==============================] - 98s 390ms/step - loss: 2.1739 - accuracy: 0.4213 - val_loss: 1.8065 - val_accuracy: 0.5625\n",
            "Epoch 9/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 1.9372 - accuracy: 0.4804\n",
            "Epoch 00009: val_loss did not improve from 1.80650\n",
            "252/252 [==============================] - 91s 362ms/step - loss: 1.9372 - accuracy: 0.4804 - val_loss: 18.8024 - val_accuracy: 0.3393\n",
            "Epoch 10/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 1.9766 - accuracy: 0.4928\n",
            "Epoch 00010: val_loss did not improve from 1.80650\n",
            "252/252 [==============================] - 90s 358ms/step - loss: 1.9766 - accuracy: 0.4928 - val_loss: 44.2934 - val_accuracy: 0.3571\n",
            "Epoch 11/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 1.6358 - accuracy: 0.5712\n",
            "Epoch 00011: val_loss did not improve from 1.80650\n",
            "252/252 [==============================] - 90s 358ms/step - loss: 1.6358 - accuracy: 0.5712 - val_loss: 6.6732 - val_accuracy: 0.4554\n",
            "Epoch 12/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 1.4768 - accuracy: 0.6303\n",
            "Epoch 00012: val_loss did not improve from 1.80650\n",
            "252/252 [==============================] - 90s 358ms/step - loss: 1.4768 - accuracy: 0.6303 - val_loss: 3.3467 - val_accuracy: 0.6964\n",
            "Epoch 13/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 1.4072 - accuracy: 0.6462\n",
            "Epoch 00013: val_loss improved from 1.80650 to 1.07948, saving model to /content/drive/My Drive/1-piece/Colour_Inception_ResnetV2.h5\n",
            "252/252 [==============================] - 100s 395ms/step - loss: 1.4072 - accuracy: 0.6462 - val_loss: 1.0795 - val_accuracy: 0.7679\n",
            "Epoch 14/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 1.2618 - accuracy: 0.6893\n",
            "Epoch 00014: val_loss did not improve from 1.07948\n",
            "252/252 [==============================] - 91s 359ms/step - loss: 1.2618 - accuracy: 0.6893 - val_loss: 1.9625 - val_accuracy: 0.7143\n",
            "Epoch 15/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 1.2380 - accuracy: 0.6998\n",
            "Epoch 00015: val_loss improved from 1.07948 to 0.89207, saving model to /content/drive/My Drive/1-piece/Colour_Inception_ResnetV2.h5\n",
            "252/252 [==============================] - 100s 397ms/step - loss: 1.2380 - accuracy: 0.6998 - val_loss: 0.8921 - val_accuracy: 0.7768\n",
            "Epoch 16/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 1.1211 - accuracy: 0.7320\n",
            "Epoch 00016: val_loss improved from 0.89207 to 0.76589, saving model to /content/drive/My Drive/1-piece/Colour_Inception_ResnetV2.h5\n",
            "252/252 [==============================] - 100s 397ms/step - loss: 1.1211 - accuracy: 0.7320 - val_loss: 0.7659 - val_accuracy: 0.8214\n",
            "Epoch 17/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 1.0417 - accuracy: 0.7514\n",
            "Epoch 00017: val_loss did not improve from 0.76589\n",
            "252/252 [==============================] - 91s 361ms/step - loss: 1.0417 - accuracy: 0.7514 - val_loss: 0.9927 - val_accuracy: 0.7500\n",
            "Epoch 18/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.9835 - accuracy: 0.7633\n",
            "Epoch 00018: val_loss improved from 0.76589 to 0.65705, saving model to /content/drive/My Drive/1-piece/Colour_Inception_ResnetV2.h5\n",
            "252/252 [==============================] - 100s 396ms/step - loss: 0.9835 - accuracy: 0.7633 - val_loss: 0.6570 - val_accuracy: 0.8750\n",
            "Epoch 19/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.9279 - accuracy: 0.7826\n",
            "Epoch 00019: val_loss did not improve from 0.65705\n",
            "252/252 [==============================] - 91s 360ms/step - loss: 0.9279 - accuracy: 0.7826 - val_loss: 0.6978 - val_accuracy: 0.8393\n",
            "Epoch 20/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.9239 - accuracy: 0.7772\n",
            "Epoch 00020: val_loss did not improve from 0.65705\n",
            "252/252 [==============================] - 89s 352ms/step - loss: 0.9239 - accuracy: 0.7772 - val_loss: 0.7009 - val_accuracy: 0.8304\n",
            "Epoch 21/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.8518 - accuracy: 0.8050\n",
            "Epoch 00021: val_loss did not improve from 0.65705\n",
            "252/252 [==============================] - 87s 346ms/step - loss: 0.8518 - accuracy: 0.8050 - val_loss: 1.9827 - val_accuracy: 0.8482\n",
            "Epoch 22/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.8529 - accuracy: 0.8035\n",
            "Epoch 00022: val_loss did not improve from 0.65705\n",
            "252/252 [==============================] - 87s 347ms/step - loss: 0.8529 - accuracy: 0.8035 - val_loss: 3.6430 - val_accuracy: 0.8661\n",
            "Epoch 23/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.8072 - accuracy: 0.8109\n",
            "Epoch 00023: val_loss did not improve from 0.65705\n",
            "252/252 [==============================] - 88s 349ms/step - loss: 0.8072 - accuracy: 0.8109 - val_loss: 2.1003 - val_accuracy: 0.8661\n",
            "Epoch 24/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.7771 - accuracy: 0.8357\n",
            "Epoch 00024: val_loss improved from 0.65705 to 0.56654, saving model to /content/drive/My Drive/1-piece/Colour_Inception_ResnetV2.h5\n",
            "252/252 [==============================] - 97s 386ms/step - loss: 0.7771 - accuracy: 0.8357 - val_loss: 0.5665 - val_accuracy: 0.8750\n",
            "Epoch 25/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.7350 - accuracy: 0.8382\n",
            "Epoch 00025: val_loss did not improve from 0.56654\n",
            "252/252 [==============================] - 90s 356ms/step - loss: 0.7350 - accuracy: 0.8382 - val_loss: 0.7808 - val_accuracy: 0.8393\n",
            "Epoch 26/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.7150 - accuracy: 0.8526\n",
            "Epoch 00026: val_loss did not improve from 0.56654\n",
            "252/252 [==============================] - 89s 352ms/step - loss: 0.7150 - accuracy: 0.8526 - val_loss: 16.9483 - val_accuracy: 0.6250\n",
            "Epoch 27/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.6898 - accuracy: 0.8526\n",
            "Epoch 00027: val_loss did not improve from 0.56654\n",
            "252/252 [==============================] - 89s 351ms/step - loss: 0.6898 - accuracy: 0.8526 - val_loss: 0.7553 - val_accuracy: 0.9107\n",
            "Epoch 28/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.7053 - accuracy: 0.8481\n",
            "Epoch 00028: val_loss did not improve from 0.56654\n",
            "252/252 [==============================] - 88s 351ms/step - loss: 0.7053 - accuracy: 0.8481 - val_loss: 5.0314 - val_accuracy: 0.6518\n",
            "Epoch 29/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.6633 - accuracy: 0.8630\n",
            "Epoch 00029: val_loss did not improve from 0.56654\n",
            "252/252 [==============================] - 89s 354ms/step - loss: 0.6633 - accuracy: 0.8630 - val_loss: 0.7872 - val_accuracy: 0.8393\n",
            "Epoch 30/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.6815 - accuracy: 0.8556\n",
            "Epoch 00030: val_loss did not improve from 0.56654\n",
            "252/252 [==============================] - 88s 351ms/step - loss: 0.6815 - accuracy: 0.8556 - val_loss: 6.0702 - val_accuracy: 0.8929\n",
            "Epoch 31/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.6333 - accuracy: 0.8705\n",
            "Epoch 00031: val_loss did not improve from 0.56654\n",
            "252/252 [==============================] - 89s 352ms/step - loss: 0.6333 - accuracy: 0.8705 - val_loss: 5.4480 - val_accuracy: 0.8839\n",
            "Epoch 32/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.6366 - accuracy: 0.8650\n",
            "Epoch 00032: val_loss did not improve from 0.56654\n",
            "252/252 [==============================] - 89s 353ms/step - loss: 0.6366 - accuracy: 0.8650 - val_loss: 1.0826 - val_accuracy: 0.7500\n",
            "Epoch 33/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.7484 - accuracy: 0.8342\n",
            "Epoch 00033: val_loss did not improve from 0.56654\n",
            "252/252 [==============================] - 89s 354ms/step - loss: 0.7484 - accuracy: 0.8342 - val_loss: 0.6706 - val_accuracy: 0.8750\n",
            "Epoch 34/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.7022 - accuracy: 0.8427\n",
            "Epoch 00034: val_loss improved from 0.56654 to 0.52054, saving model to /content/drive/My Drive/1-piece/Colour_Inception_ResnetV2.h5\n",
            "252/252 [==============================] - 99s 394ms/step - loss: 0.7022 - accuracy: 0.8427 - val_loss: 0.5205 - val_accuracy: 0.9107\n",
            "Epoch 35/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.7211 - accuracy: 0.8442\n",
            "Epoch 00035: val_loss did not improve from 0.52054\n",
            "252/252 [==============================] - 90s 357ms/step - loss: 0.7211 - accuracy: 0.8442 - val_loss: 0.6386 - val_accuracy: 0.8839\n",
            "Epoch 36/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.6445 - accuracy: 0.8685\n",
            "Epoch 00036: val_loss did not improve from 0.52054\n",
            "252/252 [==============================] - 90s 355ms/step - loss: 0.6445 - accuracy: 0.8685 - val_loss: 0.5412 - val_accuracy: 0.9375\n",
            "Epoch 37/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.5663 - accuracy: 0.8928\n",
            "Epoch 00037: val_loss did not improve from 0.52054\n",
            "252/252 [==============================] - 89s 352ms/step - loss: 0.5663 - accuracy: 0.8928 - val_loss: 0.8885 - val_accuracy: 0.9286\n",
            "Epoch 38/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.5141 - accuracy: 0.9002\n",
            "Epoch 00038: val_loss did not improve from 0.52054\n",
            "252/252 [==============================] - 88s 351ms/step - loss: 0.5141 - accuracy: 0.9002 - val_loss: 0.6164 - val_accuracy: 0.8482\n",
            "Epoch 39/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.5085 - accuracy: 0.8988\n",
            "Epoch 00039: val_loss improved from 0.52054 to 0.37666, saving model to /content/drive/My Drive/1-piece/Colour_Inception_ResnetV2.h5\n",
            "252/252 [==============================] - 99s 394ms/step - loss: 0.5085 - accuracy: 0.8988 - val_loss: 0.3767 - val_accuracy: 0.9732\n",
            "Epoch 40/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.5351 - accuracy: 0.8933\n",
            "Epoch 00040: val_loss did not improve from 0.37666\n",
            "252/252 [==============================] - 90s 356ms/step - loss: 0.5351 - accuracy: 0.8933 - val_loss: 0.9693 - val_accuracy: 0.8750\n",
            "Epoch 41/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.4811 - accuracy: 0.9102\n",
            "Epoch 00041: val_loss did not improve from 0.37666\n",
            "252/252 [==============================] - 89s 353ms/step - loss: 0.4811 - accuracy: 0.9102 - val_loss: 0.4202 - val_accuracy: 0.9464\n",
            "Epoch 42/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.6426 - accuracy: 0.8640\n",
            "Epoch 00042: val_loss did not improve from 0.37666\n",
            "252/252 [==============================] - 89s 352ms/step - loss: 0.6426 - accuracy: 0.8640 - val_loss: 3.0147 - val_accuracy: 0.9018\n",
            "Epoch 43/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.6410 - accuracy: 0.8670\n",
            "Epoch 00043: val_loss did not improve from 0.37666\n",
            "252/252 [==============================] - 89s 355ms/step - loss: 0.6410 - accuracy: 0.8670 - val_loss: 0.7810 - val_accuracy: 0.8393\n",
            "Epoch 44/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.5719 - accuracy: 0.8804\n",
            "Epoch 00044: val_loss did not improve from 0.37666\n",
            "252/252 [==============================] - 89s 353ms/step - loss: 0.5719 - accuracy: 0.8804 - val_loss: 0.5661 - val_accuracy: 0.8839\n",
            "Epoch 45/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.4943 - accuracy: 0.9072\n",
            "Epoch 00045: val_loss did not improve from 0.37666\n",
            "252/252 [==============================] - 89s 352ms/step - loss: 0.4943 - accuracy: 0.9072 - val_loss: 0.4266 - val_accuracy: 0.9286\n",
            "Epoch 46/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.4872 - accuracy: 0.9072\n",
            "Epoch 00046: val_loss improved from 0.37666 to 0.35832, saving model to /content/drive/My Drive/1-piece/Colour_Inception_ResnetV2.h5\n",
            "252/252 [==============================] - 98s 389ms/step - loss: 0.4872 - accuracy: 0.9072 - val_loss: 0.3583 - val_accuracy: 0.9375\n",
            "Epoch 47/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.4495 - accuracy: 0.9171\n",
            "Epoch 00047: val_loss did not improve from 0.35832\n",
            "252/252 [==============================] - 90s 359ms/step - loss: 0.4495 - accuracy: 0.9171 - val_loss: 0.4892 - val_accuracy: 0.9375\n",
            "Epoch 48/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.4650 - accuracy: 0.9082\n",
            "Epoch 00048: val_loss did not improve from 0.35832\n",
            "252/252 [==============================] - 89s 355ms/step - loss: 0.4650 - accuracy: 0.9082 - val_loss: 0.3618 - val_accuracy: 0.9375\n",
            "Epoch 49/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.4372 - accuracy: 0.9191\n",
            "Epoch 00049: val_loss did not improve from 0.35832\n",
            "252/252 [==============================] - 89s 355ms/step - loss: 0.4372 - accuracy: 0.9191 - val_loss: 0.5228 - val_accuracy: 0.9107\n",
            "Epoch 50/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.4782 - accuracy: 0.9032\n",
            "Epoch 00050: val_loss improved from 0.35832 to 0.31804, saving model to /content/drive/My Drive/1-piece/Colour_Inception_ResnetV2.h5\n",
            "252/252 [==============================] - 98s 389ms/step - loss: 0.4782 - accuracy: 0.9032 - val_loss: 0.3180 - val_accuracy: 0.9554\n",
            "Epoch 51/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.4370 - accuracy: 0.9196\n",
            "Epoch 00051: val_loss did not improve from 0.31804\n",
            "252/252 [==============================] - 90s 358ms/step - loss: 0.4370 - accuracy: 0.9196 - val_loss: 0.9187 - val_accuracy: 0.9018\n",
            "Epoch 52/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.4886 - accuracy: 0.9042\n",
            "Epoch 00052: val_loss did not improve from 0.31804\n",
            "252/252 [==============================] - 87s 344ms/step - loss: 0.4886 - accuracy: 0.9042 - val_loss: 0.3622 - val_accuracy: 0.9375\n",
            "Epoch 53/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.4248 - accuracy: 0.9206\n",
            "Epoch 00053: val_loss did not improve from 0.31804\n",
            "252/252 [==============================] - 87s 344ms/step - loss: 0.4248 - accuracy: 0.9206 - val_loss: 1.2650 - val_accuracy: 0.9554\n",
            "Epoch 54/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.4133 - accuracy: 0.9310\n",
            "Epoch 00054: val_loss improved from 0.31804 to 0.24263, saving model to /content/drive/My Drive/1-piece/Colour_Inception_ResnetV2.h5\n",
            "252/252 [==============================] - 96s 380ms/step - loss: 0.4133 - accuracy: 0.9310 - val_loss: 0.2426 - val_accuracy: 0.9821\n",
            "Epoch 55/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.4027 - accuracy: 0.9320\n",
            "Epoch 00055: val_loss did not improve from 0.24263\n",
            "252/252 [==============================] - 89s 353ms/step - loss: 0.4027 - accuracy: 0.9320 - val_loss: 1.5260 - val_accuracy: 0.8750\n",
            "Epoch 56/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.4240 - accuracy: 0.9201\n",
            "Epoch 00056: val_loss did not improve from 0.24263\n",
            "252/252 [==============================] - 88s 351ms/step - loss: 0.4240 - accuracy: 0.9201 - val_loss: 0.2676 - val_accuracy: 0.9821\n",
            "Epoch 57/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.4137 - accuracy: 0.9246\n",
            "Epoch 00057: val_loss did not improve from 0.24263\n",
            "252/252 [==============================] - 89s 352ms/step - loss: 0.4137 - accuracy: 0.9246 - val_loss: 0.8765 - val_accuracy: 0.8929\n",
            "Epoch 58/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.4275 - accuracy: 0.9201\n",
            "Epoch 00058: val_loss did not improve from 0.24263\n",
            "252/252 [==============================] - 88s 350ms/step - loss: 0.4275 - accuracy: 0.9201 - val_loss: 0.2808 - val_accuracy: 0.9643\n",
            "Epoch 59/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.3974 - accuracy: 0.9285\n",
            "Epoch 00059: val_loss did not improve from 0.24263\n",
            "252/252 [==============================] - 86s 340ms/step - loss: 0.3974 - accuracy: 0.9285 - val_loss: 0.3178 - val_accuracy: 0.9464\n",
            "Epoch 60/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.4136 - accuracy: 0.9310\n",
            "Epoch 00060: val_loss did not improve from 0.24263\n",
            "252/252 [==============================] - 86s 341ms/step - loss: 0.4136 - accuracy: 0.9310 - val_loss: 0.3038 - val_accuracy: 0.9554\n",
            "Epoch 61/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.3791 - accuracy: 0.9350\n",
            "Epoch 00061: val_loss did not improve from 0.24263\n",
            "252/252 [==============================] - 86s 339ms/step - loss: 0.3791 - accuracy: 0.9350 - val_loss: 0.4169 - val_accuracy: 0.9286\n",
            "Epoch 62/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.3726 - accuracy: 0.9345\n",
            "Epoch 00062: val_loss did not improve from 0.24263\n",
            "252/252 [==============================] - 86s 339ms/step - loss: 0.3726 - accuracy: 0.9345 - val_loss: 0.3522 - val_accuracy: 0.9464\n",
            "Epoch 63/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.4037 - accuracy: 0.9251\n",
            "Epoch 00063: val_loss did not improve from 0.24263\n",
            "252/252 [==============================] - 87s 344ms/step - loss: 0.4037 - accuracy: 0.9251 - val_loss: 0.4612 - val_accuracy: 0.9196\n",
            "Epoch 64/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.3808 - accuracy: 0.9340\n",
            "Epoch 00064: val_loss did not improve from 0.24263\n",
            "252/252 [==============================] - 85s 339ms/step - loss: 0.3808 - accuracy: 0.9340 - val_loss: 0.2773 - val_accuracy: 0.9464\n",
            "Epoch 65/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.3797 - accuracy: 0.9335\n",
            "Epoch 00065: val_loss did not improve from 0.24263\n",
            "252/252 [==============================] - 85s 337ms/step - loss: 0.3797 - accuracy: 0.9335 - val_loss: 0.3045 - val_accuracy: 0.9554\n",
            "Epoch 66/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.3707 - accuracy: 0.9330\n",
            "Epoch 00066: val_loss did not improve from 0.24263\n",
            "252/252 [==============================] - 85s 336ms/step - loss: 0.3707 - accuracy: 0.9330 - val_loss: 0.4575 - val_accuracy: 0.9107\n",
            "Epoch 67/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.4026 - accuracy: 0.9241\n",
            "Epoch 00067: val_loss did not improve from 0.24263\n",
            "252/252 [==============================] - 85s 337ms/step - loss: 0.4026 - accuracy: 0.9241 - val_loss: 1.0682 - val_accuracy: 0.7500\n",
            "Epoch 68/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.4236 - accuracy: 0.9161\n",
            "Epoch 00068: val_loss did not improve from 0.24263\n",
            "252/252 [==============================] - 84s 335ms/step - loss: 0.4236 - accuracy: 0.9161 - val_loss: 0.2446 - val_accuracy: 0.9821\n",
            "Epoch 69/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.4260 - accuracy: 0.9211\n",
            "Epoch 00069: val_loss did not improve from 0.24263\n",
            "252/252 [==============================] - 88s 351ms/step - loss: 0.4260 - accuracy: 0.9211 - val_loss: 1.2887 - val_accuracy: 0.7679\n",
            "Epoch 70/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.3925 - accuracy: 0.9266\n",
            "Epoch 00070: val_loss did not improve from 0.24263\n",
            "252/252 [==============================] - 87s 346ms/step - loss: 0.3925 - accuracy: 0.9266 - val_loss: 0.2886 - val_accuracy: 0.9554\n",
            "Epoch 71/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.3888 - accuracy: 0.9305\n",
            "Epoch 00071: val_loss did not improve from 0.24263\n",
            "252/252 [==============================] - 86s 342ms/step - loss: 0.3888 - accuracy: 0.9305 - val_loss: 0.3099 - val_accuracy: 0.9643\n",
            "Epoch 72/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.3785 - accuracy: 0.9290\n",
            "Epoch 00072: val_loss did not improve from 0.24263\n",
            "252/252 [==============================] - 86s 343ms/step - loss: 0.3785 - accuracy: 0.9290 - val_loss: 0.7236 - val_accuracy: 0.8571\n",
            "Epoch 73/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.3632 - accuracy: 0.9414\n",
            "Epoch 00073: val_loss improved from 0.24263 to 0.23047, saving model to /content/drive/My Drive/1-piece/Colour_Inception_ResnetV2.h5\n",
            "252/252 [==============================] - 95s 378ms/step - loss: 0.3632 - accuracy: 0.9414 - val_loss: 0.2305 - val_accuracy: 0.9821\n",
            "Epoch 74/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.3002 - accuracy: 0.9548\n",
            "Epoch 00074: val_loss did not improve from 0.23047\n",
            "252/252 [==============================] - 88s 347ms/step - loss: 0.3002 - accuracy: 0.9548 - val_loss: 0.3058 - val_accuracy: 0.9643\n",
            "Epoch 75/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.3485 - accuracy: 0.9429\n",
            "Epoch 00075: val_loss did not improve from 0.23047\n",
            "252/252 [==============================] - 86s 343ms/step - loss: 0.3485 - accuracy: 0.9429 - val_loss: 0.3008 - val_accuracy: 0.9732\n",
            "Epoch 76/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.3172 - accuracy: 0.9484\n",
            "Epoch 00076: val_loss did not improve from 0.23047\n",
            "252/252 [==============================] - 86s 341ms/step - loss: 0.3172 - accuracy: 0.9484 - val_loss: 13.0965 - val_accuracy: 0.5357\n",
            "Epoch 77/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.4630 - accuracy: 0.9012\n",
            "Epoch 00077: val_loss did not improve from 0.23047\n",
            "252/252 [==============================] - 86s 342ms/step - loss: 0.4630 - accuracy: 0.9012 - val_loss: 0.2326 - val_accuracy: 0.9732\n",
            "Epoch 78/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.3426 - accuracy: 0.9444\n",
            "Epoch 00078: val_loss improved from 0.23047 to 0.22520, saving model to /content/drive/My Drive/1-piece/Colour_Inception_ResnetV2.h5\n",
            "252/252 [==============================] - 95s 378ms/step - loss: 0.3426 - accuracy: 0.9444 - val_loss: 0.2252 - val_accuracy: 0.9732\n",
            "Epoch 79/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.3182 - accuracy: 0.9499\n",
            "Epoch 00079: val_loss did not improve from 0.22520\n",
            "252/252 [==============================] - 86s 342ms/step - loss: 0.3182 - accuracy: 0.9499 - val_loss: 0.2338 - val_accuracy: 0.9732\n",
            "Epoch 80/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.3161 - accuracy: 0.9529\n",
            "Epoch 00080: val_loss did not improve from 0.22520\n",
            "252/252 [==============================] - 86s 339ms/step - loss: 0.3161 - accuracy: 0.9529 - val_loss: 0.2503 - val_accuracy: 0.9643\n",
            "Epoch 81/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.3287 - accuracy: 0.9484\n",
            "Epoch 00081: val_loss did not improve from 0.22520\n",
            "252/252 [==============================] - 86s 341ms/step - loss: 0.3287 - accuracy: 0.9484 - val_loss: 0.2403 - val_accuracy: 0.9643\n",
            "Epoch 82/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.3295 - accuracy: 0.9449\n",
            "Epoch 00082: val_loss did not improve from 0.22520\n",
            "252/252 [==============================] - 85s 339ms/step - loss: 0.3295 - accuracy: 0.9449 - val_loss: 1.3739 - val_accuracy: 0.9464\n",
            "Epoch 83/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.3034 - accuracy: 0.9558\n",
            "Epoch 00083: val_loss did not improve from 0.22520\n",
            "252/252 [==============================] - 86s 340ms/step - loss: 0.3034 - accuracy: 0.9558 - val_loss: 0.2404 - val_accuracy: 0.9643\n",
            "Epoch 84/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.3580 - accuracy: 0.9380\n",
            "Epoch 00084: val_loss did not improve from 0.22520\n",
            "252/252 [==============================] - 85s 339ms/step - loss: 0.3580 - accuracy: 0.9380 - val_loss: 0.4503 - val_accuracy: 0.9464\n",
            "Epoch 85/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.3211 - accuracy: 0.9449\n",
            "Epoch 00085: val_loss did not improve from 0.22520\n",
            "252/252 [==============================] - 86s 343ms/step - loss: 0.3211 - accuracy: 0.9449 - val_loss: 0.2370 - val_accuracy: 0.9821\n",
            "Epoch 86/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.3089 - accuracy: 0.9524\n",
            "Epoch 00086: val_loss did not improve from 0.22520\n",
            "252/252 [==============================] - 86s 341ms/step - loss: 0.3089 - accuracy: 0.9524 - val_loss: 8.3758 - val_accuracy: 0.8125\n",
            "Epoch 87/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.3568 - accuracy: 0.9419\n",
            "Epoch 00087: val_loss did not improve from 0.22520\n",
            "252/252 [==============================] - 85s 338ms/step - loss: 0.3568 - accuracy: 0.9419 - val_loss: 2.7584 - val_accuracy: 0.8750\n",
            "Epoch 88/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.3417 - accuracy: 0.9365\n",
            "Epoch 00088: val_loss improved from 0.22520 to 0.21031, saving model to /content/drive/My Drive/1-piece/Colour_Inception_ResnetV2.h5\n",
            "252/252 [==============================] - 94s 373ms/step - loss: 0.3417 - accuracy: 0.9365 - val_loss: 0.2103 - val_accuracy: 0.9821\n",
            "Epoch 89/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.2938 - accuracy: 0.9548\n",
            "Epoch 00089: val_loss did not improve from 0.21031\n",
            "252/252 [==============================] - 86s 343ms/step - loss: 0.2938 - accuracy: 0.9548 - val_loss: 0.2223 - val_accuracy: 0.9732\n",
            "Epoch 90/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.2978 - accuracy: 0.9529\n",
            "Epoch 00090: val_loss did not improve from 0.21031\n",
            "252/252 [==============================] - 86s 341ms/step - loss: 0.2978 - accuracy: 0.9529 - val_loss: 3.8883 - val_accuracy: 0.9464\n",
            "Epoch 91/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.3244 - accuracy: 0.9469\n",
            "Epoch 00091: val_loss did not improve from 0.21031\n",
            "252/252 [==============================] - 87s 343ms/step - loss: 0.3244 - accuracy: 0.9469 - val_loss: 0.9207 - val_accuracy: 0.9732\n",
            "Epoch 92/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.3033 - accuracy: 0.9519\n",
            "Epoch 00092: val_loss did not improve from 0.21031\n",
            "252/252 [==============================] - 86s 343ms/step - loss: 0.3033 - accuracy: 0.9519 - val_loss: 4.2907 - val_accuracy: 0.7054\n",
            "Epoch 93/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.3378 - accuracy: 0.9390\n",
            "Epoch 00093: val_loss did not improve from 0.21031\n",
            "252/252 [==============================] - 87s 347ms/step - loss: 0.3378 - accuracy: 0.9390 - val_loss: 7.5591 - val_accuracy: 0.9107\n",
            "Epoch 94/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.3141 - accuracy: 0.9543\n",
            "Epoch 00094: val_loss did not improve from 0.21031\n",
            "252/252 [==============================] - 88s 349ms/step - loss: 0.3141 - accuracy: 0.9543 - val_loss: 1.6503 - val_accuracy: 0.9643\n",
            "Epoch 95/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.2809 - accuracy: 0.9558\n",
            "Epoch 00095: val_loss did not improve from 0.21031\n",
            "252/252 [==============================] - 90s 357ms/step - loss: 0.2809 - accuracy: 0.9558 - val_loss: 1.0835 - val_accuracy: 0.9196\n",
            "Epoch 96/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.2632 - accuracy: 0.9618\n",
            "Epoch 00096: val_loss did not improve from 0.21031\n",
            "252/252 [==============================] - 87s 343ms/step - loss: 0.2632 - accuracy: 0.9618 - val_loss: 0.7022 - val_accuracy: 0.9643\n",
            "Epoch 97/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.2918 - accuracy: 0.9519\n",
            "Epoch 00097: val_loss did not improve from 0.21031\n",
            "252/252 [==============================] - 86s 342ms/step - loss: 0.2918 - accuracy: 0.9519 - val_loss: 16.3392 - val_accuracy: 0.8929\n",
            "Epoch 98/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.3255 - accuracy: 0.9509\n",
            "Epoch 00098: val_loss did not improve from 0.21031\n",
            "252/252 [==============================] - 86s 340ms/step - loss: 0.3255 - accuracy: 0.9509 - val_loss: 0.4478 - val_accuracy: 0.9286\n",
            "Epoch 99/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.4077 - accuracy: 0.9231\n",
            "Epoch 00099: val_loss did not improve from 0.21031\n",
            "252/252 [==============================] - 86s 342ms/step - loss: 0.4077 - accuracy: 0.9231 - val_loss: 0.4379 - val_accuracy: 0.9107\n",
            "Epoch 100/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.3241 - accuracy: 0.9538\n",
            "Epoch 00100: val_loss did not improve from 0.21031\n",
            "252/252 [==============================] - 86s 340ms/step - loss: 0.3241 - accuracy: 0.9538 - val_loss: 0.2467 - val_accuracy: 0.9732\n",
            "Epoch 101/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.3452 - accuracy: 0.9424\n",
            "Epoch 00101: val_loss did not improve from 0.21031\n",
            "252/252 [==============================] - 86s 340ms/step - loss: 0.3452 - accuracy: 0.9424 - val_loss: 41.2592 - val_accuracy: 0.4107\n",
            "Epoch 102/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.3722 - accuracy: 0.9315\n",
            "Epoch 00102: val_loss did not improve from 0.21031\n",
            "252/252 [==============================] - 88s 348ms/step - loss: 0.3722 - accuracy: 0.9315 - val_loss: 0.2471 - val_accuracy: 0.9554\n",
            "Epoch 103/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.3379 - accuracy: 0.9409\n",
            "Epoch 00103: val_loss did not improve from 0.21031\n",
            "252/252 [==============================] - 87s 345ms/step - loss: 0.3379 - accuracy: 0.9409 - val_loss: 0.2181 - val_accuracy: 0.9821\n",
            "Epoch 104/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.2743 - accuracy: 0.9583\n",
            "Epoch 00104: val_loss improved from 0.21031 to 0.16470, saving model to /content/drive/My Drive/1-piece/Colour_Inception_ResnetV2.h5\n",
            "252/252 [==============================] - 96s 382ms/step - loss: 0.2743 - accuracy: 0.9583 - val_loss: 0.1647 - val_accuracy: 0.9911\n",
            "Epoch 105/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.2801 - accuracy: 0.9603\n",
            "Epoch 00105: val_loss did not improve from 0.16470\n",
            "252/252 [==============================] - 87s 344ms/step - loss: 0.2801 - accuracy: 0.9603 - val_loss: 0.2016 - val_accuracy: 0.9821\n",
            "Epoch 106/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.2582 - accuracy: 0.9618\n",
            "Epoch 00106: val_loss did not improve from 0.16470\n",
            "252/252 [==============================] - 87s 343ms/step - loss: 0.2582 - accuracy: 0.9618 - val_loss: 0.2518 - val_accuracy: 0.9732\n",
            "Epoch 107/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.2781 - accuracy: 0.9623\n",
            "Epoch 00107: val_loss did not improve from 0.16470\n",
            "252/252 [==============================] - 85s 339ms/step - loss: 0.2781 - accuracy: 0.9623 - val_loss: 0.3073 - val_accuracy: 0.9732\n",
            "Epoch 108/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.2831 - accuracy: 0.9558\n",
            "Epoch 00108: val_loss did not improve from 0.16470\n",
            "252/252 [==============================] - 85s 339ms/step - loss: 0.2831 - accuracy: 0.9558 - val_loss: 0.1974 - val_accuracy: 0.9821\n",
            "Epoch 109/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.2625 - accuracy: 0.9618\n",
            "Epoch 00109: val_loss did not improve from 0.16470\n",
            "252/252 [==============================] - 85s 337ms/step - loss: 0.2625 - accuracy: 0.9618 - val_loss: 0.2119 - val_accuracy: 0.9911\n",
            "Epoch 110/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.2637 - accuracy: 0.9603\n",
            "Epoch 00110: val_loss did not improve from 0.16470\n",
            "252/252 [==============================] - 85s 338ms/step - loss: 0.2637 - accuracy: 0.9603 - val_loss: 0.2144 - val_accuracy: 0.9554\n",
            "Epoch 111/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.2988 - accuracy: 0.9469\n",
            "Epoch 00111: val_loss did not improve from 0.16470\n",
            "252/252 [==============================] - 85s 338ms/step - loss: 0.2988 - accuracy: 0.9469 - val_loss: 0.2466 - val_accuracy: 0.9643\n",
            "Epoch 112/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.2665 - accuracy: 0.9583\n",
            "Epoch 00112: val_loss did not improve from 0.16470\n",
            "252/252 [==============================] - 85s 338ms/step - loss: 0.2665 - accuracy: 0.9583 - val_loss: 0.5374 - val_accuracy: 0.9018\n",
            "Epoch 113/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.2791 - accuracy: 0.9548\n",
            "Epoch 00113: val_loss did not improve from 0.16470\n",
            "252/252 [==============================] - 87s 346ms/step - loss: 0.2791 - accuracy: 0.9548 - val_loss: 0.2055 - val_accuracy: 0.9821\n",
            "Epoch 114/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.2593 - accuracy: 0.9583\n",
            "Epoch 00114: val_loss did not improve from 0.16470\n",
            "252/252 [==============================] - 86s 342ms/step - loss: 0.2593 - accuracy: 0.9583 - val_loss: 0.5751 - val_accuracy: 0.9107\n",
            "Epoch 115/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.3447 - accuracy: 0.9345\n",
            "Epoch 00115: val_loss did not improve from 0.16470\n",
            "252/252 [==============================] - 86s 340ms/step - loss: 0.3447 - accuracy: 0.9345 - val_loss: 0.8811 - val_accuracy: 0.8036\n",
            "Epoch 116/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.3395 - accuracy: 0.9454\n",
            "Epoch 00116: val_loss did not improve from 0.16470\n",
            "252/252 [==============================] - 85s 339ms/step - loss: 0.3395 - accuracy: 0.9454 - val_loss: 0.4318 - val_accuracy: 0.9375\n",
            "Epoch 117/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.3305 - accuracy: 0.9439\n",
            "Epoch 00117: val_loss did not improve from 0.16470\n",
            "252/252 [==============================] - 86s 343ms/step - loss: 0.3305 - accuracy: 0.9439 - val_loss: 4.2534 - val_accuracy: 0.8839\n",
            "Epoch 118/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.2917 - accuracy: 0.9553\n",
            "Epoch 00118: val_loss did not improve from 0.16470\n",
            "252/252 [==============================] - 86s 340ms/step - loss: 0.2917 - accuracy: 0.9553 - val_loss: 0.3219 - val_accuracy: 0.9643\n",
            "Epoch 119/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.2842 - accuracy: 0.9533\n",
            "Epoch 00119: val_loss did not improve from 0.16470\n",
            "252/252 [==============================] - 87s 343ms/step - loss: 0.2842 - accuracy: 0.9533 - val_loss: 0.2323 - val_accuracy: 0.9732\n",
            "Epoch 120/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.2650 - accuracy: 0.9643\n",
            "Epoch 00120: val_loss did not improve from 0.16470\n",
            "252/252 [==============================] - 86s 343ms/step - loss: 0.2650 - accuracy: 0.9643 - val_loss: 0.1980 - val_accuracy: 0.9732\n",
            "Epoch 121/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.2598 - accuracy: 0.9653\n",
            "Epoch 00121: val_loss did not improve from 0.16470\n",
            "252/252 [==============================] - 86s 341ms/step - loss: 0.2598 - accuracy: 0.9653 - val_loss: 0.1879 - val_accuracy: 0.9821\n",
            "Epoch 122/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.2336 - accuracy: 0.9692\n",
            "Epoch 00122: val_loss did not improve from 0.16470\n",
            "252/252 [==============================] - 86s 341ms/step - loss: 0.2336 - accuracy: 0.9692 - val_loss: 0.3294 - val_accuracy: 0.9643\n",
            "Epoch 123/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.2534 - accuracy: 0.9628\n",
            "Epoch 00123: val_loss did not improve from 0.16470\n",
            "252/252 [==============================] - 86s 341ms/step - loss: 0.2534 - accuracy: 0.9628 - val_loss: 0.6840 - val_accuracy: 0.9196\n",
            "Epoch 124/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.2449 - accuracy: 0.9623\n",
            "Epoch 00124: val_loss did not improve from 0.16470\n",
            "252/252 [==============================] - 85s 336ms/step - loss: 0.2449 - accuracy: 0.9623 - val_loss: 0.1872 - val_accuracy: 0.9821\n",
            "Epoch 125/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.2961 - accuracy: 0.9494\n",
            "Epoch 00125: val_loss did not improve from 0.16470\n",
            "252/252 [==============================] - 84s 333ms/step - loss: 0.2961 - accuracy: 0.9494 - val_loss: 0.3731 - val_accuracy: 0.9464\n",
            "Epoch 126/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.3294 - accuracy: 0.9414\n",
            "Epoch 00126: val_loss did not improve from 0.16470\n",
            "252/252 [==============================] - 84s 333ms/step - loss: 0.3294 - accuracy: 0.9414 - val_loss: 0.5299 - val_accuracy: 0.8750\n",
            "Epoch 127/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.3051 - accuracy: 0.9519\n",
            "Epoch 00127: val_loss did not improve from 0.16470\n",
            "252/252 [==============================] - 84s 334ms/step - loss: 0.3051 - accuracy: 0.9519 - val_loss: 0.3920 - val_accuracy: 0.9375\n",
            "Epoch 128/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.2912 - accuracy: 0.9514\n",
            "Epoch 00128: val_loss did not improve from 0.16470\n",
            "252/252 [==============================] - 85s 337ms/step - loss: 0.2912 - accuracy: 0.9514 - val_loss: 0.3896 - val_accuracy: 0.9375\n",
            "Epoch 129/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.2433 - accuracy: 0.9732\n",
            "Epoch 00129: val_loss did not improve from 0.16470\n",
            "252/252 [==============================] - 84s 334ms/step - loss: 0.2433 - accuracy: 0.9732 - val_loss: 0.9783 - val_accuracy: 0.8036\n",
            "Epoch 130/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.2831 - accuracy: 0.9553\n",
            "Epoch 00130: val_loss did not improve from 0.16470\n",
            "252/252 [==============================] - 84s 333ms/step - loss: 0.2831 - accuracy: 0.9553 - val_loss: 0.2313 - val_accuracy: 0.9821\n",
            "Epoch 131/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.3010 - accuracy: 0.9529\n",
            "Epoch 00131: val_loss did not improve from 0.16470\n",
            "252/252 [==============================] - 85s 336ms/step - loss: 0.3010 - accuracy: 0.9529 - val_loss: 4.7965 - val_accuracy: 0.7411\n",
            "Epoch 132/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.2619 - accuracy: 0.9677\n",
            "Epoch 00132: val_loss did not improve from 0.16470\n",
            "252/252 [==============================] - 84s 334ms/step - loss: 0.2619 - accuracy: 0.9677 - val_loss: 2.0053 - val_accuracy: 0.5000\n",
            "Epoch 133/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.2933 - accuracy: 0.9529\n",
            "Epoch 00133: val_loss did not improve from 0.16470\n",
            "252/252 [==============================] - 84s 333ms/step - loss: 0.2933 - accuracy: 0.9529 - val_loss: 14.6911 - val_accuracy: 0.8036\n",
            "Epoch 134/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.2763 - accuracy: 0.9593\n",
            "Epoch 00134: val_loss did not improve from 0.16470\n",
            "252/252 [==============================] - 84s 332ms/step - loss: 0.2763 - accuracy: 0.9593 - val_loss: 3.5820 - val_accuracy: 0.8125\n",
            "Epoch 135/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.2438 - accuracy: 0.9672\n",
            "Epoch 00135: val_loss improved from 0.16470 to 0.16369, saving model to /content/drive/My Drive/1-piece/Colour_Inception_ResnetV2.h5\n",
            "252/252 [==============================] - 95s 377ms/step - loss: 0.2438 - accuracy: 0.9672 - val_loss: 0.1637 - val_accuracy: 0.9911\n",
            "Epoch 136/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.2497 - accuracy: 0.9672\n",
            "Epoch 00136: val_loss did not improve from 0.16369\n",
            "252/252 [==============================] - 85s 337ms/step - loss: 0.2497 - accuracy: 0.9672 - val_loss: 0.2615 - val_accuracy: 0.9732\n",
            "Epoch 137/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.2268 - accuracy: 0.9702\n",
            "Epoch 00137: val_loss did not improve from 0.16369\n",
            "252/252 [==============================] - 84s 334ms/step - loss: 0.2268 - accuracy: 0.9702 - val_loss: 0.2409 - val_accuracy: 0.9821\n",
            "Epoch 138/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.3023 - accuracy: 0.9514\n",
            "Epoch 00138: val_loss did not improve from 0.16369\n",
            "252/252 [==============================] - 84s 334ms/step - loss: 0.3023 - accuracy: 0.9514 - val_loss: 0.3094 - val_accuracy: 0.9732\n",
            "Epoch 139/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.2838 - accuracy: 0.9514\n",
            "Epoch 00139: val_loss did not improve from 0.16369\n",
            "252/252 [==============================] - 85s 337ms/step - loss: 0.2838 - accuracy: 0.9514 - val_loss: 0.5221 - val_accuracy: 0.9375\n",
            "Epoch 140/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.3193 - accuracy: 0.9469\n",
            "Epoch 00140: val_loss did not improve from 0.16369\n",
            "252/252 [==============================] - 84s 335ms/step - loss: 0.3193 - accuracy: 0.9469 - val_loss: 0.2356 - val_accuracy: 0.9732\n",
            "Epoch 141/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.3169 - accuracy: 0.9444\n",
            "Epoch 00141: val_loss did not improve from 0.16369\n",
            "252/252 [==============================] - 84s 334ms/step - loss: 0.3169 - accuracy: 0.9444 - val_loss: 0.2152 - val_accuracy: 0.9732\n",
            "Epoch 142/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.2614 - accuracy: 0.9638\n",
            "Epoch 00142: val_loss did not improve from 0.16369\n",
            "252/252 [==============================] - 85s 337ms/step - loss: 0.2614 - accuracy: 0.9638 - val_loss: 0.1942 - val_accuracy: 0.9911\n",
            "Epoch 143/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.2472 - accuracy: 0.9682\n",
            "Epoch 00143: val_loss did not improve from 0.16369\n",
            "252/252 [==============================] - 84s 333ms/step - loss: 0.2472 - accuracy: 0.9682 - val_loss: 0.1872 - val_accuracy: 0.9732\n",
            "Epoch 144/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.3028 - accuracy: 0.9529\n",
            "Epoch 00144: val_loss did not improve from 0.16369\n",
            "252/252 [==============================] - 83s 330ms/step - loss: 0.3028 - accuracy: 0.9529 - val_loss: 0.2141 - val_accuracy: 0.9821\n",
            "Epoch 145/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.3040 - accuracy: 0.9459\n",
            "Epoch 00145: val_loss did not improve from 0.16369\n",
            "252/252 [==============================] - 84s 332ms/step - loss: 0.3040 - accuracy: 0.9459 - val_loss: 0.1989 - val_accuracy: 0.9821\n",
            "Epoch 146/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.3202 - accuracy: 0.9479\n",
            "Epoch 00146: val_loss did not improve from 0.16369\n",
            "252/252 [==============================] - 84s 333ms/step - loss: 0.3202 - accuracy: 0.9479 - val_loss: 0.2088 - val_accuracy: 0.9643\n",
            "Epoch 147/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.2270 - accuracy: 0.9762\n",
            "Epoch 00147: val_loss did not improve from 0.16369\n",
            "252/252 [==============================] - 83s 331ms/step - loss: 0.2270 - accuracy: 0.9762 - val_loss: 0.1799 - val_accuracy: 0.9821\n",
            "Epoch 148/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.2331 - accuracy: 0.9643\n",
            "Epoch 00148: val_loss did not improve from 0.16369\n",
            "252/252 [==============================] - 84s 333ms/step - loss: 0.2331 - accuracy: 0.9643 - val_loss: 0.5170 - val_accuracy: 0.9732\n",
            "Epoch 149/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.2613 - accuracy: 0.9583\n",
            "Epoch 00149: val_loss did not improve from 0.16369\n",
            "252/252 [==============================] - 83s 329ms/step - loss: 0.2613 - accuracy: 0.9583 - val_loss: 2.8148 - val_accuracy: 0.8839\n",
            "Epoch 150/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.2330 - accuracy: 0.9667\n",
            "Epoch 00150: val_loss did not improve from 0.16369\n",
            "252/252 [==============================] - 83s 328ms/step - loss: 0.2330 - accuracy: 0.9667 - val_loss: 1.0937 - val_accuracy: 0.9732\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uMLD4IMUCmf3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "ea07849b-b93f-437b-de36-5a8ab013b8c0"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(hist.history[\"accuracy\"])\n",
        "plt.plot(hist.history['val_accuracy'])\n",
        "plt.title(\"model accuracy\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.legend([\"Accuracy\",\"Validation Accuracy\"])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jc0kbAi4Cxa8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "8c52b70b-43e5-4fb3-dd65-6c236a6ed16a"
      },
      "source": [
        "plt.plot(hist.history['loss'])\n",
        "plt.plot(hist.history['val_loss'])\n",
        "plt.title(\"model Loss\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.legend([\"Loss\",\"Validation Loss\"])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LvKgX9gXCzau",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c60cc0ee-6640-4209-fe59-45334d89623b"
      },
      "source": [
        "Colour_TestData = TestGenerator.flow_from_directory('/content/drive/My Drive/1-piece/Test/', target_size=(224,224), batch_size = 8, shuffle = False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 112 images belonging to 112 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3eWaWhTCC3Gb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Colour_predict = model_colour.predict(Colour_TestData)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvkRpKFiC5nf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Colour_predict_classes = np.argmax(Colour_predict, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LbEtb9-FC74e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "f75a81a5-666b-4e06-d432-63baf4aeecc0"
      },
      "source": [
        "Colour_predict_classes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  0,   1,  26,  15,   4,   5,   6,  11,   8,   9,  10,  11,  12,\n",
              "        13,  14,  15,  16,  17,  18,  19,  15,  21,  11,  23,  24,  25,\n",
              "        26,  27,  28,  29,  30,  31,  32,  33,  15,  35,  36,  37,  11,\n",
              "        39,  40,  41,  42,  43,  44,  15,  46,  47,  48,  49,  50,  51,\n",
              "        52,  53,  15,  55, 109,  57,  58,  59,  60,  61,  62,  63,  64,\n",
              "        65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  72,  76,  77,\n",
              "        78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
              "        91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
              "       104, 105, 106, 107, 108, 109, 110, 111])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iw1lsUfjC-D_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a0e509fd-9fe2-4b4e-a382-ed3943d1eead"
      },
      "source": [
        "Colour_accuracy = accuracy_score(Colour_TestData.classes, Colour_predict_classes)\n",
        "print(\"Colour Accuracy: \", Colour_accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Colour Accuracy:  0.9017857142857143\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ApnHQXetDAeM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "594136cc-4c17-42bd-aa3a-2cd998443328"
      },
      "source": [
        "Colour_precision = precision_score(Colour_TestData.classes, Colour_predict_classes,average=\"weighted\")\n",
        "print(\"Colour Precision: \", Colour_precision)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Colour Precision:  0.8742559523809524\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RmbpPJzhDClB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "65ecc8fe-ba04-47cd-ce2a-6f91923c03fa"
      },
      "source": [
        "Colour_recall = recall_score(Colour_TestData.classes, Colour_predict_classes, average=\"weighted\")\n",
        "print(\"Colour Recall:\", Colour_recall)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Colour Recall: 0.9017857142857143\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzfH4Lf2DE9V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bb779745-5c49-4a7e-da62-72b1969563d0"
      },
      "source": [
        "Colour_f1_score = f1_score(Colour_TestData.classes, Colour_predict_classes, average=\"weighted\")\n",
        "print(\"F1 score for colour: \", Colour_f1_score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 score for colour:  0.8811224489795918\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQl0dS6LDHn8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Final = 0.6* Colour_predict + 0.4* Grey_predict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0JqWWHGjDKDB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Final_Predict_classes = np.argmax(Final, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Slbh9VckDMZ8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "bd553cba-58e3-4c6a-bb64-e88081677d4a"
      },
      "source": [
        "Final_Predict_classes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  0,   1,   1,  15,   4,   5,   6,  11,   8,   9,  10,  11,  12,\n",
              "        13,  14,  15,  16,  17,  18,  19,  15,  21,  11,  23,  24,  25,\n",
              "        26,  27,  28,  29,  30,  31,  32,  33,  15,  35,  36,  37,  38,\n",
              "        39,  40,  41,  42,  43,  44,  15,  46,  47,  48,  49,  50,  51,\n",
              "        52,  53,  15,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
              "        65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  72,  76,  77,\n",
              "        78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
              "        91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
              "       104, 105, 106, 107, 108, 109, 110, 111])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OLWfl9CGDPrf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2fce8fcc-5e9e-4021-bc88-b4e2cce9db6f"
      },
      "source": [
        "Final_accuracy = accuracy_score(Colour_TestData.classes, Final_Predict_classes)\n",
        "print(\"Colour Accuracy: \", Final_accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Colour Accuracy:  0.9196428571428571\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZJKf__NDQcy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "060d6bbe-c160-4aae-e419-1830a9cd8770"
      },
      "source": [
        "Final_precision = precision_score(Colour_TestData.classes, Final_Predict_classes,average=\"weighted\")\n",
        "print(\"Colour Precision: \", Final_precision)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Colour Precision:  0.8973214285714286\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MKGLdsciDSZI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "655ee3d0-f176-4a94-bed0-70dc59e178e7"
      },
      "source": [
        "Final_recall = recall_score(Colour_TestData.classes, Final_Predict_classes, average=\"weighted\")\n",
        "print(\"Colour Recall:\", Final_recall)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Colour Recall: 0.9196428571428571\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EA6IUfpfDUJV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bae09767-8e75-47a8-cac8-88c3c782c4dc"
      },
      "source": [
        "Final_f1_score = f1_score(Colour_TestData.classes, Final_Predict_classes, average=\"weighted\")\n",
        "print(\"F1 score for colour: \", Final_f1_score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 score for colour:  0.9028486394557823\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_O45FS7DWRs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Second_Final = 0.5* Colour_predict + 0.5 * Grey_predict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMbahIDZDY8A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Second_predict_classes = np.argmax(Second_Final, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDZGtRCMDbiM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "78ce6889-1978-4a65-9fed-058d49bcb630"
      },
      "source": [
        "Second_predict_classes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  0,   1,   1,  15,   4,   5,   6,  11,   8,   9,  10,  11,  12,\n",
              "        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
              "        26,  27,  28,  29,  30,  31,  32,  33,  15,  35,  36,  37,  38,\n",
              "        39,  40,  41,  42,  43,  44,  15,  46,  47,  48,  49,  50,  51,\n",
              "        52,  53,  15,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
              "        65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
              "        78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
              "        91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
              "       104, 105, 106, 107, 108, 109, 110, 111])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_xFjn41jDdzl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ed3a7984-56e0-4cb4-bb77-44facaf7b648"
      },
      "source": [
        "Second_Final_accuracy = accuracy_score(Colour_TestData.classes, Second_predict_classes)\n",
        "Second_Final_accuracy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9464285714285714"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    }
  ]
}