{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Inspectionv3_Hardwood.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwrnn9RDGRWn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "39f14e00-05cd-4deb-b38b-78be0b983c88"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1Ru2TIyG8zm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Importing the Libraries.\n",
        "import keras\n",
        "import os\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Dropout\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np\n",
        "#import keras.backend as K\n",
        "import tensorflow.keras.backend as K\n",
        "import tensorflow.compat.v1 as tf\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "import numpy as np\n",
        "import sys\n",
        "import os\n",
        "import shutil\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import keras\n",
        "import glob\n",
        "from PIL import Image\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from keras import models, regularizers, layers, optimizers, losses, metrics\n",
        "from keras.applications.resnet50 import ResNet50\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, MaxPool2D\n",
        "from keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
        "from keras.layers import AveragePooling2D\n",
        "from keras.models import load_model\n",
        "from keras.layers.pooling import GlobalAveragePooling2D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from PIL import ImageFile\n",
        "\n",
        "tf.enable_eager_execution()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H8uThe6GHIz4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ImageFile.LOAD_TRUNCATED_IMAGES = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6rFm4Cu0HLWH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Data Augmentation.\n",
        "DataGenerator = ImageDataGenerator(horizontal_flip=True, vertical_flip=True, rescale=1./255, brightness_range=[0.2,0.7])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FkFMyChNHOhL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TestGenerator = ImageDataGenerator(rescale=1./255)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6RosFDArHQjf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9cd0abba-21f2-4f80-ead9-844ef9a9f53d"
      },
      "source": [
        "Grey_TrainingData = DataGenerator.flow_from_directory('/content/drive/My Drive/1-piece/Train/', target_size=(224,224), batch_size=8, color_mode='grayscale')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2015 images belonging to 112 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbyNJFttHTH8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9d3cb8bd-ad38-4de5-a4b5-2214b218001f"
      },
      "source": [
        "Grey_ValidData = TestGenerator.flow_from_directory('/content/drive/My Drive/1-piece/Valid/', target_size=(224,224),batch_size=8, color_mode='grayscale')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 112 images belonging to 112 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "roMORhNzHatK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gpu_options = tf.GPUOptions(allow_growth=True)\n",
        "session = tf.InteractiveSession(config=tf.ConfigProto(gpu_options=gpu_options))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MhjF0A4pHkdh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.applications.inception_v3 import InceptionV3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWL9JBVbICYY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "a91d0d8f-0e43-4b1a-dc8c-1570037a41af"
      },
      "source": [
        "conv_base = InceptionV3(weights = 'imagenet', include_top = False, pooling = 'avg')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87916544/87910968 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0tw3QqY2IFb1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b58ebe9a-d3b2-44bf-d772-06aec10409bf"
      },
      "source": [
        "for layer in conv_base.layers[:299]:\n",
        "  layer.trainable = False\n",
        "for layer in conv_base.layers[299:]:\n",
        "  layer.trainable = True\n",
        "for layer in conv_base.layers:\n",
        "  if isinstance(layer, BatchNormalization):\n",
        "    layer.trainable = True\n",
        "\n",
        "print(\"Done\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPqTlCfaIIzT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2df391aa-2b03-4d86-80e9-f3fa6c41a077"
      },
      "source": [
        "for i, layer in enumerate(conv_base.layers):\n",
        "   print(i, layer.name, layer.trainable)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 input_1 False\n",
            "1 conv2d False\n",
            "2 batch_normalization True\n",
            "3 activation False\n",
            "4 conv2d_1 False\n",
            "5 batch_normalization_1 True\n",
            "6 activation_1 False\n",
            "7 conv2d_2 False\n",
            "8 batch_normalization_2 True\n",
            "9 activation_2 False\n",
            "10 max_pooling2d False\n",
            "11 conv2d_3 False\n",
            "12 batch_normalization_3 True\n",
            "13 activation_3 False\n",
            "14 conv2d_4 False\n",
            "15 batch_normalization_4 True\n",
            "16 activation_4 False\n",
            "17 max_pooling2d_1 False\n",
            "18 conv2d_8 False\n",
            "19 batch_normalization_8 True\n",
            "20 activation_8 False\n",
            "21 conv2d_6 False\n",
            "22 conv2d_9 False\n",
            "23 batch_normalization_6 True\n",
            "24 batch_normalization_9 True\n",
            "25 activation_6 False\n",
            "26 activation_9 False\n",
            "27 average_pooling2d False\n",
            "28 conv2d_5 False\n",
            "29 conv2d_7 False\n",
            "30 conv2d_10 False\n",
            "31 conv2d_11 False\n",
            "32 batch_normalization_5 True\n",
            "33 batch_normalization_7 True\n",
            "34 batch_normalization_10 True\n",
            "35 batch_normalization_11 True\n",
            "36 activation_5 False\n",
            "37 activation_7 False\n",
            "38 activation_10 False\n",
            "39 activation_11 False\n",
            "40 mixed0 False\n",
            "41 conv2d_15 False\n",
            "42 batch_normalization_15 True\n",
            "43 activation_15 False\n",
            "44 conv2d_13 False\n",
            "45 conv2d_16 False\n",
            "46 batch_normalization_13 True\n",
            "47 batch_normalization_16 True\n",
            "48 activation_13 False\n",
            "49 activation_16 False\n",
            "50 average_pooling2d_1 False\n",
            "51 conv2d_12 False\n",
            "52 conv2d_14 False\n",
            "53 conv2d_17 False\n",
            "54 conv2d_18 False\n",
            "55 batch_normalization_12 True\n",
            "56 batch_normalization_14 True\n",
            "57 batch_normalization_17 True\n",
            "58 batch_normalization_18 True\n",
            "59 activation_12 False\n",
            "60 activation_14 False\n",
            "61 activation_17 False\n",
            "62 activation_18 False\n",
            "63 mixed1 False\n",
            "64 conv2d_22 False\n",
            "65 batch_normalization_22 True\n",
            "66 activation_22 False\n",
            "67 conv2d_20 False\n",
            "68 conv2d_23 False\n",
            "69 batch_normalization_20 True\n",
            "70 batch_normalization_23 True\n",
            "71 activation_20 False\n",
            "72 activation_23 False\n",
            "73 average_pooling2d_2 False\n",
            "74 conv2d_19 False\n",
            "75 conv2d_21 False\n",
            "76 conv2d_24 False\n",
            "77 conv2d_25 False\n",
            "78 batch_normalization_19 True\n",
            "79 batch_normalization_21 True\n",
            "80 batch_normalization_24 True\n",
            "81 batch_normalization_25 True\n",
            "82 activation_19 False\n",
            "83 activation_21 False\n",
            "84 activation_24 False\n",
            "85 activation_25 False\n",
            "86 mixed2 False\n",
            "87 conv2d_27 False\n",
            "88 batch_normalization_27 True\n",
            "89 activation_27 False\n",
            "90 conv2d_28 False\n",
            "91 batch_normalization_28 True\n",
            "92 activation_28 False\n",
            "93 conv2d_26 False\n",
            "94 conv2d_29 False\n",
            "95 batch_normalization_26 True\n",
            "96 batch_normalization_29 True\n",
            "97 activation_26 False\n",
            "98 activation_29 False\n",
            "99 max_pooling2d_2 False\n",
            "100 mixed3 False\n",
            "101 conv2d_34 False\n",
            "102 batch_normalization_34 True\n",
            "103 activation_34 False\n",
            "104 conv2d_35 False\n",
            "105 batch_normalization_35 True\n",
            "106 activation_35 False\n",
            "107 conv2d_31 False\n",
            "108 conv2d_36 False\n",
            "109 batch_normalization_31 True\n",
            "110 batch_normalization_36 True\n",
            "111 activation_31 False\n",
            "112 activation_36 False\n",
            "113 conv2d_32 False\n",
            "114 conv2d_37 False\n",
            "115 batch_normalization_32 True\n",
            "116 batch_normalization_37 True\n",
            "117 activation_32 False\n",
            "118 activation_37 False\n",
            "119 average_pooling2d_3 False\n",
            "120 conv2d_30 False\n",
            "121 conv2d_33 False\n",
            "122 conv2d_38 False\n",
            "123 conv2d_39 False\n",
            "124 batch_normalization_30 True\n",
            "125 batch_normalization_33 True\n",
            "126 batch_normalization_38 True\n",
            "127 batch_normalization_39 True\n",
            "128 activation_30 False\n",
            "129 activation_33 False\n",
            "130 activation_38 False\n",
            "131 activation_39 False\n",
            "132 mixed4 False\n",
            "133 conv2d_44 False\n",
            "134 batch_normalization_44 True\n",
            "135 activation_44 False\n",
            "136 conv2d_45 False\n",
            "137 batch_normalization_45 True\n",
            "138 activation_45 False\n",
            "139 conv2d_41 False\n",
            "140 conv2d_46 False\n",
            "141 batch_normalization_41 True\n",
            "142 batch_normalization_46 True\n",
            "143 activation_41 False\n",
            "144 activation_46 False\n",
            "145 conv2d_42 False\n",
            "146 conv2d_47 False\n",
            "147 batch_normalization_42 True\n",
            "148 batch_normalization_47 True\n",
            "149 activation_42 False\n",
            "150 activation_47 False\n",
            "151 average_pooling2d_4 False\n",
            "152 conv2d_40 False\n",
            "153 conv2d_43 False\n",
            "154 conv2d_48 False\n",
            "155 conv2d_49 False\n",
            "156 batch_normalization_40 True\n",
            "157 batch_normalization_43 True\n",
            "158 batch_normalization_48 True\n",
            "159 batch_normalization_49 True\n",
            "160 activation_40 False\n",
            "161 activation_43 False\n",
            "162 activation_48 False\n",
            "163 activation_49 False\n",
            "164 mixed5 False\n",
            "165 conv2d_54 False\n",
            "166 batch_normalization_54 True\n",
            "167 activation_54 False\n",
            "168 conv2d_55 False\n",
            "169 batch_normalization_55 True\n",
            "170 activation_55 False\n",
            "171 conv2d_51 False\n",
            "172 conv2d_56 False\n",
            "173 batch_normalization_51 True\n",
            "174 batch_normalization_56 True\n",
            "175 activation_51 False\n",
            "176 activation_56 False\n",
            "177 conv2d_52 False\n",
            "178 conv2d_57 False\n",
            "179 batch_normalization_52 True\n",
            "180 batch_normalization_57 True\n",
            "181 activation_52 False\n",
            "182 activation_57 False\n",
            "183 average_pooling2d_5 False\n",
            "184 conv2d_50 False\n",
            "185 conv2d_53 False\n",
            "186 conv2d_58 False\n",
            "187 conv2d_59 False\n",
            "188 batch_normalization_50 True\n",
            "189 batch_normalization_53 True\n",
            "190 batch_normalization_58 True\n",
            "191 batch_normalization_59 True\n",
            "192 activation_50 False\n",
            "193 activation_53 False\n",
            "194 activation_58 False\n",
            "195 activation_59 False\n",
            "196 mixed6 False\n",
            "197 conv2d_64 False\n",
            "198 batch_normalization_64 True\n",
            "199 activation_64 False\n",
            "200 conv2d_65 False\n",
            "201 batch_normalization_65 True\n",
            "202 activation_65 False\n",
            "203 conv2d_61 False\n",
            "204 conv2d_66 False\n",
            "205 batch_normalization_61 True\n",
            "206 batch_normalization_66 True\n",
            "207 activation_61 False\n",
            "208 activation_66 False\n",
            "209 conv2d_62 False\n",
            "210 conv2d_67 False\n",
            "211 batch_normalization_62 True\n",
            "212 batch_normalization_67 True\n",
            "213 activation_62 False\n",
            "214 activation_67 False\n",
            "215 average_pooling2d_6 False\n",
            "216 conv2d_60 False\n",
            "217 conv2d_63 False\n",
            "218 conv2d_68 False\n",
            "219 conv2d_69 False\n",
            "220 batch_normalization_60 True\n",
            "221 batch_normalization_63 True\n",
            "222 batch_normalization_68 True\n",
            "223 batch_normalization_69 True\n",
            "224 activation_60 False\n",
            "225 activation_63 False\n",
            "226 activation_68 False\n",
            "227 activation_69 False\n",
            "228 mixed7 False\n",
            "229 conv2d_72 False\n",
            "230 batch_normalization_72 True\n",
            "231 activation_72 False\n",
            "232 conv2d_73 False\n",
            "233 batch_normalization_73 True\n",
            "234 activation_73 False\n",
            "235 conv2d_70 False\n",
            "236 conv2d_74 False\n",
            "237 batch_normalization_70 True\n",
            "238 batch_normalization_74 True\n",
            "239 activation_70 False\n",
            "240 activation_74 False\n",
            "241 conv2d_71 False\n",
            "242 conv2d_75 False\n",
            "243 batch_normalization_71 True\n",
            "244 batch_normalization_75 True\n",
            "245 activation_71 False\n",
            "246 activation_75 False\n",
            "247 max_pooling2d_3 False\n",
            "248 mixed8 False\n",
            "249 conv2d_80 False\n",
            "250 batch_normalization_80 True\n",
            "251 activation_80 False\n",
            "252 conv2d_77 False\n",
            "253 conv2d_81 False\n",
            "254 batch_normalization_77 True\n",
            "255 batch_normalization_81 True\n",
            "256 activation_77 False\n",
            "257 activation_81 False\n",
            "258 conv2d_78 False\n",
            "259 conv2d_79 False\n",
            "260 conv2d_82 False\n",
            "261 conv2d_83 False\n",
            "262 average_pooling2d_7 False\n",
            "263 conv2d_76 False\n",
            "264 batch_normalization_78 True\n",
            "265 batch_normalization_79 True\n",
            "266 batch_normalization_82 True\n",
            "267 batch_normalization_83 True\n",
            "268 conv2d_84 False\n",
            "269 batch_normalization_76 True\n",
            "270 activation_78 False\n",
            "271 activation_79 False\n",
            "272 activation_82 False\n",
            "273 activation_83 False\n",
            "274 batch_normalization_84 True\n",
            "275 activation_76 False\n",
            "276 mixed9_0 False\n",
            "277 concatenate False\n",
            "278 activation_84 False\n",
            "279 mixed9 False\n",
            "280 conv2d_89 False\n",
            "281 batch_normalization_89 True\n",
            "282 activation_89 False\n",
            "283 conv2d_86 False\n",
            "284 conv2d_90 False\n",
            "285 batch_normalization_86 True\n",
            "286 batch_normalization_90 True\n",
            "287 activation_86 False\n",
            "288 activation_90 False\n",
            "289 conv2d_87 False\n",
            "290 conv2d_88 False\n",
            "291 conv2d_91 False\n",
            "292 conv2d_92 False\n",
            "293 average_pooling2d_8 False\n",
            "294 conv2d_85 False\n",
            "295 batch_normalization_87 True\n",
            "296 batch_normalization_88 True\n",
            "297 batch_normalization_91 True\n",
            "298 batch_normalization_92 True\n",
            "299 conv2d_93 True\n",
            "300 batch_normalization_85 True\n",
            "301 activation_87 True\n",
            "302 activation_88 True\n",
            "303 activation_91 True\n",
            "304 activation_92 True\n",
            "305 batch_normalization_93 True\n",
            "306 activation_85 True\n",
            "307 mixed9_1 True\n",
            "308 concatenate_1 True\n",
            "309 activation_93 True\n",
            "310 mixed10 True\n",
            "311 global_average_pooling2d True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRgJzzTkILvk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import Input "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6XwhmneUIOz4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_tensor = Input(shape=(224,224,1))\n",
        "x = Conv2D(3,(3,3), padding='same')(input_tensor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "im_uZPYCIQ_d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = conv_base(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ATK3uMnWIUdW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = Dense(2048, activation='relu', kernel_regularizer= regularizers.l2(0.001))(x)\n",
        "x = Dropout(0.5)(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ucYVzkNJIWuk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ouput = Dense(112, activation='softmax')(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qlek0DDqId2e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Model(inputs = input_tensor, outputs = ouput )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c234MRM8IhIy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "f10ea46e-5a82-4d58-a76a-52a33f5de8a9"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 224, 224, 1)]     0         \n",
            "_________________________________________________________________\n",
            "conv2d_94 (Conv2D)           (None, 224, 224, 3)       30        \n",
            "_________________________________________________________________\n",
            "inception_v3 (Functional)    (None, 2048)              21802784  \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 2048)              4196352   \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 112)               229488    \n",
            "=================================================================\n",
            "Total params: 26,228,654\n",
            "Trainable params: 4,836,302\n",
            "Non-trainable params: 21,392,352\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YKHF6ZDtIj7X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(lr=0.001),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QFrUnTWdIm1x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "checkpoint = ModelCheckpoint(\"/content/drive/My Drive/1-piece/Inceptionv3_GrayScale.h5\",\n",
        "                             monitor=\"val_loss\",\n",
        "                             mode=\"min\",\n",
        "                             save_best_only = True,\n",
        "                             verbose=1)\n",
        "\n",
        "earlystop = EarlyStopping(monitor = 'val_loss', \n",
        "                          min_delta = 0, \n",
        "                          patience = 40,\n",
        "                          verbose = 1,\n",
        "                          restore_best_weights = True)\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(monitor = 'val_loss',\n",
        "                              factor = 0.2,\n",
        "                              patience = 40,\n",
        "                              verbose = 1,\n",
        "                              min_delta = 0.00001)\n",
        "\n",
        "callBacks = [earlystop, checkpoint, reduce_lr]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Silp66FDJEvF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2c974c5f-092b-47ca-a33f-0195db6100e6"
      },
      "source": [
        "hist = model.fit_generator(steps_per_epoch=252,generator= Grey_TrainingData, validation_data= Grey_ValidData, validation_steps=14,epochs=150,callbacks=callBacks)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-22-2f51164406f7>:1: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.fit, which supports generators.\n",
            "Epoch 1/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 6.1368 - accuracy: 0.0223\n",
            "Epoch 00001: val_loss improved from inf to 4.88483, saving model to /content/drive/My Drive/1-piece/Inceptionv3_GrayScale.h5\n",
            "252/252 [==============================] - 775s 3s/step - loss: 6.1368 - accuracy: 0.0223 - val_loss: 4.8848 - val_accuracy: 0.0804\n",
            "Epoch 2/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 4.6676 - accuracy: 0.0491\n",
            "Epoch 00002: val_loss improved from 4.88483 to 4.03751, saving model to /content/drive/My Drive/1-piece/Inceptionv3_GrayScale.h5\n",
            "252/252 [==============================] - 92s 364ms/step - loss: 4.6676 - accuracy: 0.0491 - val_loss: 4.0375 - val_accuracy: 0.1161\n",
            "Epoch 3/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 4.0528 - accuracy: 0.0824\n",
            "Epoch 00003: val_loss improved from 4.03751 to 3.93330, saving model to /content/drive/My Drive/1-piece/Inceptionv3_GrayScale.h5\n",
            "252/252 [==============================] - 92s 366ms/step - loss: 4.0528 - accuracy: 0.0824 - val_loss: 3.9333 - val_accuracy: 0.1161\n",
            "Epoch 4/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 3.6523 - accuracy: 0.1330\n",
            "Epoch 00004: val_loss improved from 3.93330 to 3.42703, saving model to /content/drive/My Drive/1-piece/Inceptionv3_GrayScale.h5\n",
            "252/252 [==============================] - 93s 370ms/step - loss: 3.6523 - accuracy: 0.1330 - val_loss: 3.4270 - val_accuracy: 0.1429\n",
            "Epoch 5/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 3.3444 - accuracy: 0.1831\n",
            "Epoch 00005: val_loss improved from 3.42703 to 2.95690, saving model to /content/drive/My Drive/1-piece/Inceptionv3_GrayScale.h5\n",
            "252/252 [==============================] - 93s 368ms/step - loss: 3.3444 - accuracy: 0.1831 - val_loss: 2.9569 - val_accuracy: 0.2857\n",
            "Epoch 6/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 3.1026 - accuracy: 0.2199\n",
            "Epoch 00006: val_loss did not improve from 2.95690\n",
            "252/252 [==============================] - 91s 360ms/step - loss: 3.1026 - accuracy: 0.2199 - val_loss: 3.4980 - val_accuracy: 0.1429\n",
            "Epoch 7/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 2.9772 - accuracy: 0.2452\n",
            "Epoch 00007: val_loss improved from 2.95690 to 2.78461, saving model to /content/drive/My Drive/1-piece/Inceptionv3_GrayScale.h5\n",
            "252/252 [==============================] - 92s 366ms/step - loss: 2.9772 - accuracy: 0.2452 - val_loss: 2.7846 - val_accuracy: 0.3393\n",
            "Epoch 8/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 2.7920 - accuracy: 0.2675\n",
            "Epoch 00008: val_loss improved from 2.78461 to 2.33842, saving model to /content/drive/My Drive/1-piece/Inceptionv3_GrayScale.h5\n",
            "252/252 [==============================] - 91s 361ms/step - loss: 2.7920 - accuracy: 0.2675 - val_loss: 2.3384 - val_accuracy: 0.3661\n",
            "Epoch 9/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 2.7178 - accuracy: 0.3122\n",
            "Epoch 00009: val_loss improved from 2.33842 to 2.31942, saving model to /content/drive/My Drive/1-piece/Inceptionv3_GrayScale.h5\n",
            "252/252 [==============================] - 90s 358ms/step - loss: 2.7178 - accuracy: 0.3122 - val_loss: 2.3194 - val_accuracy: 0.4732\n",
            "Epoch 10/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 2.5688 - accuracy: 0.3350\n",
            "Epoch 00010: val_loss did not improve from 2.31942\n",
            "252/252 [==============================] - 88s 351ms/step - loss: 2.5688 - accuracy: 0.3350 - val_loss: 2.6197 - val_accuracy: 0.3750\n",
            "Epoch 11/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 2.4564 - accuracy: 0.3677\n",
            "Epoch 00011: val_loss did not improve from 2.31942\n",
            "252/252 [==============================] - 88s 348ms/step - loss: 2.4564 - accuracy: 0.3677 - val_loss: 2.3269 - val_accuracy: 0.3750\n",
            "Epoch 12/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 2.4037 - accuracy: 0.3836\n",
            "Epoch 00012: val_loss improved from 2.31942 to 2.05920, saving model to /content/drive/My Drive/1-piece/Inceptionv3_GrayScale.h5\n",
            "252/252 [==============================] - 89s 354ms/step - loss: 2.4037 - accuracy: 0.3836 - val_loss: 2.0592 - val_accuracy: 0.4643\n",
            "Epoch 13/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 2.2969 - accuracy: 0.3906\n",
            "Epoch 00013: val_loss did not improve from 2.05920\n",
            "252/252 [==============================] - 88s 350ms/step - loss: 2.2969 - accuracy: 0.3906 - val_loss: 2.2771 - val_accuracy: 0.4286\n",
            "Epoch 14/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 2.2353 - accuracy: 0.4045\n",
            "Epoch 00014: val_loss improved from 2.05920 to 2.03475, saving model to /content/drive/My Drive/1-piece/Inceptionv3_GrayScale.h5\n",
            "252/252 [==============================] - 91s 361ms/step - loss: 2.2353 - accuracy: 0.4045 - val_loss: 2.0348 - val_accuracy: 0.4732\n",
            "Epoch 15/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 2.1807 - accuracy: 0.4258\n",
            "Epoch 00015: val_loss improved from 2.03475 to 1.90886, saving model to /content/drive/My Drive/1-piece/Inceptionv3_GrayScale.h5\n",
            "252/252 [==============================] - 90s 357ms/step - loss: 2.1807 - accuracy: 0.4258 - val_loss: 1.9089 - val_accuracy: 0.5268\n",
            "Epoch 16/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 2.1682 - accuracy: 0.4496\n",
            "Epoch 00016: val_loss did not improve from 1.90886\n",
            "252/252 [==============================] - 88s 350ms/step - loss: 2.1682 - accuracy: 0.4496 - val_loss: 1.9403 - val_accuracy: 0.5446\n",
            "Epoch 17/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 2.0638 - accuracy: 0.4357\n",
            "Epoch 00017: val_loss improved from 1.90886 to 1.64308, saving model to /content/drive/My Drive/1-piece/Inceptionv3_GrayScale.h5\n",
            "252/252 [==============================] - 91s 363ms/step - loss: 2.0638 - accuracy: 0.4357 - val_loss: 1.6431 - val_accuracy: 0.5625\n",
            "Epoch 18/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 2.0754 - accuracy: 0.4600\n",
            "Epoch 00018: val_loss did not improve from 1.64308\n",
            "252/252 [==============================] - 89s 354ms/step - loss: 2.0754 - accuracy: 0.4600 - val_loss: 1.7728 - val_accuracy: 0.5536\n",
            "Epoch 19/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 1.9975 - accuracy: 0.4903\n",
            "Epoch 00019: val_loss improved from 1.64308 to 1.59854, saving model to /content/drive/My Drive/1-piece/Inceptionv3_GrayScale.h5\n",
            "252/252 [==============================] - 92s 364ms/step - loss: 1.9975 - accuracy: 0.4903 - val_loss: 1.5985 - val_accuracy: 0.5982\n",
            "Epoch 20/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 1.9592 - accuracy: 0.4734\n",
            "Epoch 00020: val_loss did not improve from 1.59854\n",
            "252/252 [==============================] - 89s 354ms/step - loss: 1.9592 - accuracy: 0.4734 - val_loss: 1.7796 - val_accuracy: 0.5357\n",
            "Epoch 21/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 1.8915 - accuracy: 0.5027\n",
            "Epoch 00021: val_loss did not improve from 1.59854\n",
            "252/252 [==============================] - 90s 355ms/step - loss: 1.8915 - accuracy: 0.5027 - val_loss: 1.8085 - val_accuracy: 0.5268\n",
            "Epoch 22/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 1.9069 - accuracy: 0.5027\n",
            "Epoch 00022: val_loss did not improve from 1.59854\n",
            "252/252 [==============================] - 89s 352ms/step - loss: 1.9069 - accuracy: 0.5027 - val_loss: 1.7376 - val_accuracy: 0.5536\n",
            "Epoch 23/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 1.8054 - accuracy: 0.5320\n",
            "Epoch 00023: val_loss improved from 1.59854 to 1.41900, saving model to /content/drive/My Drive/1-piece/Inceptionv3_GrayScale.h5\n",
            "252/252 [==============================] - 91s 361ms/step - loss: 1.8054 - accuracy: 0.5320 - val_loss: 1.4190 - val_accuracy: 0.6339\n",
            "Epoch 24/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 1.8078 - accuracy: 0.5196\n",
            "Epoch 00024: val_loss did not improve from 1.41900\n",
            "252/252 [==============================] - 90s 357ms/step - loss: 1.8078 - accuracy: 0.5196 - val_loss: 1.6099 - val_accuracy: 0.5625\n",
            "Epoch 25/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 1.7832 - accuracy: 0.5310\n",
            "Epoch 00025: val_loss improved from 1.41900 to 1.41799, saving model to /content/drive/My Drive/1-piece/Inceptionv3_GrayScale.h5\n",
            "252/252 [==============================] - 91s 361ms/step - loss: 1.7832 - accuracy: 0.5310 - val_loss: 1.4180 - val_accuracy: 0.6429\n",
            "Epoch 26/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 1.7541 - accuracy: 0.5494\n",
            "Epoch 00026: val_loss did not improve from 1.41799\n",
            "252/252 [==============================] - 90s 356ms/step - loss: 1.7541 - accuracy: 0.5494 - val_loss: 1.5619 - val_accuracy: 0.6250\n",
            "Epoch 27/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 1.7435 - accuracy: 0.5429\n",
            "Epoch 00027: val_loss improved from 1.41799 to 1.31000, saving model to /content/drive/My Drive/1-piece/Inceptionv3_GrayScale.h5\n",
            "252/252 [==============================] - 91s 363ms/step - loss: 1.7435 - accuracy: 0.5429 - val_loss: 1.3100 - val_accuracy: 0.7143\n",
            "Epoch 28/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 1.7559 - accuracy: 0.5370\n",
            "Epoch 00028: val_loss did not improve from 1.31000\n",
            "252/252 [==============================] - 90s 359ms/step - loss: 1.7559 - accuracy: 0.5370 - val_loss: 1.3198 - val_accuracy: 0.6786\n",
            "Epoch 29/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 1.6515 - accuracy: 0.5742\n",
            "Epoch 00029: val_loss did not improve from 1.31000\n",
            "252/252 [==============================] - 89s 354ms/step - loss: 1.6515 - accuracy: 0.5742 - val_loss: 1.3934 - val_accuracy: 0.6786\n",
            "Epoch 30/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 1.6912 - accuracy: 0.5538\n",
            "Epoch 00030: val_loss did not improve from 1.31000\n",
            "252/252 [==============================] - 89s 353ms/step - loss: 1.6912 - accuracy: 0.5538 - val_loss: 1.4009 - val_accuracy: 0.6607\n",
            "Epoch 31/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 1.6146 - accuracy: 0.5921\n",
            "Epoch 00031: val_loss did not improve from 1.31000\n",
            "252/252 [==============================] - 90s 356ms/step - loss: 1.6146 - accuracy: 0.5921 - val_loss: 1.4430 - val_accuracy: 0.6964\n",
            "Epoch 32/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 1.5483 - accuracy: 0.5970\n",
            "Epoch 00032: val_loss did not improve from 1.31000\n",
            "252/252 [==============================] - 89s 353ms/step - loss: 1.5483 - accuracy: 0.5970 - val_loss: 1.9680 - val_accuracy: 0.5714\n",
            "Epoch 33/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 1.5607 - accuracy: 0.5896\n",
            "Epoch 00033: val_loss did not improve from 1.31000\n",
            "252/252 [==============================] - 88s 351ms/step - loss: 1.5607 - accuracy: 0.5896 - val_loss: 1.5478 - val_accuracy: 0.6161\n",
            "Epoch 34/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 1.5884 - accuracy: 0.5762\n",
            "Epoch 00034: val_loss improved from 1.31000 to 1.14628, saving model to /content/drive/My Drive/1-piece/Inceptionv3_GrayScale.h5\n",
            "252/252 [==============================] - 91s 361ms/step - loss: 1.5884 - accuracy: 0.5762 - val_loss: 1.1463 - val_accuracy: 0.7054\n",
            "Epoch 35/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 1.5529 - accuracy: 0.6015\n",
            "Epoch 00035: val_loss did not improve from 1.14628\n",
            "252/252 [==============================] - 90s 357ms/step - loss: 1.5529 - accuracy: 0.6015 - val_loss: 1.4745 - val_accuracy: 0.6339\n",
            "Epoch 36/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 1.5715 - accuracy: 0.5881\n",
            "Epoch 00036: val_loss did not improve from 1.14628\n",
            "252/252 [==============================] - 89s 354ms/step - loss: 1.5715 - accuracy: 0.5881 - val_loss: 1.4376 - val_accuracy: 0.6607\n",
            "Epoch 37/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 1.5158 - accuracy: 0.6050\n",
            "Epoch 00037: val_loss did not improve from 1.14628\n",
            "252/252 [==============================] - 90s 356ms/step - loss: 1.5158 - accuracy: 0.6050 - val_loss: 1.4821 - val_accuracy: 0.6607\n",
            "Epoch 38/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 1.5212 - accuracy: 0.6015\n",
            "Epoch 00038: val_loss did not improve from 1.14628\n",
            "252/252 [==============================] - 90s 355ms/step - loss: 1.5212 - accuracy: 0.6015 - val_loss: 1.4605 - val_accuracy: 0.6607\n",
            "Epoch 39/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 1.5346 - accuracy: 0.6035\n",
            "Epoch 00039: val_loss did not improve from 1.14628\n",
            "252/252 [==============================] - 89s 354ms/step - loss: 1.5346 - accuracy: 0.6035 - val_loss: 1.6122 - val_accuracy: 0.5625\n",
            "Epoch 40/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 1.4464 - accuracy: 0.6248\n",
            "Epoch 00040: val_loss did not improve from 1.14628\n",
            "252/252 [==============================] - 89s 355ms/step - loss: 1.4464 - accuracy: 0.6248 - val_loss: 1.5569 - val_accuracy: 0.6250\n",
            "Epoch 41/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 1.5099 - accuracy: 0.6015\n",
            "Epoch 00041: val_loss did not improve from 1.14628\n",
            "252/252 [==============================] - 90s 358ms/step - loss: 1.5099 - accuracy: 0.6015 - val_loss: 1.2418 - val_accuracy: 0.6607\n",
            "Epoch 42/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 1.4368 - accuracy: 0.6179\n",
            "Epoch 00042: val_loss did not improve from 1.14628\n",
            "252/252 [==============================] - 90s 356ms/step - loss: 1.4368 - accuracy: 0.6179 - val_loss: 1.3870 - val_accuracy: 0.6696\n",
            "Epoch 43/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 1.4043 - accuracy: 0.6199\n",
            "Epoch 00043: val_loss did not improve from 1.14628\n",
            "252/252 [==============================] - 89s 354ms/step - loss: 1.4043 - accuracy: 0.6199 - val_loss: 1.3074 - val_accuracy: 0.6607\n",
            "Epoch 44/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 1.4147 - accuracy: 0.6308\n",
            "Epoch 00044: val_loss did not improve from 1.14628\n",
            "252/252 [==============================] - 90s 355ms/step - loss: 1.4147 - accuracy: 0.6308 - val_loss: 1.2491 - val_accuracy: 0.7054\n",
            "Epoch 45/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 1.3912 - accuracy: 0.6298\n",
            "Epoch 00045: val_loss did not improve from 1.14628\n",
            "252/252 [==============================] - 90s 357ms/step - loss: 1.3912 - accuracy: 0.6298 - val_loss: 1.5500 - val_accuracy: 0.6339\n",
            "Epoch 46/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 1.3212 - accuracy: 0.6605\n",
            "Epoch 00046: val_loss did not improve from 1.14628\n",
            "252/252 [==============================] - 89s 355ms/step - loss: 1.3212 - accuracy: 0.6605 - val_loss: 1.3719 - val_accuracy: 0.6339\n",
            "Epoch 47/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 1.3929 - accuracy: 0.6323\n",
            "Epoch 00047: val_loss did not improve from 1.14628\n",
            "252/252 [==============================] - 89s 354ms/step - loss: 1.3929 - accuracy: 0.6323 - val_loss: 1.2778 - val_accuracy: 0.6786\n",
            "Epoch 48/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 1.3576 - accuracy: 0.6422\n",
            "Epoch 00048: val_loss did not improve from 1.14628\n",
            "252/252 [==============================] - 90s 357ms/step - loss: 1.3576 - accuracy: 0.6422 - val_loss: 1.4202 - val_accuracy: 0.6339\n",
            "Epoch 49/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 1.3583 - accuracy: 0.6382\n",
            "Epoch 00049: val_loss did not improve from 1.14628\n",
            "252/252 [==============================] - 89s 353ms/step - loss: 1.3583 - accuracy: 0.6382 - val_loss: 1.1721 - val_accuracy: 0.6786\n",
            "Epoch 50/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 1.3476 - accuracy: 0.6541\n",
            "Epoch 00050: val_loss improved from 1.14628 to 1.12907, saving model to /content/drive/My Drive/1-piece/Inceptionv3_GrayScale.h5\n",
            "252/252 [==============================] - 92s 363ms/step - loss: 1.3476 - accuracy: 0.6541 - val_loss: 1.1291 - val_accuracy: 0.7321\n",
            "Epoch 51/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 1.3432 - accuracy: 0.6521\n",
            "Epoch 00051: val_loss did not improve from 1.12907\n",
            "252/252 [==============================] - 89s 355ms/step - loss: 1.3432 - accuracy: 0.6521 - val_loss: 1.1502 - val_accuracy: 0.6518\n",
            "Epoch 52/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 1.3379 - accuracy: 0.6586\n",
            "Epoch 00052: val_loss did not improve from 1.12907\n",
            "252/252 [==============================] - 89s 354ms/step - loss: 1.3379 - accuracy: 0.6586 - val_loss: 1.3302 - val_accuracy: 0.6696\n",
            "Epoch 53/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 1.3033 - accuracy: 0.6650\n",
            "Epoch 00053: val_loss improved from 1.12907 to 1.07808, saving model to /content/drive/My Drive/1-piece/Inceptionv3_GrayScale.h5\n",
            "252/252 [==============================] - 91s 360ms/step - loss: 1.3033 - accuracy: 0.6650 - val_loss: 1.0781 - val_accuracy: 0.6875\n",
            "Epoch 54/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 1.2702 - accuracy: 0.6625\n",
            "Epoch 00054: val_loss improved from 1.07808 to 1.02270, saving model to /content/drive/My Drive/1-piece/Inceptionv3_GrayScale.h5\n",
            "252/252 [==============================] - 92s 367ms/step - loss: 1.2702 - accuracy: 0.6625 - val_loss: 1.0227 - val_accuracy: 0.7500\n",
            "Epoch 55/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 1.2648 - accuracy: 0.6705\n",
            "Epoch 00055: val_loss did not improve from 1.02270\n",
            "252/252 [==============================] - 89s 355ms/step - loss: 1.2648 - accuracy: 0.6705 - val_loss: 1.1695 - val_accuracy: 0.6607\n",
            "Epoch 56/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 1.2301 - accuracy: 0.6819\n",
            "Epoch 00056: val_loss did not improve from 1.02270\n",
            "252/252 [==============================] - 89s 351ms/step - loss: 1.2301 - accuracy: 0.6819 - val_loss: 1.1219 - val_accuracy: 0.6964\n",
            "Epoch 57/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 1.2471 - accuracy: 0.6695\n",
            "Epoch 00057: val_loss did not improve from 1.02270\n",
            "252/252 [==============================] - 88s 351ms/step - loss: 1.2471 - accuracy: 0.6695 - val_loss: 1.1719 - val_accuracy: 0.7054\n",
            "Epoch 58/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 1.2470 - accuracy: 0.6759\n",
            "Epoch 00058: val_loss did not improve from 1.02270\n",
            "252/252 [==============================] - 88s 350ms/step - loss: 1.2470 - accuracy: 0.6759 - val_loss: 1.1073 - val_accuracy: 0.6875\n",
            "Epoch 59/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 1.2183 - accuracy: 0.6799\n",
            "Epoch 00059: val_loss did not improve from 1.02270\n",
            "252/252 [==============================] - 89s 354ms/step - loss: 1.2183 - accuracy: 0.6799 - val_loss: 1.1378 - val_accuracy: 0.7054\n",
            "Epoch 60/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 1.1929 - accuracy: 0.6744\n",
            "Epoch 00060: val_loss did not improve from 1.02270\n",
            "252/252 [==============================] - 90s 357ms/step - loss: 1.1929 - accuracy: 0.6744 - val_loss: 1.0807 - val_accuracy: 0.7054\n",
            "Epoch 61/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 1.2280 - accuracy: 0.6849\n",
            "Epoch 00061: val_loss did not improve from 1.02270\n",
            "252/252 [==============================] - 90s 356ms/step - loss: 1.2280 - accuracy: 0.6849 - val_loss: 1.3416 - val_accuracy: 0.6518\n",
            "Epoch 62/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 1.2117 - accuracy: 0.6849\n",
            "Epoch 00062: val_loss did not improve from 1.02270\n",
            "252/252 [==============================] - 90s 358ms/step - loss: 1.2117 - accuracy: 0.6849 - val_loss: 1.1291 - val_accuracy: 0.6786\n",
            "Epoch 63/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 1.1979 - accuracy: 0.6888\n",
            "Epoch 00063: val_loss did not improve from 1.02270\n",
            "252/252 [==============================] - 88s 350ms/step - loss: 1.1979 - accuracy: 0.6888 - val_loss: 1.1747 - val_accuracy: 0.6786\n",
            "Epoch 64/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 1.1789 - accuracy: 0.6868\n",
            "Epoch 00064: val_loss did not improve from 1.02270\n",
            "252/252 [==============================] - 90s 356ms/step - loss: 1.1789 - accuracy: 0.6868 - val_loss: 1.5921 - val_accuracy: 0.5893\n",
            "Epoch 65/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 1.1434 - accuracy: 0.6933\n",
            "Epoch 00065: val_loss improved from 1.02270 to 1.00456, saving model to /content/drive/My Drive/1-piece/Inceptionv3_GrayScale.h5\n",
            "252/252 [==============================] - 90s 356ms/step - loss: 1.1434 - accuracy: 0.6933 - val_loss: 1.0046 - val_accuracy: 0.7232\n",
            "Epoch 66/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 1.1374 - accuracy: 0.6998\n",
            "Epoch 00066: val_loss did not improve from 1.00456\n",
            "252/252 [==============================] - 88s 349ms/step - loss: 1.1374 - accuracy: 0.6998 - val_loss: 1.0326 - val_accuracy: 0.7232\n",
            "Epoch 67/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 1.1394 - accuracy: 0.6998\n",
            "Epoch 00067: val_loss did not improve from 1.00456\n",
            "252/252 [==============================] - 87s 347ms/step - loss: 1.1394 - accuracy: 0.6998 - val_loss: 1.0470 - val_accuracy: 0.7232\n",
            "Epoch 68/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 1.1347 - accuracy: 0.7097\n",
            "Epoch 00068: val_loss improved from 1.00456 to 0.97396, saving model to /content/drive/My Drive/1-piece/Inceptionv3_GrayScale.h5\n",
            "252/252 [==============================] - 90s 357ms/step - loss: 1.1347 - accuracy: 0.7097 - val_loss: 0.9740 - val_accuracy: 0.7589\n",
            "Epoch 69/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 1.1263 - accuracy: 0.7127\n",
            "Epoch 00069: val_loss did not improve from 0.97396\n",
            "252/252 [==============================] - 88s 350ms/step - loss: 1.1263 - accuracy: 0.7127 - val_loss: 1.1285 - val_accuracy: 0.7232\n",
            "Epoch 70/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 1.0880 - accuracy: 0.7141\n",
            "Epoch 00070: val_loss improved from 0.97396 to 0.90238, saving model to /content/drive/My Drive/1-piece/Inceptionv3_GrayScale.h5\n",
            "252/252 [==============================] - 89s 355ms/step - loss: 1.0880 - accuracy: 0.7141 - val_loss: 0.9024 - val_accuracy: 0.7946\n",
            "Epoch 71/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 1.0960 - accuracy: 0.7136\n",
            "Epoch 00071: val_loss did not improve from 0.90238\n",
            "252/252 [==============================] - 87s 347ms/step - loss: 1.0960 - accuracy: 0.7136 - val_loss: 0.9176 - val_accuracy: 0.7857\n",
            "Epoch 72/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 1.1228 - accuracy: 0.7132\n",
            "Epoch 00072: val_loss did not improve from 0.90238\n",
            "252/252 [==============================] - 87s 344ms/step - loss: 1.1228 - accuracy: 0.7132 - val_loss: 0.9658 - val_accuracy: 0.7768\n",
            "Epoch 73/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 1.0872 - accuracy: 0.7176\n",
            "Epoch 00073: val_loss did not improve from 0.90238\n",
            "252/252 [==============================] - 86s 343ms/step - loss: 1.0872 - accuracy: 0.7176 - val_loss: 1.4069 - val_accuracy: 0.6518\n",
            "Epoch 74/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 1.0736 - accuracy: 0.7231\n",
            "Epoch 00074: val_loss did not improve from 0.90238\n",
            "252/252 [==============================] - 86s 341ms/step - loss: 1.0736 - accuracy: 0.7231 - val_loss: 0.9652 - val_accuracy: 0.7411\n",
            "Epoch 75/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 1.0608 - accuracy: 0.7300\n",
            "Epoch 00075: val_loss did not improve from 0.90238\n",
            "252/252 [==============================] - 87s 346ms/step - loss: 1.0608 - accuracy: 0.7300 - val_loss: 0.9461 - val_accuracy: 0.8125\n",
            "Epoch 76/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 1.0614 - accuracy: 0.7246\n",
            "Epoch 00076: val_loss did not improve from 0.90238\n",
            "252/252 [==============================] - 87s 347ms/step - loss: 1.0614 - accuracy: 0.7246 - val_loss: 0.9495 - val_accuracy: 0.7946\n",
            "Epoch 77/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 1.1101 - accuracy: 0.7166\n",
            "Epoch 00077: val_loss did not improve from 0.90238\n",
            "252/252 [==============================] - 87s 344ms/step - loss: 1.1101 - accuracy: 0.7166 - val_loss: 1.0095 - val_accuracy: 0.7500\n",
            "Epoch 78/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 1.0487 - accuracy: 0.7161\n",
            "Epoch 00078: val_loss did not improve from 0.90238\n",
            "252/252 [==============================] - 86s 343ms/step - loss: 1.0487 - accuracy: 0.7161 - val_loss: 0.9487 - val_accuracy: 0.7857\n",
            "Epoch 79/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 1.0744 - accuracy: 0.7132\n",
            "Epoch 00079: val_loss did not improve from 0.90238\n",
            "252/252 [==============================] - 87s 344ms/step - loss: 1.0744 - accuracy: 0.7132 - val_loss: 1.1140 - val_accuracy: 0.6964\n",
            "Epoch 80/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 1.0492 - accuracy: 0.7300\n",
            "Epoch 00080: val_loss did not improve from 0.90238\n",
            "252/252 [==============================] - 87s 344ms/step - loss: 1.0492 - accuracy: 0.7300 - val_loss: 0.9797 - val_accuracy: 0.7768\n",
            "Epoch 81/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 1.0393 - accuracy: 0.7221\n",
            "Epoch 00081: val_loss did not improve from 0.90238\n",
            "252/252 [==============================] - 86s 342ms/step - loss: 1.0393 - accuracy: 0.7221 - val_loss: 0.9226 - val_accuracy: 0.8036\n",
            "Epoch 82/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 1.0902 - accuracy: 0.7156\n",
            "Epoch 00082: val_loss did not improve from 0.90238\n",
            "252/252 [==============================] - 87s 345ms/step - loss: 1.0902 - accuracy: 0.7156 - val_loss: 0.9945 - val_accuracy: 0.7232\n",
            "Epoch 83/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 1.0400 - accuracy: 0.7335\n",
            "Epoch 00083: val_loss did not improve from 0.90238\n",
            "252/252 [==============================] - 87s 346ms/step - loss: 1.0400 - accuracy: 0.7335 - val_loss: 1.2828 - val_accuracy: 0.6964\n",
            "Epoch 84/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 1.0500 - accuracy: 0.7256\n",
            "Epoch 00084: val_loss did not improve from 0.90238\n",
            "252/252 [==============================] - 86s 343ms/step - loss: 1.0500 - accuracy: 0.7256 - val_loss: 1.0917 - val_accuracy: 0.6875\n",
            "Epoch 85/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 1.0514 - accuracy: 0.7221\n",
            "Epoch 00085: val_loss did not improve from 0.90238\n",
            "252/252 [==============================] - 87s 344ms/step - loss: 1.0514 - accuracy: 0.7221 - val_loss: 1.2481 - val_accuracy: 0.7054\n",
            "Epoch 86/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 1.0167 - accuracy: 0.7236\n",
            "Epoch 00086: val_loss did not improve from 0.90238\n",
            "252/252 [==============================] - 88s 349ms/step - loss: 1.0167 - accuracy: 0.7236 - val_loss: 1.0200 - val_accuracy: 0.7411\n",
            "Epoch 87/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 1.0257 - accuracy: 0.7256\n",
            "Epoch 00087: val_loss did not improve from 0.90238\n",
            "252/252 [==============================] - 88s 349ms/step - loss: 1.0257 - accuracy: 0.7256 - val_loss: 1.0515 - val_accuracy: 0.7857\n",
            "Epoch 88/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.9570 - accuracy: 0.7533\n",
            "Epoch 00088: val_loss did not improve from 0.90238\n",
            "252/252 [==============================] - 88s 347ms/step - loss: 0.9570 - accuracy: 0.7533 - val_loss: 1.2813 - val_accuracy: 0.6875\n",
            "Epoch 89/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.9829 - accuracy: 0.7375\n",
            "Epoch 00089: val_loss did not improve from 0.90238\n",
            "252/252 [==============================] - 87s 347ms/step - loss: 0.9829 - accuracy: 0.7375 - val_loss: 0.9928 - val_accuracy: 0.7589\n",
            "Epoch 90/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.9706 - accuracy: 0.7538\n",
            "Epoch 00090: val_loss did not improve from 0.90238\n",
            "252/252 [==============================] - 88s 349ms/step - loss: 0.9706 - accuracy: 0.7538 - val_loss: 0.9605 - val_accuracy: 0.7857\n",
            "Epoch 91/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.9923 - accuracy: 0.7474\n",
            "Epoch 00091: val_loss did not improve from 0.90238\n",
            "252/252 [==============================] - 88s 348ms/step - loss: 0.9923 - accuracy: 0.7474 - val_loss: 1.0003 - val_accuracy: 0.7232\n",
            "Epoch 92/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.9958 - accuracy: 0.7404\n",
            "Epoch 00092: val_loss did not improve from 0.90238\n",
            "252/252 [==============================] - 88s 348ms/step - loss: 0.9958 - accuracy: 0.7404 - val_loss: 1.2698 - val_accuracy: 0.6786\n",
            "Epoch 93/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.9891 - accuracy: 0.7449\n",
            "Epoch 00093: val_loss did not improve from 0.90238\n",
            "252/252 [==============================] - 87s 347ms/step - loss: 0.9891 - accuracy: 0.7449 - val_loss: 1.1234 - val_accuracy: 0.7054\n",
            "Epoch 94/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.9902 - accuracy: 0.7494\n",
            "Epoch 00094: val_loss improved from 0.90238 to 0.88177, saving model to /content/drive/My Drive/1-piece/Inceptionv3_GrayScale.h5\n",
            "252/252 [==============================] - 89s 355ms/step - loss: 0.9902 - accuracy: 0.7494 - val_loss: 0.8818 - val_accuracy: 0.7500\n",
            "Epoch 95/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.9593 - accuracy: 0.7538\n",
            "Epoch 00095: val_loss improved from 0.88177 to 0.85713, saving model to /content/drive/My Drive/1-piece/Inceptionv3_GrayScale.h5\n",
            "252/252 [==============================] - 90s 357ms/step - loss: 0.9593 - accuracy: 0.7538 - val_loss: 0.8571 - val_accuracy: 0.7500\n",
            "Epoch 96/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.9274 - accuracy: 0.7677\n",
            "Epoch 00096: val_loss did not improve from 0.85713\n",
            "252/252 [==============================] - 88s 351ms/step - loss: 0.9274 - accuracy: 0.7677 - val_loss: 0.8781 - val_accuracy: 0.7500\n",
            "Epoch 97/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.9323 - accuracy: 0.7598\n",
            "Epoch 00097: val_loss improved from 0.85713 to 0.73078, saving model to /content/drive/My Drive/1-piece/Inceptionv3_GrayScale.h5\n",
            "252/252 [==============================] - 90s 357ms/step - loss: 0.9323 - accuracy: 0.7598 - val_loss: 0.7308 - val_accuracy: 0.7857\n",
            "Epoch 98/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.8918 - accuracy: 0.7682\n",
            "Epoch 00098: val_loss did not improve from 0.73078\n",
            "252/252 [==============================] - 88s 348ms/step - loss: 0.8918 - accuracy: 0.7682 - val_loss: 0.8919 - val_accuracy: 0.7768\n",
            "Epoch 99/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.9445 - accuracy: 0.7454\n",
            "Epoch 00099: val_loss did not improve from 0.73078\n",
            "252/252 [==============================] - 87s 347ms/step - loss: 0.9445 - accuracy: 0.7454 - val_loss: 0.8800 - val_accuracy: 0.7589\n",
            "Epoch 100/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.9089 - accuracy: 0.7578\n",
            "Epoch 00100: val_loss did not improve from 0.73078\n",
            "252/252 [==============================] - 87s 343ms/step - loss: 0.9089 - accuracy: 0.7578 - val_loss: 0.9755 - val_accuracy: 0.7411\n",
            "Epoch 101/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.9233 - accuracy: 0.7543\n",
            "Epoch 00101: val_loss did not improve from 0.73078\n",
            "252/252 [==============================] - 87s 344ms/step - loss: 0.9233 - accuracy: 0.7543 - val_loss: 0.9853 - val_accuracy: 0.7589\n",
            "Epoch 102/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.9517 - accuracy: 0.7563\n",
            "Epoch 00102: val_loss did not improve from 0.73078\n",
            "252/252 [==============================] - 87s 345ms/step - loss: 0.9517 - accuracy: 0.7563 - val_loss: 1.0809 - val_accuracy: 0.6964\n",
            "Epoch 103/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.8985 - accuracy: 0.7727\n",
            "Epoch 00103: val_loss did not improve from 0.73078\n",
            "252/252 [==============================] - 87s 344ms/step - loss: 0.8985 - accuracy: 0.7727 - val_loss: 0.9036 - val_accuracy: 0.8036\n",
            "Epoch 104/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.9044 - accuracy: 0.7633\n",
            "Epoch 00104: val_loss did not improve from 0.73078\n",
            "252/252 [==============================] - 87s 345ms/step - loss: 0.9044 - accuracy: 0.7633 - val_loss: 0.9948 - val_accuracy: 0.7589\n",
            "Epoch 105/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.8975 - accuracy: 0.7633\n",
            "Epoch 00105: val_loss did not improve from 0.73078\n",
            "252/252 [==============================] - 87s 344ms/step - loss: 0.8975 - accuracy: 0.7633 - val_loss: 0.9045 - val_accuracy: 0.7857\n",
            "Epoch 106/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.9120 - accuracy: 0.7618\n",
            "Epoch 00106: val_loss did not improve from 0.73078\n",
            "252/252 [==============================] - 87s 345ms/step - loss: 0.9120 - accuracy: 0.7618 - val_loss: 0.9037 - val_accuracy: 0.7946\n",
            "Epoch 107/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.9473 - accuracy: 0.7489\n",
            "Epoch 00107: val_loss did not improve from 0.73078\n",
            "252/252 [==============================] - 87s 345ms/step - loss: 0.9473 - accuracy: 0.7489 - val_loss: 0.9686 - val_accuracy: 0.7232\n",
            "Epoch 108/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.9405 - accuracy: 0.7578\n",
            "Epoch 00108: val_loss did not improve from 0.73078\n",
            "252/252 [==============================] - 87s 346ms/step - loss: 0.9405 - accuracy: 0.7578 - val_loss: 0.8689 - val_accuracy: 0.7768\n",
            "Epoch 109/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.8438 - accuracy: 0.7876\n",
            "Epoch 00109: val_loss did not improve from 0.73078\n",
            "252/252 [==============================] - 86s 342ms/step - loss: 0.8438 - accuracy: 0.7876 - val_loss: 1.0100 - val_accuracy: 0.7589\n",
            "Epoch 110/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.9043 - accuracy: 0.7682\n",
            "Epoch 00110: val_loss did not improve from 0.73078\n",
            "252/252 [==============================] - 87s 345ms/step - loss: 0.9043 - accuracy: 0.7682 - val_loss: 0.9303 - val_accuracy: 0.7411\n",
            "Epoch 111/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.8952 - accuracy: 0.7613\n",
            "Epoch 00111: val_loss did not improve from 0.73078\n",
            "252/252 [==============================] - 87s 345ms/step - loss: 0.8952 - accuracy: 0.7613 - val_loss: 1.0735 - val_accuracy: 0.7143\n",
            "Epoch 112/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.8800 - accuracy: 0.7697\n",
            "Epoch 00112: val_loss did not improve from 0.73078\n",
            "252/252 [==============================] - 87s 347ms/step - loss: 0.8800 - accuracy: 0.7697 - val_loss: 1.1648 - val_accuracy: 0.6875\n",
            "Epoch 113/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.8422 - accuracy: 0.7772\n",
            "Epoch 00113: val_loss did not improve from 0.73078\n",
            "252/252 [==============================] - 88s 349ms/step - loss: 0.8422 - accuracy: 0.7772 - val_loss: 0.8152 - val_accuracy: 0.7768\n",
            "Epoch 114/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.8772 - accuracy: 0.7737\n",
            "Epoch 00114: val_loss did not improve from 0.73078\n",
            "252/252 [==============================] - 87s 347ms/step - loss: 0.8772 - accuracy: 0.7737 - val_loss: 1.0500 - val_accuracy: 0.7500\n",
            "Epoch 115/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.8275 - accuracy: 0.7926\n",
            "Epoch 00115: val_loss did not improve from 0.73078\n",
            "252/252 [==============================] - 87s 345ms/step - loss: 0.8275 - accuracy: 0.7926 - val_loss: 0.8263 - val_accuracy: 0.7589\n",
            "Epoch 116/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.8321 - accuracy: 0.7896\n",
            "Epoch 00116: val_loss did not improve from 0.73078\n",
            "252/252 [==============================] - 87s 344ms/step - loss: 0.8321 - accuracy: 0.7896 - val_loss: 0.8417 - val_accuracy: 0.7857\n",
            "Epoch 117/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.8819 - accuracy: 0.7692\n",
            "Epoch 00117: val_loss did not improve from 0.73078\n",
            "252/252 [==============================] - 86s 343ms/step - loss: 0.8819 - accuracy: 0.7692 - val_loss: 0.8180 - val_accuracy: 0.7857\n",
            "Epoch 118/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.8353 - accuracy: 0.7826\n",
            "Epoch 00118: val_loss did not improve from 0.73078\n",
            "252/252 [==============================] - 86s 340ms/step - loss: 0.8353 - accuracy: 0.7826 - val_loss: 0.7794 - val_accuracy: 0.7857\n",
            "Epoch 119/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.8872 - accuracy: 0.7727\n",
            "Epoch 00119: val_loss did not improve from 0.73078\n",
            "252/252 [==============================] - 87s 346ms/step - loss: 0.8872 - accuracy: 0.7727 - val_loss: 0.8396 - val_accuracy: 0.7768\n",
            "Epoch 120/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.8503 - accuracy: 0.7816\n",
            "Epoch 00120: val_loss did not improve from 0.73078\n",
            "252/252 [==============================] - 87s 344ms/step - loss: 0.8503 - accuracy: 0.7816 - val_loss: 0.8273 - val_accuracy: 0.7411\n",
            "Epoch 121/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.8355 - accuracy: 0.7806\n",
            "Epoch 00121: val_loss did not improve from 0.73078\n",
            "252/252 [==============================] - 86s 343ms/step - loss: 0.8355 - accuracy: 0.7806 - val_loss: 0.8650 - val_accuracy: 0.7768\n",
            "Epoch 122/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.7948 - accuracy: 0.8030\n",
            "Epoch 00122: val_loss did not improve from 0.73078\n",
            "252/252 [==============================] - 87s 345ms/step - loss: 0.7948 - accuracy: 0.8030 - val_loss: 0.8677 - val_accuracy: 0.7679\n",
            "Epoch 123/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.8904 - accuracy: 0.7623\n",
            "Epoch 00123: val_loss did not improve from 0.73078\n",
            "252/252 [==============================] - 87s 346ms/step - loss: 0.8904 - accuracy: 0.7623 - val_loss: 0.9432 - val_accuracy: 0.7232\n",
            "Epoch 124/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.8394 - accuracy: 0.7891\n",
            "Epoch 00124: val_loss improved from 0.73078 to 0.62683, saving model to /content/drive/My Drive/1-piece/Inceptionv3_GrayScale.h5\n",
            "252/252 [==============================] - 89s 354ms/step - loss: 0.8394 - accuracy: 0.7891 - val_loss: 0.6268 - val_accuracy: 0.8393\n",
            "Epoch 125/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.8283 - accuracy: 0.7886\n",
            "Epoch 00125: val_loss did not improve from 0.62683\n",
            "252/252 [==============================] - 88s 351ms/step - loss: 0.8283 - accuracy: 0.7886 - val_loss: 0.7383 - val_accuracy: 0.8125\n",
            "Epoch 126/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.8412 - accuracy: 0.7911\n",
            "Epoch 00126: val_loss did not improve from 0.62683\n",
            "252/252 [==============================] - 88s 348ms/step - loss: 0.8412 - accuracy: 0.7911 - val_loss: 0.7204 - val_accuracy: 0.8125\n",
            "Epoch 127/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.7934 - accuracy: 0.7906\n",
            "Epoch 00127: val_loss did not improve from 0.62683\n",
            "252/252 [==============================] - 86s 341ms/step - loss: 0.7934 - accuracy: 0.7906 - val_loss: 0.6975 - val_accuracy: 0.7768\n",
            "Epoch 128/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.7905 - accuracy: 0.7931\n",
            "Epoch 00128: val_loss did not improve from 0.62683\n",
            "252/252 [==============================] - 85s 339ms/step - loss: 0.7905 - accuracy: 0.7931 - val_loss: 0.7144 - val_accuracy: 0.8304\n",
            "Epoch 129/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.8775 - accuracy: 0.7663\n",
            "Epoch 00129: val_loss did not improve from 0.62683\n",
            "252/252 [==============================] - 85s 338ms/step - loss: 0.8775 - accuracy: 0.7663 - val_loss: 0.8600 - val_accuracy: 0.8036\n",
            "Epoch 130/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.8351 - accuracy: 0.7811\n",
            "Epoch 00130: val_loss did not improve from 0.62683\n",
            "252/252 [==============================] - 85s 338ms/step - loss: 0.8351 - accuracy: 0.7811 - val_loss: 0.7399 - val_accuracy: 0.8036\n",
            "Epoch 131/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.7830 - accuracy: 0.7985\n",
            "Epoch 00131: val_loss did not improve from 0.62683\n",
            "252/252 [==============================] - 85s 338ms/step - loss: 0.7830 - accuracy: 0.7985 - val_loss: 0.6661 - val_accuracy: 0.8571\n",
            "Epoch 132/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.8533 - accuracy: 0.7762\n",
            "Epoch 00132: val_loss did not improve from 0.62683\n",
            "252/252 [==============================] - 85s 339ms/step - loss: 0.8533 - accuracy: 0.7762 - val_loss: 0.7573 - val_accuracy: 0.7857\n",
            "Epoch 133/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.8157 - accuracy: 0.7866\n",
            "Epoch 00133: val_loss did not improve from 0.62683\n",
            "252/252 [==============================] - 85s 339ms/step - loss: 0.8157 - accuracy: 0.7866 - val_loss: 0.8433 - val_accuracy: 0.7946\n",
            "Epoch 134/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.7995 - accuracy: 0.7916\n",
            "Epoch 00134: val_loss did not improve from 0.62683\n",
            "252/252 [==============================] - 85s 336ms/step - loss: 0.7995 - accuracy: 0.7916 - val_loss: 0.6314 - val_accuracy: 0.8393\n",
            "Epoch 135/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.7683 - accuracy: 0.8005\n",
            "Epoch 00135: val_loss did not improve from 0.62683\n",
            "252/252 [==============================] - 84s 334ms/step - loss: 0.7683 - accuracy: 0.8005 - val_loss: 0.7009 - val_accuracy: 0.7857\n",
            "Epoch 136/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.8020 - accuracy: 0.7886\n",
            "Epoch 00136: val_loss did not improve from 0.62683\n",
            "252/252 [==============================] - 83s 329ms/step - loss: 0.8020 - accuracy: 0.7886 - val_loss: 0.7048 - val_accuracy: 0.8214\n",
            "Epoch 137/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.8365 - accuracy: 0.7881\n",
            "Epoch 00137: val_loss did not improve from 0.62683\n",
            "252/252 [==============================] - 84s 335ms/step - loss: 0.8365 - accuracy: 0.7881 - val_loss: 0.7050 - val_accuracy: 0.8125\n",
            "Epoch 138/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.7988 - accuracy: 0.7916\n",
            "Epoch 00138: val_loss did not improve from 0.62683\n",
            "252/252 [==============================] - 85s 336ms/step - loss: 0.7988 - accuracy: 0.7916 - val_loss: 0.8154 - val_accuracy: 0.7946\n",
            "Epoch 139/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.7435 - accuracy: 0.8199\n",
            "Epoch 00139: val_loss did not improve from 0.62683\n",
            "252/252 [==============================] - 87s 344ms/step - loss: 0.7435 - accuracy: 0.8199 - val_loss: 1.1177 - val_accuracy: 0.7768\n",
            "Epoch 140/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.7677 - accuracy: 0.8065\n",
            "Epoch 00140: val_loss did not improve from 0.62683\n",
            "252/252 [==============================] - 85s 338ms/step - loss: 0.7677 - accuracy: 0.8065 - val_loss: 0.8076 - val_accuracy: 0.8125\n",
            "Epoch 141/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.7423 - accuracy: 0.8189\n",
            "Epoch 00141: val_loss did not improve from 0.62683\n",
            "252/252 [==============================] - 84s 334ms/step - loss: 0.7423 - accuracy: 0.8189 - val_loss: 1.0713 - val_accuracy: 0.7589\n",
            "Epoch 142/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.7103 - accuracy: 0.8238\n",
            "Epoch 00142: val_loss did not improve from 0.62683\n",
            "252/252 [==============================] - 85s 339ms/step - loss: 0.7103 - accuracy: 0.8238 - val_loss: 0.6976 - val_accuracy: 0.8482\n",
            "Epoch 143/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.7849 - accuracy: 0.8015\n",
            "Epoch 00143: val_loss did not improve from 0.62683\n",
            "252/252 [==============================] - 85s 338ms/step - loss: 0.7849 - accuracy: 0.8015 - val_loss: 0.7244 - val_accuracy: 0.8304\n",
            "Epoch 144/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.7491 - accuracy: 0.8139\n",
            "Epoch 00144: val_loss did not improve from 0.62683\n",
            "252/252 [==============================] - 86s 341ms/step - loss: 0.7491 - accuracy: 0.8139 - val_loss: 0.6912 - val_accuracy: 0.7857\n",
            "Epoch 145/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.7471 - accuracy: 0.8164\n",
            "Epoch 00145: val_loss did not improve from 0.62683\n",
            "252/252 [==============================] - 86s 342ms/step - loss: 0.7471 - accuracy: 0.8164 - val_loss: 0.6986 - val_accuracy: 0.7946\n",
            "Epoch 146/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.7629 - accuracy: 0.8223\n",
            "Epoch 00146: val_loss did not improve from 0.62683\n",
            "252/252 [==============================] - 86s 341ms/step - loss: 0.7629 - accuracy: 0.8223 - val_loss: 0.7026 - val_accuracy: 0.8482\n",
            "Epoch 147/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.7797 - accuracy: 0.8035\n",
            "Epoch 00147: val_loss improved from 0.62683 to 0.59383, saving model to /content/drive/My Drive/1-piece/Inceptionv3_GrayScale.h5\n",
            "252/252 [==============================] - 87s 347ms/step - loss: 0.7797 - accuracy: 0.8035 - val_loss: 0.5938 - val_accuracy: 0.8661\n",
            "Epoch 148/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.7518 - accuracy: 0.8074\n",
            "Epoch 00148: val_loss did not improve from 0.59383\n",
            "252/252 [==============================] - 88s 347ms/step - loss: 0.7518 - accuracy: 0.8074 - val_loss: 0.6984 - val_accuracy: 0.8304\n",
            "Epoch 149/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.7750 - accuracy: 0.8035\n",
            "Epoch 00149: val_loss did not improve from 0.59383\n",
            "252/252 [==============================] - 87s 346ms/step - loss: 0.7750 - accuracy: 0.8035 - val_loss: 0.9122 - val_accuracy: 0.7768\n",
            "Epoch 150/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.7533 - accuracy: 0.8094\n",
            "Epoch 00150: val_loss did not improve from 0.59383\n",
            "252/252 [==============================] - 86s 343ms/step - loss: 0.7533 - accuracy: 0.8094 - val_loss: 0.8243 - val_accuracy: 0.7768\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7rddNBrFJWH5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "d3e38474-c9ba-4599-ae83-fd3b4ea357fd"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(hist.history[\"accuracy\"])\n",
        "plt.plot(hist.history['val_accuracy'])\n",
        "plt.title(\"model accuracy\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.legend([\"Accuracy\",\"Validation Accuracy\"])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tk4bvR-UJbm1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "f51e8505-08c4-462a-fc5f-53d4899c1ef0"
      },
      "source": [
        "plt.plot(hist.history['loss'])\n",
        "plt.plot(hist.history['val_loss'])\n",
        "plt.title(\"model Loss\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.legend([\"Loss\",\"Validation Loss\"])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YnKgsbT2Jn1K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b2baf339-2c2e-47c5-df7c-7a8c2b3164c2"
      },
      "source": [
        "GreyTestData = TestGenerator.flow_from_directory('/content/drive/My Drive/1-piece/Test/', target_size=(224,224), batch_size = 8, shuffle = False, color_mode='grayscale')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 112 images belonging to 112 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8Gg_F49Jw28",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Grey_predict = model.predict(GreyTestData)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O37PVgcGJ4YO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Grey_predict_classes = np.argmax(Grey_predict, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ssASZqHcKCdz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "48905995-e28e-449f-f95a-104a0af41670"
      },
      "source": [
        "Grey_predict_classes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 24,  29,  29,  21,   4,  24,  24,   7,   9,  10,  10,  11,  12,\n",
              "        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
              "        29,  27,  17,  29,  30,  24,  32,  33,  34,  35,  36,  37,  38,\n",
              "        39,  40,  41,  42,  43,  44,  45,  46,  48,  48,  49,  50,  67,\n",
              "        52,  53,  54,  55,  56,  57,  68,  59,  60,  61,  51,  77,  64,\n",
              "        67,  66,  67,  68,  69,  70,  71,  72, 108,  74,  75,  76,  76,\n",
              "        78,  79,  80,  81,  82,  83,  84,  85,  85,  87,  88,  89,  66,\n",
              "        91,  92,  93,  94,  95,  96,  97,  98, 100, 100, 101,  66, 103,\n",
              "        74, 105,  59, 107, 108, 109, 110, 111])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HvCrugUfKG0L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "from sklearn.metrics import roc_auc_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eOWWlroCKJXK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2b9a9aae-e9c3-4354-9d99-dfe5d5aa69ad"
      },
      "source": [
        "Grey_accuracy = accuracy_score(GreyTestData.classes, Grey_predict_classes)\n",
        "print(\"Grey Accuracy: \", Grey_accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Grey Accuracy:  0.7767857142857143\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qT8GZ8SWKQsZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "4a587f81-ddc5-4a12-aad0-4abd8fe55e35"
      },
      "source": [
        "Grey_precision = precision_score(GreyTestData.classes, Grey_predict_classes,average=\"weighted\")\n",
        "print(\"Grey Precision: \", Grey_precision)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Grey Precision:  0.7019345238095237\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vaMESfPKXYT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "963e9888-145d-4725-a47c-6e4517461fb0"
      },
      "source": [
        "Grey_recall = recall_score(GreyTestData.classes, Grey_predict_classes, average=\"weighted\")\n",
        "print(\"Grey Recall:\", Grey_recall)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Grey Recall: 0.7767857142857143\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ArX8LkQ3KbDn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a96658b4-0a2e-44a2-8a34-8bd128b89649"
      },
      "source": [
        "Grey_f1_score = f1_score(GreyTestData.classes, Grey_predict_classes, average=\"weighted\")\n",
        "print(\"F1 score for Grey: \", Grey_f1_score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 score for Grey:  0.7238095238095238\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JE2Pmwq4KvbW",
        "colab_type": "text"
      },
      "source": [
        "**Processing for colour Data.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eI7an7B8K1Iy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "582dc02f-10e9-41d9-e391-7f091d67eb10"
      },
      "source": [
        "Colour_TrainingData =  DataGenerator.flow_from_directory('/content/drive/My Drive/1-piece/Train/', target_size=(224,224), batch_size=8)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2015 images belonging to 112 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZrczUjKLUa7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5c20daeb-a56b-4fd9-bd2a-6b4f4cbf0584"
      },
      "source": [
        "Colour_ValidData =  DataGenerator.flow_from_directory('/content/drive/My Drive/1-piece/Valid/', target_size=(224,224), batch_size=8)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 112 images belonging to 112 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOOU7KB1LhAX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "conv_base_colour = InceptionV3(weights = 'imagenet', include_top = False, pooling = 'avg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SvVV5qnxLpMI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6e23d9b2-63ca-43fc-e6ed-4205ce996182"
      },
      "source": [
        "for layer in conv_base_colour.layers[:299]:\n",
        "  layer.trainable = False\n",
        "for layer in conv_base_colour.layers[299:]:\n",
        "  layer.trainable = True\n",
        "for layer in conv_base_colour.layers:\n",
        "  if isinstance(layer, BatchNormalization):\n",
        "    layer.trainable = True\n",
        "\n",
        "print(\"Done\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4DVU5NALssh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b243d8b2-b535-4369-d753-aa4417a9d75b"
      },
      "source": [
        "for i, layer in enumerate(conv_base_colour.layers):\n",
        "   print(i, layer.name, layer.trainable)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 input_3 False\n",
            "1 conv2d_95 False\n",
            "2 batch_normalization_94 True\n",
            "3 activation_94 False\n",
            "4 conv2d_96 False\n",
            "5 batch_normalization_95 True\n",
            "6 activation_95 False\n",
            "7 conv2d_97 False\n",
            "8 batch_normalization_96 True\n",
            "9 activation_96 False\n",
            "10 max_pooling2d_4 False\n",
            "11 conv2d_98 False\n",
            "12 batch_normalization_97 True\n",
            "13 activation_97 False\n",
            "14 conv2d_99 False\n",
            "15 batch_normalization_98 True\n",
            "16 activation_98 False\n",
            "17 max_pooling2d_5 False\n",
            "18 conv2d_103 False\n",
            "19 batch_normalization_102 True\n",
            "20 activation_102 False\n",
            "21 conv2d_101 False\n",
            "22 conv2d_104 False\n",
            "23 batch_normalization_100 True\n",
            "24 batch_normalization_103 True\n",
            "25 activation_100 False\n",
            "26 activation_103 False\n",
            "27 average_pooling2d_9 False\n",
            "28 conv2d_100 False\n",
            "29 conv2d_102 False\n",
            "30 conv2d_105 False\n",
            "31 conv2d_106 False\n",
            "32 batch_normalization_99 True\n",
            "33 batch_normalization_101 True\n",
            "34 batch_normalization_104 True\n",
            "35 batch_normalization_105 True\n",
            "36 activation_99 False\n",
            "37 activation_101 False\n",
            "38 activation_104 False\n",
            "39 activation_105 False\n",
            "40 mixed0 False\n",
            "41 conv2d_110 False\n",
            "42 batch_normalization_109 True\n",
            "43 activation_109 False\n",
            "44 conv2d_108 False\n",
            "45 conv2d_111 False\n",
            "46 batch_normalization_107 True\n",
            "47 batch_normalization_110 True\n",
            "48 activation_107 False\n",
            "49 activation_110 False\n",
            "50 average_pooling2d_10 False\n",
            "51 conv2d_107 False\n",
            "52 conv2d_109 False\n",
            "53 conv2d_112 False\n",
            "54 conv2d_113 False\n",
            "55 batch_normalization_106 True\n",
            "56 batch_normalization_108 True\n",
            "57 batch_normalization_111 True\n",
            "58 batch_normalization_112 True\n",
            "59 activation_106 False\n",
            "60 activation_108 False\n",
            "61 activation_111 False\n",
            "62 activation_112 False\n",
            "63 mixed1 False\n",
            "64 conv2d_117 False\n",
            "65 batch_normalization_116 True\n",
            "66 activation_116 False\n",
            "67 conv2d_115 False\n",
            "68 conv2d_118 False\n",
            "69 batch_normalization_114 True\n",
            "70 batch_normalization_117 True\n",
            "71 activation_114 False\n",
            "72 activation_117 False\n",
            "73 average_pooling2d_11 False\n",
            "74 conv2d_114 False\n",
            "75 conv2d_116 False\n",
            "76 conv2d_119 False\n",
            "77 conv2d_120 False\n",
            "78 batch_normalization_113 True\n",
            "79 batch_normalization_115 True\n",
            "80 batch_normalization_118 True\n",
            "81 batch_normalization_119 True\n",
            "82 activation_113 False\n",
            "83 activation_115 False\n",
            "84 activation_118 False\n",
            "85 activation_119 False\n",
            "86 mixed2 False\n",
            "87 conv2d_122 False\n",
            "88 batch_normalization_121 True\n",
            "89 activation_121 False\n",
            "90 conv2d_123 False\n",
            "91 batch_normalization_122 True\n",
            "92 activation_122 False\n",
            "93 conv2d_121 False\n",
            "94 conv2d_124 False\n",
            "95 batch_normalization_120 True\n",
            "96 batch_normalization_123 True\n",
            "97 activation_120 False\n",
            "98 activation_123 False\n",
            "99 max_pooling2d_6 False\n",
            "100 mixed3 False\n",
            "101 conv2d_129 False\n",
            "102 batch_normalization_128 True\n",
            "103 activation_128 False\n",
            "104 conv2d_130 False\n",
            "105 batch_normalization_129 True\n",
            "106 activation_129 False\n",
            "107 conv2d_126 False\n",
            "108 conv2d_131 False\n",
            "109 batch_normalization_125 True\n",
            "110 batch_normalization_130 True\n",
            "111 activation_125 False\n",
            "112 activation_130 False\n",
            "113 conv2d_127 False\n",
            "114 conv2d_132 False\n",
            "115 batch_normalization_126 True\n",
            "116 batch_normalization_131 True\n",
            "117 activation_126 False\n",
            "118 activation_131 False\n",
            "119 average_pooling2d_12 False\n",
            "120 conv2d_125 False\n",
            "121 conv2d_128 False\n",
            "122 conv2d_133 False\n",
            "123 conv2d_134 False\n",
            "124 batch_normalization_124 True\n",
            "125 batch_normalization_127 True\n",
            "126 batch_normalization_132 True\n",
            "127 batch_normalization_133 True\n",
            "128 activation_124 False\n",
            "129 activation_127 False\n",
            "130 activation_132 False\n",
            "131 activation_133 False\n",
            "132 mixed4 False\n",
            "133 conv2d_139 False\n",
            "134 batch_normalization_138 True\n",
            "135 activation_138 False\n",
            "136 conv2d_140 False\n",
            "137 batch_normalization_139 True\n",
            "138 activation_139 False\n",
            "139 conv2d_136 False\n",
            "140 conv2d_141 False\n",
            "141 batch_normalization_135 True\n",
            "142 batch_normalization_140 True\n",
            "143 activation_135 False\n",
            "144 activation_140 False\n",
            "145 conv2d_137 False\n",
            "146 conv2d_142 False\n",
            "147 batch_normalization_136 True\n",
            "148 batch_normalization_141 True\n",
            "149 activation_136 False\n",
            "150 activation_141 False\n",
            "151 average_pooling2d_13 False\n",
            "152 conv2d_135 False\n",
            "153 conv2d_138 False\n",
            "154 conv2d_143 False\n",
            "155 conv2d_144 False\n",
            "156 batch_normalization_134 True\n",
            "157 batch_normalization_137 True\n",
            "158 batch_normalization_142 True\n",
            "159 batch_normalization_143 True\n",
            "160 activation_134 False\n",
            "161 activation_137 False\n",
            "162 activation_142 False\n",
            "163 activation_143 False\n",
            "164 mixed5 False\n",
            "165 conv2d_149 False\n",
            "166 batch_normalization_148 True\n",
            "167 activation_148 False\n",
            "168 conv2d_150 False\n",
            "169 batch_normalization_149 True\n",
            "170 activation_149 False\n",
            "171 conv2d_146 False\n",
            "172 conv2d_151 False\n",
            "173 batch_normalization_145 True\n",
            "174 batch_normalization_150 True\n",
            "175 activation_145 False\n",
            "176 activation_150 False\n",
            "177 conv2d_147 False\n",
            "178 conv2d_152 False\n",
            "179 batch_normalization_146 True\n",
            "180 batch_normalization_151 True\n",
            "181 activation_146 False\n",
            "182 activation_151 False\n",
            "183 average_pooling2d_14 False\n",
            "184 conv2d_145 False\n",
            "185 conv2d_148 False\n",
            "186 conv2d_153 False\n",
            "187 conv2d_154 False\n",
            "188 batch_normalization_144 True\n",
            "189 batch_normalization_147 True\n",
            "190 batch_normalization_152 True\n",
            "191 batch_normalization_153 True\n",
            "192 activation_144 False\n",
            "193 activation_147 False\n",
            "194 activation_152 False\n",
            "195 activation_153 False\n",
            "196 mixed6 False\n",
            "197 conv2d_159 False\n",
            "198 batch_normalization_158 True\n",
            "199 activation_158 False\n",
            "200 conv2d_160 False\n",
            "201 batch_normalization_159 True\n",
            "202 activation_159 False\n",
            "203 conv2d_156 False\n",
            "204 conv2d_161 False\n",
            "205 batch_normalization_155 True\n",
            "206 batch_normalization_160 True\n",
            "207 activation_155 False\n",
            "208 activation_160 False\n",
            "209 conv2d_157 False\n",
            "210 conv2d_162 False\n",
            "211 batch_normalization_156 True\n",
            "212 batch_normalization_161 True\n",
            "213 activation_156 False\n",
            "214 activation_161 False\n",
            "215 average_pooling2d_15 False\n",
            "216 conv2d_155 False\n",
            "217 conv2d_158 False\n",
            "218 conv2d_163 False\n",
            "219 conv2d_164 False\n",
            "220 batch_normalization_154 True\n",
            "221 batch_normalization_157 True\n",
            "222 batch_normalization_162 True\n",
            "223 batch_normalization_163 True\n",
            "224 activation_154 False\n",
            "225 activation_157 False\n",
            "226 activation_162 False\n",
            "227 activation_163 False\n",
            "228 mixed7 False\n",
            "229 conv2d_167 False\n",
            "230 batch_normalization_166 True\n",
            "231 activation_166 False\n",
            "232 conv2d_168 False\n",
            "233 batch_normalization_167 True\n",
            "234 activation_167 False\n",
            "235 conv2d_165 False\n",
            "236 conv2d_169 False\n",
            "237 batch_normalization_164 True\n",
            "238 batch_normalization_168 True\n",
            "239 activation_164 False\n",
            "240 activation_168 False\n",
            "241 conv2d_166 False\n",
            "242 conv2d_170 False\n",
            "243 batch_normalization_165 True\n",
            "244 batch_normalization_169 True\n",
            "245 activation_165 False\n",
            "246 activation_169 False\n",
            "247 max_pooling2d_7 False\n",
            "248 mixed8 False\n",
            "249 conv2d_175 False\n",
            "250 batch_normalization_174 True\n",
            "251 activation_174 False\n",
            "252 conv2d_172 False\n",
            "253 conv2d_176 False\n",
            "254 batch_normalization_171 True\n",
            "255 batch_normalization_175 True\n",
            "256 activation_171 False\n",
            "257 activation_175 False\n",
            "258 conv2d_173 False\n",
            "259 conv2d_174 False\n",
            "260 conv2d_177 False\n",
            "261 conv2d_178 False\n",
            "262 average_pooling2d_16 False\n",
            "263 conv2d_171 False\n",
            "264 batch_normalization_172 True\n",
            "265 batch_normalization_173 True\n",
            "266 batch_normalization_176 True\n",
            "267 batch_normalization_177 True\n",
            "268 conv2d_179 False\n",
            "269 batch_normalization_170 True\n",
            "270 activation_172 False\n",
            "271 activation_173 False\n",
            "272 activation_176 False\n",
            "273 activation_177 False\n",
            "274 batch_normalization_178 True\n",
            "275 activation_170 False\n",
            "276 mixed9_0 False\n",
            "277 concatenate_2 False\n",
            "278 activation_178 False\n",
            "279 mixed9 False\n",
            "280 conv2d_184 False\n",
            "281 batch_normalization_183 True\n",
            "282 activation_183 False\n",
            "283 conv2d_181 False\n",
            "284 conv2d_185 False\n",
            "285 batch_normalization_180 True\n",
            "286 batch_normalization_184 True\n",
            "287 activation_180 False\n",
            "288 activation_184 False\n",
            "289 conv2d_182 False\n",
            "290 conv2d_183 False\n",
            "291 conv2d_186 False\n",
            "292 conv2d_187 False\n",
            "293 average_pooling2d_17 False\n",
            "294 conv2d_180 False\n",
            "295 batch_normalization_181 True\n",
            "296 batch_normalization_182 True\n",
            "297 batch_normalization_185 True\n",
            "298 batch_normalization_186 True\n",
            "299 conv2d_188 True\n",
            "300 batch_normalization_179 True\n",
            "301 activation_181 True\n",
            "302 activation_182 True\n",
            "303 activation_185 True\n",
            "304 activation_186 True\n",
            "305 batch_normalization_187 True\n",
            "306 activation_179 True\n",
            "307 mixed9_1 True\n",
            "308 concatenate_3 True\n",
            "309 activation_187 True\n",
            "310 mixed10 True\n",
            "311 global_average_pooling2d_1 True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lPX3WjtrL6rb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import Input "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBEiiUIqL80Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_tensor = Input(shape=(224,224,3))\n",
        "x = conv_base_colour(input_tensor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3uttgFYMEQj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = Dense(2048, activation='relu', kernel_regularizer= regularizers.l2(0.001))(x)\n",
        "x = Dropout(0.5)(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9XGPFSfMHfI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ouput = Dense(112, activation='softmax')(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yklGm-IGMLKi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "colour_model = Model(inputs = input_tensor, outputs = ouput )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cI4OUhkgMQTN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "colour_model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(lr=0.001),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4v7B5i7Mf33",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "checkpoint = ModelCheckpoint(\"/content/drive/My Drive/1-piece/Colour_InceptionV3.h5\",\n",
        "                             monitor=\"val_loss\",\n",
        "                             mode=\"min\",\n",
        "                             save_best_only = True,\n",
        "                             verbose=1)\n",
        "\n",
        "earlystop = EarlyStopping(monitor = 'val_loss', \n",
        "                          min_delta = 0, \n",
        "                          patience = 40,\n",
        "                          verbose = 1,\n",
        "                          restore_best_weights = True)\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(monitor = 'val_loss',\n",
        "                              factor = 0.2,\n",
        "                              patience = 40,\n",
        "                              verbose = 1,\n",
        "                              min_delta = 0.00001)\n",
        "\n",
        "callBacks = [earlystop, checkpoint, reduce_lr]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yaMZLpsAMz7e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3f64867d-cebb-4515-86b7-3bee6ccfbb83"
      },
      "source": [
        "hist = colour_model.fit_generator(steps_per_epoch=252,generator= Colour_TrainingData, validation_data= Colour_ValidData, validation_steps=14,epochs=150,callbacks=callBacks)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 6.0946 - accuracy: 0.0293\n",
            "Epoch 00001: val_loss improved from inf to 4.70998, saving model to /content/drive/My Drive/1-piece/Colour_InceptionV3.h5\n",
            "252/252 [==============================] - 90s 357ms/step - loss: 6.0946 - accuracy: 0.0293 - val_loss: 4.7100 - val_accuracy: 0.0804\n",
            "Epoch 2/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 4.5412 - accuracy: 0.0779\n",
            "Epoch 00002: val_loss improved from 4.70998 to 3.51492, saving model to /content/drive/My Drive/1-piece/Colour_InceptionV3.h5\n",
            "252/252 [==============================] - 90s 356ms/step - loss: 4.5412 - accuracy: 0.0779 - val_loss: 3.5149 - val_accuracy: 0.2679\n",
            "Epoch 3/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 3.8182 - accuracy: 0.1494\n",
            "Epoch 00003: val_loss improved from 3.51492 to 2.69684, saving model to /content/drive/My Drive/1-piece/Colour_InceptionV3.h5\n",
            "252/252 [==============================] - 90s 355ms/step - loss: 3.8182 - accuracy: 0.1494 - val_loss: 2.6968 - val_accuracy: 0.3929\n",
            "Epoch 4/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 3.3053 - accuracy: 0.2164\n",
            "Epoch 00004: val_loss improved from 2.69684 to 2.09938, saving model to /content/drive/My Drive/1-piece/Colour_InceptionV3.h5\n",
            "252/252 [==============================] - 90s 357ms/step - loss: 3.3053 - accuracy: 0.2164 - val_loss: 2.0994 - val_accuracy: 0.5893\n",
            "Epoch 5/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 2.9811 - accuracy: 0.2794\n",
            "Epoch 00005: val_loss improved from 2.09938 to 1.76869, saving model to /content/drive/My Drive/1-piece/Colour_InceptionV3.h5\n",
            "252/252 [==============================] - 90s 357ms/step - loss: 2.9811 - accuracy: 0.2794 - val_loss: 1.7687 - val_accuracy: 0.6250\n",
            "Epoch 6/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 2.6666 - accuracy: 0.3404\n",
            "Epoch 00006: val_loss improved from 1.76869 to 1.60957, saving model to /content/drive/My Drive/1-piece/Colour_InceptionV3.h5\n",
            "252/252 [==============================] - 90s 358ms/step - loss: 2.6666 - accuracy: 0.3404 - val_loss: 1.6096 - val_accuracy: 0.6696\n",
            "Epoch 7/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 2.5389 - accuracy: 0.3692\n",
            "Epoch 00007: val_loss improved from 1.60957 to 1.47992, saving model to /content/drive/My Drive/1-piece/Colour_InceptionV3.h5\n",
            "252/252 [==============================] - 90s 357ms/step - loss: 2.5389 - accuracy: 0.3692 - val_loss: 1.4799 - val_accuracy: 0.6964\n",
            "Epoch 8/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 2.3554 - accuracy: 0.4010\n",
            "Epoch 00008: val_loss improved from 1.47992 to 1.42189, saving model to /content/drive/My Drive/1-piece/Colour_InceptionV3.h5\n",
            "252/252 [==============================] - 89s 355ms/step - loss: 2.3554 - accuracy: 0.4010 - val_loss: 1.4219 - val_accuracy: 0.6786\n",
            "Epoch 9/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 2.2420 - accuracy: 0.4263\n",
            "Epoch 00009: val_loss improved from 1.42189 to 1.24009, saving model to /content/drive/My Drive/1-piece/Colour_InceptionV3.h5\n",
            "252/252 [==============================] - 89s 354ms/step - loss: 2.2420 - accuracy: 0.4263 - val_loss: 1.2401 - val_accuracy: 0.7054\n",
            "Epoch 10/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 2.1481 - accuracy: 0.4561\n",
            "Epoch 00010: val_loss improved from 1.24009 to 0.98020, saving model to /content/drive/My Drive/1-piece/Colour_InceptionV3.h5\n",
            "252/252 [==============================] - 89s 354ms/step - loss: 2.1481 - accuracy: 0.4561 - val_loss: 0.9802 - val_accuracy: 0.8482\n",
            "Epoch 11/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 2.0095 - accuracy: 0.4908\n",
            "Epoch 00011: val_loss did not improve from 0.98020\n",
            "252/252 [==============================] - 87s 344ms/step - loss: 2.0095 - accuracy: 0.4908 - val_loss: 0.9885 - val_accuracy: 0.8125\n",
            "Epoch 12/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 1.9629 - accuracy: 0.5007\n",
            "Epoch 00012: val_loss improved from 0.98020 to 0.96591, saving model to /content/drive/My Drive/1-piece/Colour_InceptionV3.h5\n",
            "252/252 [==============================] - 88s 351ms/step - loss: 1.9629 - accuracy: 0.5007 - val_loss: 0.9659 - val_accuracy: 0.8214\n",
            "Epoch 13/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 1.9150 - accuracy: 0.5151\n",
            "Epoch 00013: val_loss did not improve from 0.96591\n",
            "252/252 [==============================] - 87s 344ms/step - loss: 1.9150 - accuracy: 0.5151 - val_loss: 1.0009 - val_accuracy: 0.8125\n",
            "Epoch 14/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 1.7986 - accuracy: 0.5643\n",
            "Epoch 00014: val_loss improved from 0.96591 to 0.82024, saving model to /content/drive/My Drive/1-piece/Colour_InceptionV3.h5\n",
            "252/252 [==============================] - 90s 357ms/step - loss: 1.7986 - accuracy: 0.5643 - val_loss: 0.8202 - val_accuracy: 0.8125\n",
            "Epoch 15/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 1.8036 - accuracy: 0.5573\n",
            "Epoch 00015: val_loss did not improve from 0.82024\n",
            "252/252 [==============================] - 88s 348ms/step - loss: 1.8036 - accuracy: 0.5573 - val_loss: 0.8436 - val_accuracy: 0.8750\n",
            "Epoch 16/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 1.7366 - accuracy: 0.5658\n",
            "Epoch 00016: val_loss did not improve from 0.82024\n",
            "252/252 [==============================] - 87s 345ms/step - loss: 1.7366 - accuracy: 0.5658 - val_loss: 0.8593 - val_accuracy: 0.8036\n",
            "Epoch 17/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 1.6900 - accuracy: 0.5797\n",
            "Epoch 00017: val_loss improved from 0.82024 to 0.71434, saving model to /content/drive/My Drive/1-piece/Colour_InceptionV3.h5\n",
            "252/252 [==============================] - 89s 351ms/step - loss: 1.6900 - accuracy: 0.5797 - val_loss: 0.7143 - val_accuracy: 0.8661\n",
            "Epoch 18/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 1.6501 - accuracy: 0.5747\n",
            "Epoch 00018: val_loss did not improve from 0.71434\n",
            "252/252 [==============================] - 88s 347ms/step - loss: 1.6501 - accuracy: 0.5747 - val_loss: 0.8744 - val_accuracy: 0.8214\n",
            "Epoch 19/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 1.6165 - accuracy: 0.6094\n",
            "Epoch 00019: val_loss did not improve from 0.71434\n",
            "252/252 [==============================] - 87s 347ms/step - loss: 1.6165 - accuracy: 0.6094 - val_loss: 0.7462 - val_accuracy: 0.8661\n",
            "Epoch 20/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 1.5144 - accuracy: 0.6392\n",
            "Epoch 00020: val_loss improved from 0.71434 to 0.70214, saving model to /content/drive/My Drive/1-piece/Colour_InceptionV3.h5\n",
            "252/252 [==============================] - 90s 355ms/step - loss: 1.5144 - accuracy: 0.6392 - val_loss: 0.7021 - val_accuracy: 0.9018\n",
            "Epoch 21/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 1.5643 - accuracy: 0.6203\n",
            "Epoch 00021: val_loss did not improve from 0.70214\n",
            "252/252 [==============================] - 88s 350ms/step - loss: 1.5643 - accuracy: 0.6203 - val_loss: 0.7481 - val_accuracy: 0.8571\n",
            "Epoch 22/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 1.5066 - accuracy: 0.6397\n",
            "Epoch 00022: val_loss improved from 0.70214 to 0.63354, saving model to /content/drive/My Drive/1-piece/Colour_InceptionV3.h5\n",
            "252/252 [==============================] - 90s 358ms/step - loss: 1.5066 - accuracy: 0.6397 - val_loss: 0.6335 - val_accuracy: 0.8750\n",
            "Epoch 23/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 1.4256 - accuracy: 0.6720\n",
            "Epoch 00023: val_loss did not improve from 0.63354\n",
            "252/252 [==============================] - 88s 348ms/step - loss: 1.4256 - accuracy: 0.6720 - val_loss: 0.6811 - val_accuracy: 0.8571\n",
            "Epoch 24/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 1.4533 - accuracy: 0.6447\n",
            "Epoch 00024: val_loss did not improve from 0.63354\n",
            "252/252 [==============================] - 87s 345ms/step - loss: 1.4533 - accuracy: 0.6447 - val_loss: 0.7385 - val_accuracy: 0.8750\n",
            "Epoch 25/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 1.3691 - accuracy: 0.6834\n",
            "Epoch 00025: val_loss did not improve from 0.63354\n",
            "252/252 [==============================] - 87s 347ms/step - loss: 1.3691 - accuracy: 0.6834 - val_loss: 0.7014 - val_accuracy: 0.8482\n",
            "Epoch 26/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 1.3602 - accuracy: 0.6799\n",
            "Epoch 00026: val_loss did not improve from 0.63354\n",
            "252/252 [==============================] - 86s 343ms/step - loss: 1.3602 - accuracy: 0.6799 - val_loss: 0.7837 - val_accuracy: 0.8661\n",
            "Epoch 27/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 1.3370 - accuracy: 0.6854\n",
            "Epoch 00027: val_loss did not improve from 0.63354\n",
            "252/252 [==============================] - 86s 343ms/step - loss: 1.3370 - accuracy: 0.6854 - val_loss: 0.6700 - val_accuracy: 0.9107\n",
            "Epoch 28/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 1.3054 - accuracy: 0.6908\n",
            "Epoch 00028: val_loss improved from 0.63354 to 0.55622, saving model to /content/drive/My Drive/1-piece/Colour_InceptionV3.h5\n",
            "252/252 [==============================] - 89s 354ms/step - loss: 1.3054 - accuracy: 0.6908 - val_loss: 0.5562 - val_accuracy: 0.9018\n",
            "Epoch 29/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 1.3032 - accuracy: 0.6943\n",
            "Epoch 00029: val_loss improved from 0.55622 to 0.54743, saving model to /content/drive/My Drive/1-piece/Colour_InceptionV3.h5\n",
            "252/252 [==============================] - 89s 355ms/step - loss: 1.3032 - accuracy: 0.6943 - val_loss: 0.5474 - val_accuracy: 0.9196\n",
            "Epoch 30/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 1.2623 - accuracy: 0.6893\n",
            "Epoch 00030: val_loss did not improve from 0.54743\n",
            "252/252 [==============================] - 86s 342ms/step - loss: 1.2623 - accuracy: 0.6893 - val_loss: 0.5618 - val_accuracy: 0.8929\n",
            "Epoch 31/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 1.3073 - accuracy: 0.6864\n",
            "Epoch 00031: val_loss did not improve from 0.54743\n",
            "252/252 [==============================] - 86s 342ms/step - loss: 1.3073 - accuracy: 0.6864 - val_loss: 0.5490 - val_accuracy: 0.9286\n",
            "Epoch 32/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 1.2030 - accuracy: 0.7176\n",
            "Epoch 00032: val_loss improved from 0.54743 to 0.52103, saving model to /content/drive/My Drive/1-piece/Colour_InceptionV3.h5\n",
            "252/252 [==============================] - 89s 355ms/step - loss: 1.2030 - accuracy: 0.7176 - val_loss: 0.5210 - val_accuracy: 0.9018\n",
            "Epoch 33/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 1.2428 - accuracy: 0.6883\n",
            "Epoch 00033: val_loss improved from 0.52103 to 0.49125, saving model to /content/drive/My Drive/1-piece/Colour_InceptionV3.h5\n",
            "252/252 [==============================] - 89s 353ms/step - loss: 1.2428 - accuracy: 0.6883 - val_loss: 0.4913 - val_accuracy: 0.9196\n",
            "Epoch 34/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 1.1738 - accuracy: 0.7270\n",
            "Epoch 00034: val_loss did not improve from 0.49125\n",
            "252/252 [==============================] - 87s 347ms/step - loss: 1.1738 - accuracy: 0.7270 - val_loss: 0.5004 - val_accuracy: 0.9554\n",
            "Epoch 35/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 1.2348 - accuracy: 0.7022\n",
            "Epoch 00035: val_loss did not improve from 0.49125\n",
            "252/252 [==============================] - 87s 345ms/step - loss: 1.2348 - accuracy: 0.7022 - val_loss: 0.6035 - val_accuracy: 0.9375\n",
            "Epoch 36/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 1.1598 - accuracy: 0.7261\n",
            "Epoch 00036: val_loss did not improve from 0.49125\n",
            "252/252 [==============================] - 86s 341ms/step - loss: 1.1598 - accuracy: 0.7261 - val_loss: 0.5549 - val_accuracy: 0.9196\n",
            "Epoch 37/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 1.1370 - accuracy: 0.7275\n",
            "Epoch 00037: val_loss improved from 0.49125 to 0.41544, saving model to /content/drive/My Drive/1-piece/Colour_InceptionV3.h5\n",
            "252/252 [==============================] - 88s 351ms/step - loss: 1.1370 - accuracy: 0.7275 - val_loss: 0.4154 - val_accuracy: 0.9464\n",
            "Epoch 38/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 1.1279 - accuracy: 0.7266\n",
            "Epoch 00038: val_loss did not improve from 0.41544\n",
            "252/252 [==============================] - 87s 344ms/step - loss: 1.1279 - accuracy: 0.7266 - val_loss: 0.5002 - val_accuracy: 0.9286\n",
            "Epoch 39/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 1.1123 - accuracy: 0.7345\n",
            "Epoch 00039: val_loss did not improve from 0.41544\n",
            "252/252 [==============================] - 87s 345ms/step - loss: 1.1123 - accuracy: 0.7345 - val_loss: 0.4286 - val_accuracy: 0.9464\n",
            "Epoch 40/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 1.1032 - accuracy: 0.7439\n",
            "Epoch 00040: val_loss did not improve from 0.41544\n",
            "252/252 [==============================] - 86s 342ms/step - loss: 1.1032 - accuracy: 0.7439 - val_loss: 0.4683 - val_accuracy: 0.9464\n",
            "Epoch 41/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 1.0380 - accuracy: 0.7677\n",
            "Epoch 00041: val_loss did not improve from 0.41544\n",
            "252/252 [==============================] - 86s 340ms/step - loss: 1.0380 - accuracy: 0.7677 - val_loss: 0.4216 - val_accuracy: 0.9554\n",
            "Epoch 42/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 1.0689 - accuracy: 0.7340\n",
            "Epoch 00042: val_loss did not improve from 0.41544\n",
            "252/252 [==============================] - 86s 343ms/step - loss: 1.0689 - accuracy: 0.7340 - val_loss: 0.5372 - val_accuracy: 0.9196\n",
            "Epoch 43/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 1.0230 - accuracy: 0.7672\n",
            "Epoch 00043: val_loss improved from 0.41544 to 0.40946, saving model to /content/drive/My Drive/1-piece/Colour_InceptionV3.h5\n",
            "252/252 [==============================] - 89s 354ms/step - loss: 1.0230 - accuracy: 0.7672 - val_loss: 0.4095 - val_accuracy: 0.9643\n",
            "Epoch 44/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 1.0471 - accuracy: 0.7633\n",
            "Epoch 00044: val_loss did not improve from 0.40946\n",
            "252/252 [==============================] - 86s 343ms/step - loss: 1.0471 - accuracy: 0.7633 - val_loss: 0.4518 - val_accuracy: 0.9554\n",
            "Epoch 45/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 1.0242 - accuracy: 0.7613\n",
            "Epoch 00045: val_loss did not improve from 0.40946\n",
            "252/252 [==============================] - 87s 344ms/step - loss: 1.0242 - accuracy: 0.7613 - val_loss: 0.4943 - val_accuracy: 0.9196\n",
            "Epoch 46/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 1.0304 - accuracy: 0.7543\n",
            "Epoch 00046: val_loss did not improve from 0.40946\n",
            "252/252 [==============================] - 87s 347ms/step - loss: 1.0304 - accuracy: 0.7543 - val_loss: 0.4703 - val_accuracy: 0.9554\n",
            "Epoch 47/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.9693 - accuracy: 0.7821\n",
            "Epoch 00047: val_loss improved from 0.40946 to 0.33567, saving model to /content/drive/My Drive/1-piece/Colour_InceptionV3.h5\n",
            "252/252 [==============================] - 89s 355ms/step - loss: 0.9693 - accuracy: 0.7821 - val_loss: 0.3357 - val_accuracy: 0.9732\n",
            "Epoch 48/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 1.0203 - accuracy: 0.7578\n",
            "Epoch 00048: val_loss did not improve from 0.33567\n",
            "252/252 [==============================] - 88s 348ms/step - loss: 1.0203 - accuracy: 0.7578 - val_loss: 0.3895 - val_accuracy: 0.9554\n",
            "Epoch 49/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.9604 - accuracy: 0.7792\n",
            "Epoch 00049: val_loss improved from 0.33567 to 0.32302, saving model to /content/drive/My Drive/1-piece/Colour_InceptionV3.h5\n",
            "252/252 [==============================] - 89s 354ms/step - loss: 0.9604 - accuracy: 0.7792 - val_loss: 0.3230 - val_accuracy: 0.9643\n",
            "Epoch 50/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.9696 - accuracy: 0.7752\n",
            "Epoch 00050: val_loss did not improve from 0.32302\n",
            "252/252 [==============================] - 87s 347ms/step - loss: 0.9696 - accuracy: 0.7752 - val_loss: 0.3467 - val_accuracy: 0.9554\n",
            "Epoch 51/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.9354 - accuracy: 0.7826\n",
            "Epoch 00051: val_loss did not improve from 0.32302\n",
            "252/252 [==============================] - 86s 342ms/step - loss: 0.9354 - accuracy: 0.7826 - val_loss: 0.3927 - val_accuracy: 0.9732\n",
            "Epoch 52/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.9403 - accuracy: 0.7801\n",
            "Epoch 00052: val_loss did not improve from 0.32302\n",
            "252/252 [==============================] - 87s 344ms/step - loss: 0.9403 - accuracy: 0.7801 - val_loss: 0.3397 - val_accuracy: 0.9286\n",
            "Epoch 53/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.8380 - accuracy: 0.8139\n",
            "Epoch 00053: val_loss improved from 0.32302 to 0.30255, saving model to /content/drive/My Drive/1-piece/Colour_InceptionV3.h5\n",
            "252/252 [==============================] - 89s 353ms/step - loss: 0.8380 - accuracy: 0.8139 - val_loss: 0.3026 - val_accuracy: 0.9821\n",
            "Epoch 54/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.8898 - accuracy: 0.8065\n",
            "Epoch 00054: val_loss did not improve from 0.30255\n",
            "252/252 [==============================] - 87s 344ms/step - loss: 0.8898 - accuracy: 0.8065 - val_loss: 0.3203 - val_accuracy: 0.9643\n",
            "Epoch 55/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.9086 - accuracy: 0.7901\n",
            "Epoch 00055: val_loss did not improve from 0.30255\n",
            "252/252 [==============================] - 86s 341ms/step - loss: 0.9086 - accuracy: 0.7901 - val_loss: 0.3110 - val_accuracy: 0.9643\n",
            "Epoch 56/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.8744 - accuracy: 0.7965\n",
            "Epoch 00056: val_loss did not improve from 0.30255\n",
            "252/252 [==============================] - 86s 342ms/step - loss: 0.8744 - accuracy: 0.7965 - val_loss: 0.3660 - val_accuracy: 0.9643\n",
            "Epoch 57/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.8394 - accuracy: 0.8104\n",
            "Epoch 00057: val_loss did not improve from 0.30255\n",
            "252/252 [==============================] - 87s 345ms/step - loss: 0.8394 - accuracy: 0.8104 - val_loss: 0.3170 - val_accuracy: 0.9821\n",
            "Epoch 58/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.8846 - accuracy: 0.7980\n",
            "Epoch 00058: val_loss improved from 0.30255 to 0.28085, saving model to /content/drive/My Drive/1-piece/Colour_InceptionV3.h5\n",
            "252/252 [==============================] - 89s 354ms/step - loss: 0.8846 - accuracy: 0.7980 - val_loss: 0.2808 - val_accuracy: 0.9911\n",
            "Epoch 59/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.8530 - accuracy: 0.7990\n",
            "Epoch 00059: val_loss improved from 0.28085 to 0.26804, saving model to /content/drive/My Drive/1-piece/Colour_InceptionV3.h5\n",
            "252/252 [==============================] - 90s 357ms/step - loss: 0.8530 - accuracy: 0.7990 - val_loss: 0.2680 - val_accuracy: 0.9911\n",
            "Epoch 60/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.8338 - accuracy: 0.8094\n",
            "Epoch 00060: val_loss did not improve from 0.26804\n",
            "252/252 [==============================] - 88s 349ms/step - loss: 0.8338 - accuracy: 0.8094 - val_loss: 0.3163 - val_accuracy: 0.9554\n",
            "Epoch 61/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.8300 - accuracy: 0.8154\n",
            "Epoch 00061: val_loss did not improve from 0.26804\n",
            "252/252 [==============================] - 87s 346ms/step - loss: 0.8300 - accuracy: 0.8154 - val_loss: 0.3313 - val_accuracy: 0.9732\n",
            "Epoch 62/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.7763 - accuracy: 0.8174\n",
            "Epoch 00062: val_loss did not improve from 0.26804\n",
            "252/252 [==============================] - 86s 343ms/step - loss: 0.7763 - accuracy: 0.8174 - val_loss: 0.3447 - val_accuracy: 0.9464\n",
            "Epoch 63/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.7913 - accuracy: 0.8194\n",
            "Epoch 00063: val_loss did not improve from 0.26804\n",
            "252/252 [==============================] - 87s 343ms/step - loss: 0.7913 - accuracy: 0.8194 - val_loss: 0.3436 - val_accuracy: 0.9732\n",
            "Epoch 64/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.7769 - accuracy: 0.8362\n",
            "Epoch 00064: val_loss did not improve from 0.26804\n",
            "252/252 [==============================] - 87s 347ms/step - loss: 0.7769 - accuracy: 0.8362 - val_loss: 0.3078 - val_accuracy: 0.9643\n",
            "Epoch 65/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.7918 - accuracy: 0.8218\n",
            "Epoch 00065: val_loss improved from 0.26804 to 0.25401, saving model to /content/drive/My Drive/1-piece/Colour_InceptionV3.h5\n",
            "252/252 [==============================] - 89s 353ms/step - loss: 0.7918 - accuracy: 0.8218 - val_loss: 0.2540 - val_accuracy: 0.9911\n",
            "Epoch 66/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.7842 - accuracy: 0.8273\n",
            "Epoch 00066: val_loss did not improve from 0.25401\n",
            "252/252 [==============================] - 87s 344ms/step - loss: 0.7842 - accuracy: 0.8273 - val_loss: 0.2805 - val_accuracy: 0.9732\n",
            "Epoch 67/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.8157 - accuracy: 0.8005\n",
            "Epoch 00067: val_loss improved from 0.25401 to 0.25358, saving model to /content/drive/My Drive/1-piece/Colour_InceptionV3.h5\n",
            "252/252 [==============================] - 90s 357ms/step - loss: 0.8157 - accuracy: 0.8005 - val_loss: 0.2536 - val_accuracy: 0.9911\n",
            "Epoch 68/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.7646 - accuracy: 0.8263\n",
            "Epoch 00068: val_loss did not improve from 0.25358\n",
            "252/252 [==============================] - 87s 346ms/step - loss: 0.7646 - accuracy: 0.8263 - val_loss: 0.2957 - val_accuracy: 0.9643\n",
            "Epoch 69/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.7788 - accuracy: 0.8169\n",
            "Epoch 00069: val_loss improved from 0.25358 to 0.24016, saving model to /content/drive/My Drive/1-piece/Colour_InceptionV3.h5\n",
            "252/252 [==============================] - 89s 353ms/step - loss: 0.7788 - accuracy: 0.8169 - val_loss: 0.2402 - val_accuracy: 0.9911\n",
            "Epoch 70/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.7705 - accuracy: 0.8263\n",
            "Epoch 00070: val_loss did not improve from 0.24016\n",
            "252/252 [==============================] - 87s 346ms/step - loss: 0.7705 - accuracy: 0.8263 - val_loss: 0.3153 - val_accuracy: 0.9554\n",
            "Epoch 71/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.7641 - accuracy: 0.8248\n",
            "Epoch 00071: val_loss did not improve from 0.24016\n",
            "252/252 [==============================] - 87s 345ms/step - loss: 0.7641 - accuracy: 0.8248 - val_loss: 0.3105 - val_accuracy: 0.9732\n",
            "Epoch 72/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.7245 - accuracy: 0.8407\n",
            "Epoch 00072: val_loss did not improve from 0.24016\n",
            "252/252 [==============================] - 86s 340ms/step - loss: 0.7245 - accuracy: 0.8407 - val_loss: 0.2988 - val_accuracy: 0.9732\n",
            "Epoch 73/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.7228 - accuracy: 0.8387\n",
            "Epoch 00073: val_loss did not improve from 0.24016\n",
            "252/252 [==============================] - 86s 342ms/step - loss: 0.7228 - accuracy: 0.8387 - val_loss: 0.2921 - val_accuracy: 0.9732\n",
            "Epoch 74/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.7873 - accuracy: 0.8184\n",
            "Epoch 00074: val_loss did not improve from 0.24016\n",
            "252/252 [==============================] - 87s 347ms/step - loss: 0.7873 - accuracy: 0.8184 - val_loss: 0.2822 - val_accuracy: 0.9643\n",
            "Epoch 75/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.7592 - accuracy: 0.8308\n",
            "Epoch 00075: val_loss did not improve from 0.24016\n",
            "252/252 [==============================] - 87s 344ms/step - loss: 0.7592 - accuracy: 0.8308 - val_loss: 0.2622 - val_accuracy: 0.9643\n",
            "Epoch 76/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.7614 - accuracy: 0.8278\n",
            "Epoch 00076: val_loss did not improve from 0.24016\n",
            "252/252 [==============================] - 87s 345ms/step - loss: 0.7614 - accuracy: 0.8278 - val_loss: 0.3092 - val_accuracy: 0.9643\n",
            "Epoch 77/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.7105 - accuracy: 0.8397\n",
            "Epoch 00077: val_loss did not improve from 0.24016\n",
            "252/252 [==============================] - 86s 342ms/step - loss: 0.7105 - accuracy: 0.8397 - val_loss: 0.3099 - val_accuracy: 0.9732\n",
            "Epoch 78/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.6931 - accuracy: 0.8422\n",
            "Epoch 00078: val_loss improved from 0.24016 to 0.23864, saving model to /content/drive/My Drive/1-piece/Colour_InceptionV3.h5\n",
            "252/252 [==============================] - 90s 355ms/step - loss: 0.6931 - accuracy: 0.8422 - val_loss: 0.2386 - val_accuracy: 0.9732\n",
            "Epoch 79/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.6963 - accuracy: 0.8442\n",
            "Epoch 00079: val_loss did not improve from 0.23864\n",
            "252/252 [==============================] - 87s 346ms/step - loss: 0.6963 - accuracy: 0.8442 - val_loss: 0.2482 - val_accuracy: 0.9821\n",
            "Epoch 80/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.7087 - accuracy: 0.8397\n",
            "Epoch 00080: val_loss did not improve from 0.23864\n",
            "252/252 [==============================] - 87s 344ms/step - loss: 0.7087 - accuracy: 0.8397 - val_loss: 0.2715 - val_accuracy: 0.9643\n",
            "Epoch 81/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.6735 - accuracy: 0.8521\n",
            "Epoch 00081: val_loss did not improve from 0.23864\n",
            "252/252 [==============================] - 88s 348ms/step - loss: 0.6735 - accuracy: 0.8521 - val_loss: 0.3065 - val_accuracy: 0.9643\n",
            "Epoch 82/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.6752 - accuracy: 0.8392\n",
            "Epoch 00082: val_loss did not improve from 0.23864\n",
            "252/252 [==============================] - 87s 346ms/step - loss: 0.6752 - accuracy: 0.8392 - val_loss: 0.3104 - val_accuracy: 0.9732\n",
            "Epoch 83/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.7020 - accuracy: 0.8352\n",
            "Epoch 00083: val_loss did not improve from 0.23864\n",
            "252/252 [==============================] - 87s 346ms/step - loss: 0.7020 - accuracy: 0.8352 - val_loss: 0.2585 - val_accuracy: 0.9821\n",
            "Epoch 84/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.6787 - accuracy: 0.8457\n",
            "Epoch 00084: val_loss did not improve from 0.23864\n",
            "252/252 [==============================] - 87s 345ms/step - loss: 0.6787 - accuracy: 0.8457 - val_loss: 0.2695 - val_accuracy: 0.9821\n",
            "Epoch 85/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.6742 - accuracy: 0.8526\n",
            "Epoch 00085: val_loss did not improve from 0.23864\n",
            "252/252 [==============================] - 88s 348ms/step - loss: 0.6742 - accuracy: 0.8526 - val_loss: 0.2792 - val_accuracy: 0.9821\n",
            "Epoch 86/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.6838 - accuracy: 0.8457\n",
            "Epoch 00086: val_loss did not improve from 0.23864\n",
            "252/252 [==============================] - 87s 346ms/step - loss: 0.6838 - accuracy: 0.8457 - val_loss: 0.2466 - val_accuracy: 0.9732\n",
            "Epoch 87/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.7544 - accuracy: 0.8278\n",
            "Epoch 00087: val_loss did not improve from 0.23864\n",
            "252/252 [==============================] - 87s 344ms/step - loss: 0.7544 - accuracy: 0.8278 - val_loss: 0.2454 - val_accuracy: 0.9732\n",
            "Epoch 88/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.6677 - accuracy: 0.8427\n",
            "Epoch 00088: val_loss did not improve from 0.23864\n",
            "252/252 [==============================] - 86s 342ms/step - loss: 0.6677 - accuracy: 0.8427 - val_loss: 0.2635 - val_accuracy: 0.9821\n",
            "Epoch 89/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.6718 - accuracy: 0.8447\n",
            "Epoch 00089: val_loss did not improve from 0.23864\n",
            "252/252 [==============================] - 87s 345ms/step - loss: 0.6718 - accuracy: 0.8447 - val_loss: 0.2879 - val_accuracy: 0.9554\n",
            "Epoch 90/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.6632 - accuracy: 0.8521\n",
            "Epoch 00090: val_loss did not improve from 0.23864\n",
            "252/252 [==============================] - 87s 345ms/step - loss: 0.6632 - accuracy: 0.8521 - val_loss: 0.2651 - val_accuracy: 0.9732\n",
            "Epoch 91/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.6655 - accuracy: 0.8476\n",
            "Epoch 00091: val_loss did not improve from 0.23864\n",
            "252/252 [==============================] - 86s 342ms/step - loss: 0.6655 - accuracy: 0.8476 - val_loss: 0.3471 - val_accuracy: 0.9554\n",
            "Epoch 92/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.6514 - accuracy: 0.8571\n",
            "Epoch 00092: val_loss did not improve from 0.23864\n",
            "252/252 [==============================] - 87s 344ms/step - loss: 0.6514 - accuracy: 0.8571 - val_loss: 0.2573 - val_accuracy: 0.9732\n",
            "Epoch 93/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.6420 - accuracy: 0.8536\n",
            "Epoch 00093: val_loss improved from 0.23864 to 0.22990, saving model to /content/drive/My Drive/1-piece/Colour_InceptionV3.h5\n",
            "252/252 [==============================] - 89s 353ms/step - loss: 0.6420 - accuracy: 0.8536 - val_loss: 0.2299 - val_accuracy: 0.9911\n",
            "Epoch 94/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.6883 - accuracy: 0.8591\n",
            "Epoch 00094: val_loss did not improve from 0.22990\n",
            "252/252 [==============================] - 87s 347ms/step - loss: 0.6883 - accuracy: 0.8591 - val_loss: 0.2418 - val_accuracy: 0.9821\n",
            "Epoch 95/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.6610 - accuracy: 0.8526\n",
            "Epoch 00095: val_loss improved from 0.22990 to 0.19902, saving model to /content/drive/My Drive/1-piece/Colour_InceptionV3.h5\n",
            "252/252 [==============================] - 90s 356ms/step - loss: 0.6610 - accuracy: 0.8526 - val_loss: 0.1990 - val_accuracy: 0.9911\n",
            "Epoch 96/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.6427 - accuracy: 0.8481\n",
            "Epoch 00096: val_loss did not improve from 0.19902\n",
            "252/252 [==============================] - 88s 349ms/step - loss: 0.6427 - accuracy: 0.8481 - val_loss: 0.2896 - val_accuracy: 0.9732\n",
            "Epoch 97/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.6051 - accuracy: 0.8725\n",
            "Epoch 00097: val_loss did not improve from 0.19902\n",
            "252/252 [==============================] - 87s 345ms/step - loss: 0.6051 - accuracy: 0.8725 - val_loss: 0.3360 - val_accuracy: 0.9464\n",
            "Epoch 98/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.6316 - accuracy: 0.8531\n",
            "Epoch 00098: val_loss did not improve from 0.19902\n",
            "252/252 [==============================] - 86s 340ms/step - loss: 0.6316 - accuracy: 0.8531 - val_loss: 0.3038 - val_accuracy: 0.9821\n",
            "Epoch 99/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.6472 - accuracy: 0.8491\n",
            "Epoch 00099: val_loss did not improve from 0.19902\n",
            "252/252 [==============================] - 87s 343ms/step - loss: 0.6472 - accuracy: 0.8491 - val_loss: 0.2640 - val_accuracy: 0.9643\n",
            "Epoch 100/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.5937 - accuracy: 0.8635\n",
            "Epoch 00100: val_loss did not improve from 0.19902\n",
            "252/252 [==============================] - 85s 339ms/step - loss: 0.5937 - accuracy: 0.8635 - val_loss: 0.2616 - val_accuracy: 0.9732\n",
            "Epoch 101/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.6076 - accuracy: 0.8610\n",
            "Epoch 00101: val_loss did not improve from 0.19902\n",
            "252/252 [==============================] - 85s 339ms/step - loss: 0.6076 - accuracy: 0.8610 - val_loss: 0.2263 - val_accuracy: 0.9643\n",
            "Epoch 102/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.5921 - accuracy: 0.8715\n",
            "Epoch 00102: val_loss did not improve from 0.19902\n",
            "252/252 [==============================] - 86s 340ms/step - loss: 0.5921 - accuracy: 0.8715 - val_loss: 0.2090 - val_accuracy: 0.9821\n",
            "Epoch 103/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.6130 - accuracy: 0.8576\n",
            "Epoch 00103: val_loss improved from 0.19902 to 0.18651, saving model to /content/drive/My Drive/1-piece/Colour_InceptionV3.h5\n",
            "252/252 [==============================] - 89s 353ms/step - loss: 0.6130 - accuracy: 0.8576 - val_loss: 0.1865 - val_accuracy: 1.0000\n",
            "Epoch 104/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.6115 - accuracy: 0.8591\n",
            "Epoch 00104: val_loss did not improve from 0.18651\n",
            "252/252 [==============================] - 86s 343ms/step - loss: 0.6115 - accuracy: 0.8591 - val_loss: 0.2107 - val_accuracy: 0.9732\n",
            "Epoch 105/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.6249 - accuracy: 0.8591\n",
            "Epoch 00105: val_loss did not improve from 0.18651\n",
            "252/252 [==============================] - 86s 340ms/step - loss: 0.6249 - accuracy: 0.8591 - val_loss: 0.2665 - val_accuracy: 0.9821\n",
            "Epoch 106/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.5991 - accuracy: 0.8680\n",
            "Epoch 00106: val_loss did not improve from 0.18651\n",
            "252/252 [==============================] - 86s 343ms/step - loss: 0.5991 - accuracy: 0.8680 - val_loss: 0.2333 - val_accuracy: 0.9732\n",
            "Epoch 107/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.5960 - accuracy: 0.8690\n",
            "Epoch 00107: val_loss did not improve from 0.18651\n",
            "252/252 [==============================] - 86s 343ms/step - loss: 0.5960 - accuracy: 0.8690 - val_loss: 0.2392 - val_accuracy: 0.9821\n",
            "Epoch 108/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.5944 - accuracy: 0.8710\n",
            "Epoch 00108: val_loss did not improve from 0.18651\n",
            "252/252 [==============================] - 86s 342ms/step - loss: 0.5944 - accuracy: 0.8710 - val_loss: 0.2005 - val_accuracy: 0.9911\n",
            "Epoch 109/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.5707 - accuracy: 0.8710\n",
            "Epoch 00109: val_loss did not improve from 0.18651\n",
            "252/252 [==============================] - 87s 344ms/step - loss: 0.5707 - accuracy: 0.8710 - val_loss: 0.2521 - val_accuracy: 0.9821\n",
            "Epoch 110/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.5994 - accuracy: 0.8620\n",
            "Epoch 00110: val_loss did not improve from 0.18651\n",
            "252/252 [==============================] - 87s 346ms/step - loss: 0.5994 - accuracy: 0.8620 - val_loss: 0.2765 - val_accuracy: 0.9643\n",
            "Epoch 111/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.5823 - accuracy: 0.8705\n",
            "Epoch 00111: val_loss did not improve from 0.18651\n",
            "252/252 [==============================] - 87s 345ms/step - loss: 0.5823 - accuracy: 0.8705 - val_loss: 0.1957 - val_accuracy: 0.9821\n",
            "Epoch 112/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.5527 - accuracy: 0.8769\n",
            "Epoch 00112: val_loss did not improve from 0.18651\n",
            "252/252 [==============================] - 86s 343ms/step - loss: 0.5527 - accuracy: 0.8769 - val_loss: 0.2025 - val_accuracy: 0.9911\n",
            "Epoch 113/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.5859 - accuracy: 0.8680\n",
            "Epoch 00113: val_loss did not improve from 0.18651\n",
            "252/252 [==============================] - 86s 342ms/step - loss: 0.5859 - accuracy: 0.8680 - val_loss: 0.2261 - val_accuracy: 0.9732\n",
            "Epoch 114/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.6081 - accuracy: 0.8650\n",
            "Epoch 00114: val_loss improved from 0.18651 to 0.18115, saving model to /content/drive/My Drive/1-piece/Colour_InceptionV3.h5\n",
            "252/252 [==============================] - 89s 354ms/step - loss: 0.6081 - accuracy: 0.8650 - val_loss: 0.1811 - val_accuracy: 1.0000\n",
            "Epoch 115/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.5738 - accuracy: 0.8730\n",
            "Epoch 00115: val_loss did not improve from 0.18115\n",
            "252/252 [==============================] - 90s 356ms/step - loss: 0.5738 - accuracy: 0.8730 - val_loss: 0.2417 - val_accuracy: 0.9821\n",
            "Epoch 116/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.5461 - accuracy: 0.8834\n",
            "Epoch 00116: val_loss did not improve from 0.18115\n",
            "252/252 [==============================] - 87s 346ms/step - loss: 0.5461 - accuracy: 0.8834 - val_loss: 0.1957 - val_accuracy: 0.9911\n",
            "Epoch 117/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.5731 - accuracy: 0.8695\n",
            "Epoch 00117: val_loss did not improve from 0.18115\n",
            "252/252 [==============================] - 87s 347ms/step - loss: 0.5731 - accuracy: 0.8695 - val_loss: 0.2592 - val_accuracy: 0.9821\n",
            "Epoch 118/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.5331 - accuracy: 0.8864\n",
            "Epoch 00118: val_loss did not improve from 0.18115\n",
            "252/252 [==============================] - 87s 344ms/step - loss: 0.5331 - accuracy: 0.8864 - val_loss: 0.1903 - val_accuracy: 0.9911\n",
            "Epoch 119/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.5826 - accuracy: 0.8759\n",
            "Epoch 00119: val_loss did not improve from 0.18115\n",
            "252/252 [==============================] - 87s 345ms/step - loss: 0.5826 - accuracy: 0.8759 - val_loss: 0.2047 - val_accuracy: 0.9911\n",
            "Epoch 120/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.5354 - accuracy: 0.8859\n",
            "Epoch 00120: val_loss did not improve from 0.18115\n",
            "252/252 [==============================] - 87s 345ms/step - loss: 0.5354 - accuracy: 0.8859 - val_loss: 0.2654 - val_accuracy: 0.9732\n",
            "Epoch 121/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.5281 - accuracy: 0.8804\n",
            "Epoch 00121: val_loss did not improve from 0.18115\n",
            "252/252 [==============================] - 87s 344ms/step - loss: 0.5281 - accuracy: 0.8804 - val_loss: 0.2108 - val_accuracy: 0.9821\n",
            "Epoch 122/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.5434 - accuracy: 0.8734\n",
            "Epoch 00122: val_loss did not improve from 0.18115\n",
            "252/252 [==============================] - 86s 343ms/step - loss: 0.5434 - accuracy: 0.8734 - val_loss: 0.1820 - val_accuracy: 0.9911\n",
            "Epoch 123/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.5421 - accuracy: 0.8814\n",
            "Epoch 00123: val_loss did not improve from 0.18115\n",
            "252/252 [==============================] - 88s 349ms/step - loss: 0.5421 - accuracy: 0.8814 - val_loss: 0.2300 - val_accuracy: 0.9821\n",
            "Epoch 124/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.5368 - accuracy: 0.8804\n",
            "Epoch 00124: val_loss improved from 0.18115 to 0.17134, saving model to /content/drive/My Drive/1-piece/Colour_InceptionV3.h5\n",
            "252/252 [==============================] - 90s 357ms/step - loss: 0.5368 - accuracy: 0.8804 - val_loss: 0.1713 - val_accuracy: 1.0000\n",
            "Epoch 125/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.5317 - accuracy: 0.8908\n",
            "Epoch 00125: val_loss did not improve from 0.17134\n",
            "252/252 [==============================] - 88s 347ms/step - loss: 0.5317 - accuracy: 0.8908 - val_loss: 0.1805 - val_accuracy: 0.9911\n",
            "Epoch 126/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.5417 - accuracy: 0.8799\n",
            "Epoch 00126: val_loss did not improve from 0.17134\n",
            "252/252 [==============================] - 88s 350ms/step - loss: 0.5417 - accuracy: 0.8799 - val_loss: 0.2438 - val_accuracy: 0.9732\n",
            "Epoch 127/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.5186 - accuracy: 0.8888\n",
            "Epoch 00127: val_loss did not improve from 0.17134\n",
            "252/252 [==============================] - 87s 344ms/step - loss: 0.5186 - accuracy: 0.8888 - val_loss: 0.1973 - val_accuracy: 0.9732\n",
            "Epoch 128/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.5378 - accuracy: 0.8779\n",
            "Epoch 00128: val_loss improved from 0.17134 to 0.17051, saving model to /content/drive/My Drive/1-piece/Colour_InceptionV3.h5\n",
            "252/252 [==============================] - 88s 351ms/step - loss: 0.5378 - accuracy: 0.8779 - val_loss: 0.1705 - val_accuracy: 1.0000\n",
            "Epoch 129/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.5323 - accuracy: 0.8854\n",
            "Epoch 00129: val_loss did not improve from 0.17051\n",
            "252/252 [==============================] - 88s 348ms/step - loss: 0.5323 - accuracy: 0.8854 - val_loss: 0.1862 - val_accuracy: 0.9911\n",
            "Epoch 130/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.4932 - accuracy: 0.8948\n",
            "Epoch 00130: val_loss did not improve from 0.17051\n",
            "252/252 [==============================] - 87s 346ms/step - loss: 0.4932 - accuracy: 0.8948 - val_loss: 0.1711 - val_accuracy: 0.9821\n",
            "Epoch 131/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.5311 - accuracy: 0.8814\n",
            "Epoch 00131: val_loss did not improve from 0.17051\n",
            "252/252 [==============================] - 87s 344ms/step - loss: 0.5311 - accuracy: 0.8814 - val_loss: 0.2061 - val_accuracy: 0.9821\n",
            "Epoch 132/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.5431 - accuracy: 0.8779\n",
            "Epoch 00132: val_loss did not improve from 0.17051\n",
            "252/252 [==============================] - 86s 341ms/step - loss: 0.5431 - accuracy: 0.8779 - val_loss: 0.1900 - val_accuracy: 0.9911\n",
            "Epoch 133/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.4879 - accuracy: 0.8913\n",
            "Epoch 00133: val_loss did not improve from 0.17051\n",
            "252/252 [==============================] - 86s 341ms/step - loss: 0.4879 - accuracy: 0.8913 - val_loss: 0.2335 - val_accuracy: 0.9732\n",
            "Epoch 134/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.5098 - accuracy: 0.8898\n",
            "Epoch 00134: val_loss improved from 0.17051 to 0.16281, saving model to /content/drive/My Drive/1-piece/Colour_InceptionV3.h5\n",
            "252/252 [==============================] - 89s 351ms/step - loss: 0.5098 - accuracy: 0.8898 - val_loss: 0.1628 - val_accuracy: 0.9911\n",
            "Epoch 135/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.5321 - accuracy: 0.8779\n",
            "Epoch 00135: val_loss did not improve from 0.16281\n",
            "252/252 [==============================] - 88s 349ms/step - loss: 0.5321 - accuracy: 0.8779 - val_loss: 0.2519 - val_accuracy: 0.9732\n",
            "Epoch 136/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.5317 - accuracy: 0.8759\n",
            "Epoch 00136: val_loss did not improve from 0.16281\n",
            "252/252 [==============================] - 87s 344ms/step - loss: 0.5317 - accuracy: 0.8759 - val_loss: 0.1750 - val_accuracy: 0.9911\n",
            "Epoch 137/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.5438 - accuracy: 0.8754\n",
            "Epoch 00137: val_loss did not improve from 0.16281\n",
            "252/252 [==============================] - 87s 345ms/step - loss: 0.5438 - accuracy: 0.8754 - val_loss: 0.1654 - val_accuracy: 1.0000\n",
            "Epoch 138/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.5725 - accuracy: 0.8774\n",
            "Epoch 00138: val_loss did not improve from 0.16281\n",
            "252/252 [==============================] - 87s 347ms/step - loss: 0.5725 - accuracy: 0.8774 - val_loss: 0.2085 - val_accuracy: 0.9821\n",
            "Epoch 139/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.5051 - accuracy: 0.8913\n",
            "Epoch 00139: val_loss did not improve from 0.16281\n",
            "252/252 [==============================] - 87s 346ms/step - loss: 0.5051 - accuracy: 0.8913 - val_loss: 0.1980 - val_accuracy: 0.9732\n",
            "Epoch 140/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.5269 - accuracy: 0.8829\n",
            "Epoch 00140: val_loss did not improve from 0.16281\n",
            "252/252 [==============================] - 86s 341ms/step - loss: 0.5269 - accuracy: 0.8829 - val_loss: 0.1708 - val_accuracy: 0.9911\n",
            "Epoch 141/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.4899 - accuracy: 0.8998\n",
            "Epoch 00141: val_loss did not improve from 0.16281\n",
            "252/252 [==============================] - 86s 341ms/step - loss: 0.4899 - accuracy: 0.8998 - val_loss: 0.2200 - val_accuracy: 0.9732\n",
            "Epoch 142/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.4882 - accuracy: 0.8908\n",
            "Epoch 00142: val_loss did not improve from 0.16281\n",
            "252/252 [==============================] - 86s 340ms/step - loss: 0.4882 - accuracy: 0.8908 - val_loss: 0.1677 - val_accuracy: 0.9911\n",
            "Epoch 143/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.5109 - accuracy: 0.8834\n",
            "Epoch 00143: val_loss did not improve from 0.16281\n",
            "252/252 [==============================] - 85s 338ms/step - loss: 0.5109 - accuracy: 0.8834 - val_loss: 0.1775 - val_accuracy: 1.0000\n",
            "Epoch 144/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.4989 - accuracy: 0.8968\n",
            "Epoch 00144: val_loss did not improve from 0.16281\n",
            "252/252 [==============================] - 85s 338ms/step - loss: 0.4989 - accuracy: 0.8968 - val_loss: 0.1870 - val_accuracy: 0.9821\n",
            "Epoch 145/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.5099 - accuracy: 0.8883\n",
            "Epoch 00145: val_loss did not improve from 0.16281\n",
            "252/252 [==============================] - 85s 338ms/step - loss: 0.5099 - accuracy: 0.8883 - val_loss: 0.1781 - val_accuracy: 0.9911\n",
            "Epoch 146/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.4335 - accuracy: 0.9097\n",
            "Epoch 00146: val_loss did not improve from 0.16281\n",
            "252/252 [==============================] - 85s 337ms/step - loss: 0.4335 - accuracy: 0.9097 - val_loss: 0.2063 - val_accuracy: 0.9821\n",
            "Epoch 147/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.5106 - accuracy: 0.8734\n",
            "Epoch 00147: val_loss did not improve from 0.16281\n",
            "252/252 [==============================] - 85s 336ms/step - loss: 0.5106 - accuracy: 0.8734 - val_loss: 0.1823 - val_accuracy: 0.9911\n",
            "Epoch 148/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.4883 - accuracy: 0.8878\n",
            "Epoch 00148: val_loss did not improve from 0.16281\n",
            "252/252 [==============================] - 85s 336ms/step - loss: 0.4883 - accuracy: 0.8878 - val_loss: 0.1992 - val_accuracy: 0.9821\n",
            "Epoch 149/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.5026 - accuracy: 0.8849\n",
            "Epoch 00149: val_loss did not improve from 0.16281\n",
            "252/252 [==============================] - 85s 337ms/step - loss: 0.5026 - accuracy: 0.8849 - val_loss: 0.1761 - val_accuracy: 0.9911\n",
            "Epoch 150/150\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.4851 - accuracy: 0.8983\n",
            "Epoch 00150: val_loss did not improve from 0.16281\n",
            "252/252 [==============================] - 85s 335ms/step - loss: 0.4851 - accuracy: 0.8983 - val_loss: 0.1730 - val_accuracy: 0.9821\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZD3o1_jNFdU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "a233606b-578a-4b8b-dbbb-293046e3e56d"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(hist.history[\"accuracy\"])\n",
        "plt.plot(hist.history['val_accuracy'])\n",
        "plt.title(\"model accuracy\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.legend([\"Accuracy\",\"Validation Accuracy\"])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pIX7hNiiNKiC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "a3463f6b-cb51-4393-cf7d-e724cbf6b7fd"
      },
      "source": [
        "plt.plot(hist.history['loss'])\n",
        "plt.plot(hist.history['val_loss'])\n",
        "plt.title(\"model Loss\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.legend([\"Loss\",\"Validation Loss\"])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ty3i6zFRNMNS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d33d1adc-ab74-4d47-f19a-08e07c493d0e"
      },
      "source": [
        "Colour_TestData = TestGenerator.flow_from_directory('/content/drive/My Drive/1-piece/Test/', target_size=(224,224), batch_size = 8, shuffle = False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 112 images belonging to 112 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nq_iPyotOgaL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Colour_predict = colour_model.predict(Colour_TestData)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TsPBSBl8OndK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Colour_predict_classes = np.argmax(Colour_predict, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rvyl2C1yOqD_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "aaa4ad46-b3ac-4a64-85f8-253b8aba0180"
      },
      "source": [
        "Colour_predict_classes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  0,   1,  15,   3,   4,   5,   6,   7,   6,   9,  10,  11,  12,\n",
              "        14,  14,  15,  16,  23,  19,  19,  20,  21,  13,  23,  24,  25,\n",
              "        26,  27,  28,  27,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
              "        39,  40,  41,  42,  43,  44,  51,  46,  47,  47,  49,  50,  51,\n",
              "        52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  51,  63,  64,\n",
              "        67,  66,  67,  68,  69,   1,  71,  98,  73,  74,  98,  76,  77,\n",
              "       108,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
              "        91,  93,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102,  52,\n",
              "       104, 105, 106, 107, 108, 109, 110, 111])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "meFyvYOrOr9L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "feb5725a-5971-409b-c870-08624978ea25"
      },
      "source": [
        "Colour_accuracy = accuracy_score(Colour_TestData.classes, Colour_predict_classes)\n",
        "print(\"Colour Accuracy: \", Colour_accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Colour Accuracy:  0.8482142857142857\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-4hFVOkPpsd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "05606ce9-a5d6-4078-f7ec-b11b73c392c2"
      },
      "source": [
        "Colour_precision = precision_score(Colour_TestData.classes, Colour_predict_classes,average=\"weighted\")\n",
        "print(\"Colour Precision: \", Colour_precision)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Colour Precision:  0.7827380952380951\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VkgJCVPqPu3t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "30af508b-641c-496f-96fd-515be5f1ee6d"
      },
      "source": [
        "Colour_recall = recall_score(Colour_TestData.classes, Colour_predict_classes, average=\"weighted\")\n",
        "print(\"Colour Recall:\", Colour_recall)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Colour Recall: 0.8482142857142857\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGzTOJ5VPydq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "042bbfbb-3be1-45be-8528-769345bd8ef0"
      },
      "source": [
        "Colour_f1_score = f1_score(Colour_TestData.classes, Colour_predict_classes, average=\"weighted\")\n",
        "print(\"F1 score for colour: \", Colour_f1_score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 score for colour:  0.8035714285714286\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A3QNKcw2P5wD",
        "colab_type": "text"
      },
      "source": [
        "**Emsemble**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "01-hknWtP-OV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Final = 0.6* Colour_predict + 0.4* Grey_predict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CnzKZmW8QB1Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Final_Predict_classes = np.argmax(Final, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ez9pZ_95QFPT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "9c3d27e9-63ad-4c86-9cdc-7eb07d22f3bb"
      },
      "source": [
        "Final_Predict_classes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  0,   1,  15,   3,   4,   5,   6,   7,   6,   9,  10,  11,  12,\n",
              "        14,  14,  15,  16,  17,  19,  19,  20,  21,  22,  23,  24,  25,\n",
              "        26,  27,  28,  27,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
              "        39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
              "        52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  51,  63,  64,\n",
              "        67,  66,  67,  68,  69,  70,  71,  98,  73,  74,  98,  76,  77,\n",
              "        78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
              "        91,  93,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
              "       104, 105, 106, 107, 108, 109, 110, 111])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uIIiaLeAQHCz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1ebeadcb-9b16-452f-bfd1-4201f041d943"
      },
      "source": [
        "Final_accuracy = accuracy_score(Colour_TestData.classes, Final_Predict_classes)\n",
        "print(\"Colour Accuracy: \", Final_accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Colour Accuracy:  0.9107142857142857\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xWh0QU4QKfi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "75bb11a1-3502-44c0-c232-a1203a761007"
      },
      "source": [
        "Final_precision = precision_score(Colour_TestData.classes, Final_Predict_classes,average=\"weighted\")\n",
        "print(\"Colour Precision: \", Final_precision)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Colour Precision:  0.8690476190476192\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUe0YMKmQS0f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1390c447-13e5-4318-ace9-0c4b5ef578e8"
      },
      "source": [
        "Final_recall = recall_score(Colour_TestData.classes, Final_Predict_classes, average=\"weighted\")\n",
        "print(\"Colour Recall:\", Final_recall)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Colour Recall: 0.9107142857142857\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJraKXWUQVt_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b459eb0c-b676-4443-f93a-496d682554c4"
      },
      "source": [
        "Final_f1_score = f1_score(Colour_TestData.classes, Final_Predict_classes, average=\"weighted\")\n",
        "print(\"F1 score for colour: \", Final_f1_score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 score for colour:  0.8824404761904763\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qEgDAK36qj-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Second_Final = 0.5* Colour_predict + 0.5 * Grey_predict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z5J1_SGc63t7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Second_predict_classes = np.argmax(Second_Final, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmdwqtuo7A63",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "eea36423-4c29-41d7-aa09-6cf2bc35fa70"
      },
      "source": [
        "Second_predict_classes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  0,   1,  15,   3,   4,   5,   6,   7,   6,   9,  10,  11,  12,\n",
              "        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
              "        26,  27,  17,  27,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
              "        39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
              "        52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  51,  63,  64,\n",
              "        67,  66,  67,  68,  69,  70,  71,  72,  73,  74,  98,  76,  77,\n",
              "        78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
              "        91,  92,  93,  94,  95,  96,  97,  98, 100, 100, 101, 102, 103,\n",
              "       104, 105, 106, 107, 108, 109, 110, 111])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6hhnNOD07EsP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b6640838-e145-4244-abec-c6614a51a9a9"
      },
      "source": [
        "Second_Final_accuracy = accuracy_score(Colour_TestData.classes, Second_predict_classes)\n",
        "Second_Final_accuracy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9285714285714286"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    }
  ]
}